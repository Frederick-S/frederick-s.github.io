title: 'MIT 6.824 Lab 1 (6) - 实现'
tags:
- MIT 6.824
- Go
- MapReduce
---

`Lab 1` 需要我们实现一个单机多线程、多进程的 `MapReduce` 程序，结合 `MapReduce` 的主要流程首先来看一下在本实验中需要做什么。

<!-- 1. 首先 `MapReduce` 框架将输入数据分为 `M` 片，每片数据大小一般为 `16 MB` 至 `64 MB`（具体大小可由用户入参控制）：这里可简单使用输入文件的个数作为 `M` 的值，也不需要对输入文件进行数据块切分，当然如果文件数量过多或者单个文件过大也可以将单个文件拆分后分发给多个 `map` 节点
2. 在所有的程序拷贝中，某台机器上的程序会成为主节点（`master`），其余称为工作节点（`worker`），由主节点向工作节点分派任务，一共有 `M` 个 `map` 任务和 `R` 个 `reduce` 任务需要分派：这里的主节点就是我们需要实现的 `Coordinator` 类，`R` 在本实验中固定为10
3. 如果某个工作节点被分派了 `map` 任务则会读取当前的数据分片，然后将输入数据解析为一组键值对后传递给用户自定义的 `map` 函数执行。`map` 函数产生的中间结果键值对会暂存在内存中：按照第一条的规则，当前的数据分片就是一个文件，`map` 节点读取文件内容后通过插件加载用户自定义的 `map` 函数，调用 `map` 函数后生成一组中间结果键值对
4. 暂存在内存中的中间结果键值对会周期性的写入到本地磁盘中，并根据某个分片函数将这些数据写入到本地磁盘下的 `R` 个区。同时，这些数据写入后的地址会回传给 `master` 节点： -->

## 概览
通过 `test-mr.sh` 可以看到该实验会先启动一个主节点进程，然后再启动多个工作节点进程。

## 主节点
主节点的入口是 `mrcoordinator.go`，通过 `go run mrcoordinator.go pg*.txt` 可运行一个主节点程序，其中 `pg*.txt` 是本次 `MapReduce` 程序的输入数据。同时，主节点和工作节点间通过 `RPC` 进行交互，需要我们实现以下 `RPC` 接口：

1. 实验中主节点的任务分发采用的是拉模式，工作节点会定期向主节点请求一个任务，这个任务可以是 `map` 任务也可以是 `reduce` 任务，由主节点根据当前任务的状态决定应该推送 `map` 任务还是 `reduce` 任务

## 工作节点
工作节点的入口是 `mrworker.go`，通过 `go run mrworker.go wc.so` 可运行一个工作节点程序，其中 `wc.so` 是本次 `MapReduce` 程序用到的用户自定义 `map` 和 `reduce` 函数。工作节点只有一个 `Worker` 主方法，需要不断向主节点轮询请求任务，那么工作节点什么时候结束轮询？根据实验建议有两种方法，一种是当本次 `MapReduce` 任务完成后，主节点进程退出，当工作节点再次请求主节点任务时，`RPC` 请求必然失败，此时工作节点可认为本次任务已完成主节点已退出，从而结束轮询；另一种是当主节点完成后，在收到工作节点新的任务请求时，返回一个要求工作节点退出的标识（或者也可抽象为一种任务类型），工作节点收到 `RPC` 响应后退出。

参考：

* [6.824 Lab 1: MapReduce](https://pdos.csail.mit.edu/6.824/labs/lab-mr.html)