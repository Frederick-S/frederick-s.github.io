title: 'MIT 6.824 - Spanner: Google’s Globally-Distributed Database'
tags:
- MIT 6.824
- Paper
- Distributed Systems
- Spanner
---

## 介绍
`Spanner` 是一个由 `Google` 设计，构建和部署的可扩展的全球分布式数据库。从高层次的抽象来看，作为一个数据库，`Spanner` 将数据进行分片，每个分片构建在一组 `Paxos` 状态机之上，同时所有的数据存储在世界各地的各个数据中心内。`Spanner` 使用副本来保证数据库的全球可用性和客户端读取数据的就近访问性；客户端也能自动的在各个副本之间实现故障转移。当数据量或者服务器数量发生变化时，`Spanner` 能自动的跨服务器对数据进行重分区；同时，`Spanner` 也能自动的跨服务器（甚至是跨数据中心）迁移数据来达成负载均衡或者应对异常。`Spanner` 的扩展性能够支持上百个数据中心的几百万台服务器，以及几万亿的数据行。

应用程序可以借助 `Spanner` 来确保高可用，即使是面对大面积的自然灾害，也可以通过将数据存储在单个大洲或者跨大洲的多个数据中心来保证容错。`Spanner` 的第一个客户是 `F1`，`F1` 是 `Google` 广告后端的一个重构项目。`F1` 的每份数据在美国境内存有5个副本。大部分其他的应用程序一般会将数据备份在同一个地理区域内的3到5个数据中心中，不过这在应对极端灾害时容错性要略差一些。因为在能够容忍1到2个数据中心异常的情况下，大多数的应用程序相比于更进一步的高可用更看重低延迟。

`Spanner` 设计的首要关注点是管理跨数据中心的数据副本，不过设计者依然在 `Google` 已有的分布式系统设施之上花了大量的时间来设计和实现某些重要的数据库特性。虽然 `Bigtable` 能满足很多项目的需求，不过依然有很多 `Bigtable` 的用户反馈在某些场景下 `Bigtable` 难以胜任：例如涉及复杂、不断改变的数据库模式；或者要求大范围数据复制场景下保证强一致性。出于半关系型数据模型以及同步复制的特性，很多 `Google` 的应用选择使用 `Megastore` 来存储数据，尽管 `Megastore` 的写性能不是很好。因此，`Spanner` 从一个类似 `Bigtable` 的带版本号的键值存储演化为了一个基于时间戳的多版本数据库。`Spanner` 中的数据保存在半关系型的表中；每个数据存有多个版本，每个版本的数据都自动标记着提交时的时间戳；旧版本的数据可以根据可配置的垃圾回收策略进行回收；应用程序可以读取某个旧的时间戳下的数据。`Spanner` 支持通用的事务，以及提供了一个基于 `SQL` 的查询语言。

作为一个全球分布式数据库，`Spanner` 提供了几个有趣的特性。首先，应用程序能以合适的粒度动态的调控数据复制的配置。应用程序可以通过配置指定哪个数据中心保存什么样的数据，数据存储的位置距离终端用户有多远（控制读延迟），数据的各个副本间距离多远（控制写延迟），每个数据要保存几个副本（控制持久性，可用性和读性能）。同时，系统可以动态和透明的在各个数据中心间迁移数据，从而在各数据中心间实现资源的均衡使用。第二，`Spanner` 实现了两个在分布式数据库中难以实现的功能：提供了外部一致性的读和写，以及在某个时间戳上跨全球数据库的一致性读。这些特性使得 `Spanner` 能够在全球多数据中心级别支持一致性备份，一致性的 `MapReduce` 任务执行，以及原子性的数据库模式更新，即使执行这些操作时存在进行中的事务也没有关系。

`Spanner` 通过对事务记录全球提交时间戳来实现上述特性，即使事务可能会被分布式的执行。事务的时间戳体现了串行顺序性。另外，这个串行顺序性满足外部一致性（或者相当于线性一致性）：如果某个事务$T_1$在另一个事务$T_2$开始执行前完成提交，则$T_1$的提交时间戳小于$T_2$的提交时间戳。`Spanner` 是第一个在全球数据中心级别保证这一特性的系统。

实现上述特性的关键点是一个全新的 `TrueTime` `API` 及其实现。这个 `API` 直接将时间的不确定性暴露给了使用方，而 `Spanner` 基于 `TrueTime` 提供的不确定性时间的范围（后面会提到 `TrueTime` 返回当前时间时不是返回一个单独的值，而是一个范围，`TrueTime` 会确保当前时间落在这个范围内）实现了事务时间戳先后顺序的保证。如果这个时间的不确定性范围太大，`Spanner` 会减缓操作来等待不确定性范围变小。`Google` 的集群管理软件提供了 `TrueTime` `API` 的一种实现。这个实现利用多个现代的基准时钟（`GPS` 和原子钟）能将时间不确定性控制在很小的一个范围内（一般来说小于10毫秒）。

## 实现
本节描述了 `Spanner` 的结构及其底层实现。然后会再介绍目录（`directory`），和文件系统中的目录不同，`Spanner` 中的目录是一个抽象的概念，用于管理数据副本和访问局部性，同时也是数据迁移的最小单元。最后会介绍 `Spanner` 的数据模型，相比于键值数据库 `Spanner` 更像是个关系型数据库，以及描述了应用程序如何控制数据的存储位置来实现访问局部性。

一个 `Spanner` 的完整部署被称之为 `universe`。因为 `Spanner` 在全球级别的数据中心管理数据，所以一共只会有几个运行中的 `universe`。`Google` 目前运行了一个测试/体验环境的 `universe`，一个开发/生产环境的 `universe`，以及一个仅生产环境的 `universe`。

一个 `Spanner` 实例以一组 `zone` 的形式来组织，每个 `zone` 差不多等同于部署了一批 `Bigtable` 服务器。每个 `zone` 是一个可管理的部署单元。系统以 `zone` 为单位对数据进行复制。当上线或者下线数据中心时，可以向运行中的系统添加或者删除 `zone`。`zone` 也是物理隔离的单位：一个数据中心内可能有1个或者多个 `zone`，例如不同应用程序的数据需要分片到同一个数据中心内的不同服务器上。

![alt](/images/spanner-1.png)

上图展示了 `Spanner` 的一个 `universe` 中各服务器的职责。每个 `zone` 有一个 `zonemaster` 和成百上千台 `spanserver`。`zonemaster` 向 `spanserver` 分发数据，`spanserver` 向客户端提供数据服务。同时，客户端通过每个 `zone` 内的 `location proxy` 来确定需要访问哪台 `spanserver` 获取数据。`universe master` 和 `placement driver` 目前是单点的。`universe master` 主要是一个控制台，用于展示所有 `zone` 的状态信息，从而方便调试。`placement driver` 负责自动的在各个 `zone` 之前进行数据迁移，这个的操作耗时一般是分钟级。出于满足数据副本数量的要求以及实现数据访问的负载均衡，`placement driver` 会周期性的和 `spanserver` 通信从而确认哪些数据需要迁移。出于篇幅考虑，论文只会描述 `spanserver` 的实现细节。

### Spanserver 软件栈
![alt](/images/spanner-2.png)

本节主要关注 `spanserver` 的实现并展示了如何在 `Bigtable` 的实现之上构建数据复制和分布式事务。上图展示了 `spanserver` 的软件栈。在底部，每个 `spanserver` 负责管理100到1000个被称之为 `tablet` 的数据结构实例。`tablet` 类似于 `Bigtable` 中表的抽象，其内部维护了如下的映射：

```
(key:string, timestamp:int64) -> string
```

和 `Bigtable` 不同的是，`Spanner` 给每一个数据都标记了时间戳，从而使得 `Spanner` 更像是一个多版本数据库而不是键值存储。每个 `tablet` 的状态会保存在一组类似 `B` 树的文件以及一个预写日志中，所有的文件都会保存在一个称之为 `Colossus`（`Google File System` 的后继者）的分布式文件系统中。

为了支持数据复制，每个 `spanserver` 在每个 `tablet` 之上构建了一个单 `Paxos` 状态机（`Spanner` 的早期设计支持每个 `tablet` 对应多个 `Paxos` 状态机，这能支持更灵活的复制配置。不过由于这种设计的复杂性作者最终放弃了）。每个状态机将其元数据和日志保存到对应的 `tablet` 中。`Spanner` 的 `Paxos` 实现支持长期存活的主节点，每个主节点会分配一个基于时间的租约，租期的默认长度是10秒。当前 `Spanner` 的实现会记录两次 `Paxos` 的写操作，一次是在 `tablet` 的日志中，另一次是在 `Paxos` 的日志中。不过这个目前只是权宜之计，可能会在未来修复。`Spanner` 的 `Paxos` 实现能以管道的方式执行，因此在 `WAN` 环境的延迟下能提高 `Spanner` 的吞吐；不过提交到 `Paxos` 的写操作会按照顺序执行。

`Spanner` 借助 `Paxos` 状态机实现了一致性的数据映射复制。每个副本的键值映射状态都会保存在相应的 `tablet` 中。客户端的写操作必须由主节点发起 `Paxos` 协议；而读操作可以由任意一个有着最新数据的副本执行。这些副本构成了一个 `Pzsos group`。

对于身为主节点的副本来说，每个 `spanserver` 实现了一个锁表（`lock table`）来实现并发控制。锁表包含了两阶段锁的状态：它会将某个范围内的键和锁的状态建立映射（长期存活的主节点是高效管理锁表的关键。）。在 `Bigtable` 和 `Spanner` 中，锁表都是专门为长时间运行的事务所设计（例如，对于报表生成这样的事务可能需要花费分钟级的时间才能完成），但在锁竞争激烈的情况下使用乐观并发控制策略会造成性能不佳。诸如事务读这样需要同步的操作需要先从锁表中获取锁；其他不涉及同步的操作则无需操作锁表。

对于身为主节点的副本来说，每个 `spanserver` 实现了一个事务管理器（`transaction manager`）来支持分布式事务。事务管理器被用来实现 `participant leader`；而其他同 `Paxos` 组内的副本则被称为 `participant slaves`。如果一个事务只涉及一个 `Paxos` 组（对于大多数的事务来说），则无需事务管理器介入，因为锁表和 `Paxos` 一起已经提供了事务功能。如果一个事务涉及多个 `Paxos` 组，则每个组的主节点需要协同完成二阶段提交。其中某个 `Paxos` 组会被选为协调者：该组的 `participant leader` 则会担任 `coordinator leader`，该组内其他的从节点则担任 `coordinator slaves`。事务管理器的状态会保存在底层的 `Paxos` 组中（因此这个状态数据也会存有多个副本）。

### 目录和数据放置
在键值映射之上，`Spanner` 的实现支持被称为目录（`directory`）的桶的抽象，目录是一组有着公共前缀的连续键的集合（命名为目录是由于历史的偶然；一个更好的命名可能是桶（`bucket`）。）。目录的支持使得应用程序可以通过设置合适的键来控制数据访问的局部性。

一个目录是数据放置的最小单元。每个目录下的所有数据有着相同的复制配置。数据以目录的形式从一个 `Paxos` 组迁移到另一个 `Paxos` 组，下图描述了这个过程。`Spanner` 可能会移动一个目录来减轻某个 `Paxos` 组的负载；或者将经常被同时访问的多个目录移动到同一个 `Paxos` 组中；或者将某个目录移动到距离客户端更近的 `Paxos` 组中。目录的移动可以和客户端的操作同时进行。一个 `50 MB` 大小的目录可以在几秒内完成。

![alt](/images/spanner-3.png)

一个 `Paxos` 组可能会包含多个目录说明 `Spanner` 的 `tablet` 和 `Bigtable` 的 `tablet` 不同：`Spanner` 的 `tablet` 没有必要是行空间（`row space`）内按照字典顺序的连续分区。相反，一个 `Spanner` 的 `tablet` 可能包含了行空间的多个分区。正是基于此特性才使得多个同时被访问的目录可以被移动到同一个 `Paxos` 组中。下图展示了各组成部分间的关系：

![alt](/images/spanner-4.png)

`Spanner` 使用 `Movedir` 这样的后台任务在多个 `Paxos` 组之间移动目录。`Movedir` 也被用来向 `Paxos` 组中添加或者删除副本，因为目前 `Spanner` 还不支持在 `Paxos` 内部实现配置变更。`Movedir` 没有被设计为一个独立的事务，这主要是为了避免在进行大量数据移动时阻塞读写请求。相反，`movedir` 会在后台开始迁移数据。当 `movedir` 完成数据迁移，但还剩下一小部分数据未迁移时，则会发起一个事务自动的完成数据的迁移，然后更新涉及的两个 `Paxos` 组的元数据。

目录是应用程序能够控制副本的地理位置属性（或者简单来说，数据放置）的最小单位。在 `Spanner` 的设计中，数据放置规范语言（`placement-specification language`）和管理副本配置的职责相解耦。管理员可以控制两个维度：副本的数量和类型，以及副本所在的地理位置属性。`Spanner` 为这两个维度提供了可选的选项（例如，`North America, replicated 5 ways with 1 witness`）。应用程序通过标记每个数据库和/或者单个目录的复制选项组合来控制数据的复制。例如，某个应用程序可能会将每个终端用户的数据保存在自己的目录中，从而使得用户 `A` 的数据在欧洲有三个副本，用户 `B` 的数据在北美有5个副本。

出于表达清晰的考虑作者简化了描述。实际上，如果某个目录包含的数据过多，`Spanner` 会将其拆分为多个段（`fragment`）。不同的段会由不同的 `Paxos` 组提供服务（也对应了不同的服务器）。`Movedir` 实际上是在各个 `Paxos` 组之间移动段，而不是整个目录。

### 数据模型
`Spanner` 为应用程序提供了如下的数据特性：一个基于模式化半关系型表的数据模型，一个查询语言，以及通用型事务。之所以要支持这些特性是受几方面的驱动。支持模式化半关系型表和同步复制的需求来自于 `Megastore` 的流行。至少有300个 `Google` 内部的应用程序选择使用 `Megastore`（尽管它的性能不是很好），因为它的数据模型比 `Bigtable` 更简单，而且它也支持跨数据中心的同步数据复制（`Bigtable` 只支持跨数据中心数据复制的最终一致性）。使用 `Megastore` 的 `Google` 应用程序中比较有名的有 `Gmail`，`Picasa`，`Calendar`，`Android Market` 和 `AppEngine`。在 `Spanner` 中支持类似 `SQL` 的查询语言的需求同样很明确，因为交互式数据分析工具 `Dremel` 也很流行。最后，希望 `Bigtable` 支持跨行的事务的呼声也很强烈；开发 `Percolator` 的部分原因就是为了解决这个问题。某些作者认为通用的二阶段提交的支持成本太大，因为它存在性能和可用性问题。不过，`Spanner` 的作者认为最好交给应用开发人员来处理由于过度使用事务而产生的性能瓶颈，而不是始终在缺少事务的环境下编程。而在 `Paxos` 之上实现二阶段提交则减缓了可用性问题。

应用程序的数据模型构建在目录式的键值数据映射之上。一个应用程序会在一个 `universe` 中创建一个或者多个数据库。每个数据库可以包含不限制数量的模式化表。`Spanner` 的表类似于关系型数据库中的表，它同样有行，列，以及带版本的值。本文不会深入探讨 `Spanner` 的查询语言。它和 `SQL` 很像不过在这基础之上多了些扩展来支持 `protocol-buffer` 类型的字段。

`Spanner` 的数据模型不是纯关系型的，它的行必须有名称。更准确的来说，每张表需要有一个或者多个主键列组成的有序集合。这个要求使得 `Spanner` 看起来像一个键值存储：主键定义了每行的名称，每个表定义了主键列到非主键列的映射。只有某个主键对应有值（即使值是 `NULL`）才能被认为某一行存在。采用这个结构使得应用程序能通过选择键来控制数据访问的局部性。

![alt](/images/spanner-5.png)

上图展示了 `Spanner` 数据模式的一个示例，在这个例子中，我们创建了两张表来存储每个用户和每张照片的元数据。`Spanner` 的模式语言和 `Megastore` 类似，不过 `Spanner` 有额外的要求，`Spanner` 的每个数据库必须由客户端分区为一个或者多个层次化的表。客户端程序通过 `INTERLEAVE IN` 来声明数据库模式的层次化结构。位于层次化结构顶端的表被称之为 `directory table`。`directory table` 中以 `K` 为键的数据，和关联的子孙表中所有键以 `K` 为起始的行按照字典顺序组成了一个目录。`ON DELETE CASCADE` 表明如果删除了 `directory table` 中的一条数据，则需要一并删除关联的子孙表中的数据。上图也展示了示例数据库的交错结构（`interleaved layout`）：例如，`Albums(2, 1)` 表示 `Albums` 表中 `user_id` 为2，`album_id` 为1的数据。这种由交错的表组成的目录对于客户端来说非常重要，因为它使得客户端能够描述不同的表之间的局部性关联，这对于分片、分布式的数据库的高性能来说非常重要。如果缺少这个特性，`Spanner` 将无从知晓最重要的局部性关联。

## TrueTime
本节主要描述 `TrueTime` 的 `API` 及概述其实现。`TrueTime` 大部分的细节会在另一篇论文中描述，本文主要是展示它对于 `Spanner` 的重要性。下表列举了 `TrueTime` 的 `API`。`TrueTime` 以 `TTinterval` 的形式表示时间，`TTinterval` 是一段表示非确定性时间的有界区间（而标准时间接口并不会将时间的不确定性暴露给客户端）。`TTinterval` 两个端点值的类型为 `TTstamp`。`TT.now()` 会返回一个 `TTinterval`，并且保证 `TTinterval` 所表示的时间区间一定包含 `TT.now()` 被调用时的绝对时间。这个时间类似于带闰秒的 `UNIX` 时间。定义时间的瞬时误差上限为$\epsilon$，其值为 `TTinterval` 区间长度的一半，以及定义$\bar{\epsilon}$ 为平均误差上限。`TT.after()` 和 `TT.before()` 是基于 `TT.now()` 的更易用的封装。

|Method   |Returns   |
|---|---|
|TT.now()   |TTinterval: [earliest, latest]   |
|TT.after(t)   |true if t has definitely passed   |
|TT.before(t)   |true if t has definitely not arrived   |

## 参考
* [Spanner: Google’s Globally-Distributed Database](https://pdos.csail.mit.edu/6.824/papers/spanner.pdf)
* [Benefits of Cloud Spanner replication](https://cloud.google.com/spanner/docs/replication#benefits_of_cloud_spanner_replication)