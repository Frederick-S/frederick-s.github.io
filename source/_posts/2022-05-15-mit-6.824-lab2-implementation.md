title: "MIT 6.824 - Lab 2 (3): 实现"
tags:
- MIT 6.824
- Go
- Raft
- Distributed Systems
---

## 准备工作
### 日志
[Debugging by Pretty Printing](https://blog.josejg.com/debugging-pretty/) 中介绍了如何高效的打印日志，这有助于在实验时进行问题排查。

首先在 `Go` 侧需要封装一个日志打印函数 `PrettyDebug`（`raft` 目录下已经有了 `Debug` 变量，所以这里重命名为 `PrettyDebug`），在 `raft` 目录下新建一个 `Go` 文件，复制以下内容：

```go
package raft

import (
	"fmt"
	"log"
	"os"
	"strconv"
	"time"
)

// Retrieve the verbosity level from an environment variable
func getVerbosity() int {
	v := os.Getenv("VERBOSE")
	level := 0
	if v != "" {
		var err error
		level, err = strconv.Atoi(v)
		if err != nil {
			log.Fatalf("Invalid verbosity %v", v)
		}
	}
	return level
}

type logTopic string

const (
	dClient    logTopic = "CLNT"
	dCommit    logTopic = "CMIT"
	dDrop      logTopic = "DROP"
	dError     logTopic = "ERRO"
	dInfo      logTopic = "INFO"
	dLeader    logTopic = "LEAD"
	dCandidate logTopic = "CAND"
	dLog       logTopic = "LOG1"
	dLog2      logTopic = "LOG2"
	dPersist   logTopic = "PERS"
	dSnap      logTopic = "SNAP"
	dTerm      logTopic = "TERM"
	dTest      logTopic = "TEST"
	dTimer     logTopic = "TIMR"
	dTrace     logTopic = "TRCE"
	dVote      logTopic = "VOTE"
	dWarn      logTopic = "WARN"
)

var debugStart time.Time
var debugVerbosity int

func init() {
	debugVerbosity = getVerbosity()
	debugStart = time.Now()

	log.SetFlags(log.Flags() &^ (log.Ldate | log.Ltime))
}

func PrettyDebug(topic logTopic, format string, a ...interface{}) {
	if debugVerbosity >= 1 {
		t := time.Since(debugStart).Microseconds()
		t /= 100
		prefix := fmt.Sprintf("%06d %v ", t, string(topic))
		format = prefix + format
		log.Printf(format, a...)
	}
}
```

`PrettyDebug` 会通过环境变量 `VERBOSE` 来决定是否打印日志，该方法接受三个参数，第一个是日志主题用于对日志分组，后两个参数则是传递给 `log.Printf` 进行格式化打印，使用方法如下：

```go
PrettyDebug(dTimer, "S%d, apply log, log index=%v, log term=%v, log command=%v", rf.me, entry.Index, entry.Term, entry.Command)
```

日志信息中的 `S%d` 是关键，它表示当前节点的编号，如 `S0`，`S1`，按照这个模式打印日志，在后续日志处理时能将日志按照节点分组。

然后，就可以通过 `VERBOSE=1 go test -run TestFigure82C` 来进行测试（这里的 `TestFigure82C` 可以换成其他的测试用例）：

![alt](/images/raft-lab-1.png)

不过所有日志都混到了一起，不好区分，作者因此提供了一个 `Python` 脚本 [dslogs](https://gist.github.com/JJGO/e64c0e8aedb5d464b5f79d3b12197338) 来美化日志。这个脚本用到了 `typer` 和 `rich` 两个库，可以通过 `pip` 全局安装。接着再执行测试 `VERBOSE=1 go test -run TestFigure82C | pipenv run python dslogs.py`（这里使用了 `pipenv` 来安装依赖和运行脚本，不使用 `pipenv` 的可以按照作者的方式执行），美化后的日志根据主题着色后有了更强的区分度：

![alt](/images/raft-lab-2.png)

更进一步，还可以将日志按照节点分组展示 `VERBOSE=1 go test -run TestFigure82C | pipenv run python dslogs.py -c 3`：

![alt](/images/raft-lab-3.png)

在上图中，每一列表示一个节点的日志，而且自上而下随时间排序。

### 批量测试
做实验时有时候测试用例成功了，有时候失败了，每次手动测试不方便抓取日志，[Debugging by Pretty Printing](https://blog.josejg.com/debugging-pretty/) 的作者提供了另一个脚本 [dstest](https://gist.github.com/JJGO/0d73540ef7cc2f066cb535156b7cbdab) 来进行批量测试，并且当测试失败时自动保存日志到文件中，从而可以使用上面提到的脚本 `dslogs` 来处理日志，`dstest` 这个脚本也依赖 `typer` 和 `rich` 这两个库。

然后通过 `pipenv run python dstest.py 2A -n 10 -v 1` 进行批量测试，这里 `2A` 可以换成其他的测试用例，`-n 10` 表示测试多少次，默认是10，`-v 1` 表示设置环境变量 `VERBOSE`，这样就能告诉 `Go` 打印日志：

![alt](/images/raft-lab-4.png)

![alt](/images/raft-lab-5.png)

脚本貌似有个小问题，当设置 `-v x` 参数时，会多一个名为 `x` 的测试任务，不过并不影响使用。

如果某次测试执行失败，则会保存相应的日志：

![alt](/images/raft-lab-6.png)

## 实现
### 2A
第一个实验是选主，关键有两点：随机化的 `election timeout` 和什么时候重置 `election timeout`。

当候选节点发出 `RequestVote` 请求后，应该在哪里判断是否获得了足够的选票？一种是在遍历完所有从节点发出 `RequestVote` 请求后，不过由于 `RPC` 的异步性，需要某种异步通知机制来通知当前的 `goroutine`。可以使用 `sync.WaitGroup`，事先计算好需要多少张选票才能成为主节点，发送 `RPC` 请求前调用 `WaitGroup.Add(1)`，每当获得一张选票后就调用 `WaitGroup.Done()`，当获得了足够的选票后当前 `goroutine` 就能被唤醒，不过由于当前节点不一定能成为主节点，所以存在无法被唤醒的可能。虽然可以把 `WaitGroup` 设置成所有 `RPC` 都响应后再唤醒，不过整个响应时间就受限于最慢的 `RPC` 请求，等待时间可能会超过一个 `election timeout` 周期。使用这种方式的一个很大的问题就是无法及时响应其他候选节点成为主节点的情况，因为当前候选节点还阻塞在 `WaitGroup.Wait()`。

所以可以将是否获得了足够的选票的判断放在每个 `RequestVote` 的响应中。先初始化需要的选票数量，每次获得选票后使用原子方法 `atomic.AddInt32` 对票数减1，当返回票数小于等于0时，说明当前候选节点成为了主节点。

### 2B
第二个实验需要实现日志复制。日志是 `Raft` 的核心部分，首先定义 `LogEntry`，包含三个字段，索引、任期、指令：

```go
type LogEntry struct {
	Index   int
	Term    int
	Command interface{}
}
```

之所以这里需要 `Index` 是因为需要对日志压缩，所以不能使用 `rf.log` 的数组下标作为日志项的索引。

复制日志时，可以选择在调用 `Start` 方法时就发送 `AppendEntries` 请求，并且在响应中判断从节点的日志是否匹配来更新 `prevLogIndex`，然后继续发送 `AppendEntries` 请求。不过，这会造成两个问题。

第一个问题是冗余的 `RPC` 请求，假设客户端连续调用了10次 `Start`，那么根据当前的 `prevLogIndex` 计算，主节点所发送的 `AppendEntries` 请求中分别包含1条日志，2条日志，...，10条日志。然而这10次 `AppendEntries` 请求完全可以由第10条请求替代，而如果 `prevLogIndex` 不匹配，主从节点间来回协调的过程又会带来更多的 `RPC` 交互，最终有可能导致测试用例 `TestCount2B` 的失败。

第二个问题是测试用例会模拟出特别不稳定的网络，如果在 `AppendEntries` 的响应中接着递归异步调用 `AppendEntries`，由于 `goroutine` 都在等待网络可能会造成同时存在的 `goroutine` 数量过多，导致测试失败。

所以，可以选择不在 `Start` 中发送带日志的 `AppendEntries` 请求，而是在常规心跳中根据 `nextIndex` 计算是否要发送日志。

### 2C

### 2D

## 参考

* [6.824 Lab 2: Raft](https://pdos.csail.mit.edu/6.824/labs/lab-raft.html)
* [Debugging by Pretty Printing](https://blog.josejg.com/debugging-pretty/)