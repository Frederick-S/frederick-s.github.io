title: "MIT 6.824 - Lab 3 (2): 实现"
tags:
- MIT 6.824
- Go
- Raft
- Distributed Systems
---

`Lab 3` 需要我们实现一个基于 `Raft` 的键值数据库，支持三个操作：

* `Put(key, value)`
* `Append(key, value)`
* `Get(key)`

## 3A
### 客户端
客户端要做的只有一件事，就是向某个服务端发送请求。不过由于客户端不知道哪个服务端是主节点，所以需要不断轮询各服务端发送请求。为了避免每次轮询所有服务端浪费时间，客户端可以记录每次请求成功后的服务端编号，这个服务端就是当次请求中的主节点；当客户端再次发起请求时，可以先假定之前的服务端依然是主节点，从而先向该服务端发送请求，如果请求失败并返回非主节点异常，则再尝试下一个服务端。

### 服务端
`Lab 3` 要求服务端将客户端请求成功的结果放到 `RPC` 响应中，不过 `Raft.Start()` 的执行成功不代表最终日志的应用成功，所以服务端调用 `Raft.Start()` 后需要阻塞等待，直到 `Raft` 将对应日志应用到状态机。等待/唤醒的模式可以想到使用条件变量 `sync.Cond`，不过 `Go` 中有 `channel` 这个更方便的特性来实现。

正常情况下，服务端调用 `Raft.Start()` 添加日志的顺序和之后从 `applyCh` 中收到日志的顺序一致，也就是说客户端请求到达服务端并被处理的顺序和服务端从 `applyCh` 中收到日志的顺序一致。所以，服务端可以维护一个客户端请求的队列，队列中存放的是 `channel`，每当服务端从 `applyCh` 中收到日志，就将日志发送到队首的 `channel` 中，并从队列中移除。这样阻塞等待中的 `RPC` 服务端线程就能被唤醒，并响应客户端。

不过在异常情况下，客户端请求队列和服务端从 `applyCh` 中收到日志的顺序并不是一一对应，因此服务端收到日志时需要剔除掉队列中无效的请求，并通过 `channel` 发送一个 `ErrWrongLeader` 异常，这样客户端就能换一个服务端来重试。由于通过日志索引无法唯一确定一条 `Raft` 日志，所以需要在 `ApplyMsg` 中添加 `CommandTerm` 来标识日志所属的任期，这样服务端从 `applyCh` 中收到日志后就能通过比较客户端请求队列中的日志任期和索引来判断请求是否有效。

记客户端请求队列队首日志的任期和索引为 `(term_client, index_client)`，记服务端从 `applyCh` 收到的日志的任期和索引为 `(term_applied, index_applied)`。正常情况下有 `term_client == term_applied` 以及 `index_client == index_applied`。从服务端角度来说，异常情况有两种，一种是当前服务端不再是主节点，另一种情况是当前服务端依然是主节点，不过中途发生了主从切换可能造成当前的日志和最初的不同。对于第一种情况可以直接清空客户端请求队列，虽然 `(term_applied, index_applied)` 有可能符合部分的客户端请求，不过由于当前服务端不再是主节点，下次客户端请求的时候本身就要再轮询所有的服务端，所以这里等同于是提前让客户端轮询。对于第二种情况（也考虑原来是从节点后来变成主节点的场景），可以从队首开始遍历客户端请求队列，直到找到 `(term_client, index_client)` 和 `(term_applied, index_applied)` 相同的请求，在这之前的请求都可以剔除并返回异常（这里需要一个自定义异常，告诉客户端直接重试，因为当前服务端依然是主节点，所以客户端没有必要轮询）。

## 3B

## 参考
* [6.824 Lab 3: Fault-tolerant Key/Value Service](https://pdos.csail.mit.edu/6.824/labs/lab-kvraft.html)