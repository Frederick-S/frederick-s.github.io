<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Add property to web with JavaScript in SharePoint 2013 App</title>
    <url>/2015/06/07/add-property-to-web-with-javascript-in-sharepoint-2013-app/</url>
    <content><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><code>SharePoint App Model</code> provides a new approach to SharePoint development. And here is the question: where to save app data? There are several ways to save data in an app, you can create a list or connect to a database in Windows Azure or set custom properties in <code>AppManifest.xml</code>. But we can also save data to the property bag of a SharePoint web.</p>
<h2 id="Add-property-to-web"><a href="#Add-property-to-web" class="headerlink" title="Add property to web"></a>Add property to web</h2><p>Adding custom property to web is easy. Let’s just see the code:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> context = SP.ClientContext.get_current();</span><br><span class="line"><span class="keyword">var</span> web = context.get_web();</span><br><span class="line"></span><br><span class="line"><span class="comment">// Add a new property</span></span><br><span class="line"><span class="keyword">var</span> props = web.get_allProperties();</span><br><span class="line">props.set_item(<span class="string">&quot;MyProperty&quot;</span>, <span class="string">&quot;My property value&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// Apply change to web</span></span><br><span class="line">web.update();</span><br><span class="line">context.load(web);</span><br><span class="line"></span><br><span class="line">context.executeQueryAsync(<span class="function"><span class="keyword">function</span> (<span class="params">sender, args</span>) </span>&#123;</span><br><span class="line">    alert(<span class="string">&quot;Success.&quot;</span>);</span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span> (<span class="params">sender, args</span>) </span>&#123;</span><br><span class="line">    alert(<span class="string">&quot;Request failed.&quot;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>How do we know “MyProperty” is really added to web? We can check it here: <code>http://your_web/_api/web/AllProperties?$select=MyProperty</code>. The result looks like this:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">entry</span> <span class="attr">xml:base</span>=<span class="string">&quot;http://your_web/test/_api/&quot;</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://www.w3.org/2005/Atom&quot;</span> <span class="attr">xmlns:d</span>=<span class="string">&quot;http://schemas.microsoft.com/ado/2007/08/dataservices&quot;</span> <span class="attr">xmlns:m</span>=<span class="string">&quot;http://schemas.microsoft.com/ado/2007/08/dataservices/metadata&quot;</span> <span class="attr">xmlns:georss</span>=<span class="string">&quot;http://www.georss.org/georss&quot;</span> <span class="attr">xmlns:gml</span>=<span class="string">&quot;http://www.opengis.net/gml&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">id</span>&gt;</span>http://your_web/_api/web/AllProperties<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">category</span> <span class="attr">term</span>=<span class="string">&quot;SP.PropertyValues&quot;</span> <span class="attr">scheme</span>=<span class="string">&quot;http://schemas.microsoft.com/ado/2007/08/dataservices/scheme&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">link</span> <span class="attr">rel</span>=<span class="string">&quot;edit&quot;</span> <span class="attr">href</span>=<span class="string">&quot;web/AllProperties&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">updated</span>&gt;</span>2013-12-04T04:37:07Z<span class="tag">&lt;/<span class="name">updated</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">author</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span> /&gt;</span>;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">author</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">content</span> <span class="attr">type</span>=<span class="string">&quot;application/xml&quot;</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">m:properties</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">d:myproperty</span>&gt;</span>My property value<span class="tag">&lt;/<span class="name">d:myproperty</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">m:properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">content</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">entry</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="Read-property-from-web"><a href="#Read-property-from-web" class="headerlink" title="Read property from web"></a>Read property from web</h2><p>We have two approaches to read properties from web: <code>props.get_item(&quot;PropertyKey&quot;)</code> or <code>REST API</code>.</p>
<h3 id="The-get-item-method"><a href="#The-get-item-method" class="headerlink" title="The get_item method"></a>The get_item method</h3><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> context = SP.ClientContext.get_current();</span><br><span class="line"><span class="keyword">var</span> web = context.get_web();</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> props = web.get_allProperties();</span><br><span class="line">context.load(props);</span><br><span class="line"></span><br><span class="line">context.executeQueryAsync(<span class="function"><span class="keyword">function</span> (<span class="params">sender, args</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">var</span> prop = props.get_item(<span class="string">&quot;MyProperty&quot;</span>);</span><br><span class="line">    alert(prop);</span><br><span class="line">&#125;, <span class="function"><span class="keyword">function</span> (<span class="params">sender, args</span>) </span>&#123;</span><br><span class="line">    alert(<span class="string">&quot;Request failed.&quot;</span>);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<h3 id="The-REST-API"><a href="#The-REST-API" class="headerlink" title="The REST API"></a>The REST API</h3><figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> executor = <span class="keyword">new</span> SP.RequestExecutor(<span class="string">&#x27;http://your_web&#x27;</span>);</span><br><span class="line">executor.executeAsync(&#123;</span><br><span class="line">    url: <span class="string">&#x27;http://your_web/_api/web/AllProperties?$select=MyProperty&#x27;</span>,</span><br><span class="line">    method: <span class="string">&#x27;GET&#x27;</span>,</span><br><span class="line">    headers: &#123; <span class="string">&quot;Accept&quot;</span>: <span class="string">&quot;application/json; odata=verbose&quot;</span> &#125;,</span><br><span class="line">    success: <span class="function"><span class="keyword">function</span> (<span class="params">response</span>) </span>&#123;</span><br><span class="line">        <span class="keyword">var</span> obj = <span class="built_in">JSON</span>.parse(response.body);</span><br><span class="line">        alert(obj.d.MyProperty);</span><br><span class="line">    &#125;,</span><br><span class="line">    error: <span class="function"><span class="keyword">function</span> (<span class="params">response</span>) </span>&#123;</span><br><span class="line">        alert(response.body);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>

<p>And here is the json query result, very straightforward:</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;d&quot;</span>: &#123;</span><br><span class="line">        <span class="attr">&quot;__metadata&quot;</span>: &#123;</span><br><span class="line">            <span class="attr">&quot;id&quot;</span>: <span class="string">&quot;http://your_web/_api/web/AllProperties&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;uri&quot;</span>: <span class="string">&quot;http://your_web/_api/web/AllProperties&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;type&quot;</span>: <span class="string">&quot;SP.PropertyValues&quot;</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">&quot;MyProperty&quot;</span>: <span class="string">&quot;My property value&quot;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Reference:</p>
<ul>
<li><a href="http://blogs.technet.com/b/sharepointdevelopersupport/archive/2013/05/06/how-to-add-properties-to-spweb-property-bag-using-jsom-in-sharepoint-2013.aspx">HOW TO: Add properties to SPWeb property bag using JSOM in SharePoint 2013</a></li>
</ul>
]]></content>
      <tags>
        <tag>SharePoint Add-in</tag>
      </tags>
  </entry>
  <entry>
    <title>Fail to resize SharePoint App Part if &quot;Chrome Type&quot; is &quot;None&quot; or &quot;Border Only&quot;</title>
    <url>/2015/09/10/fail-to-resize-sharepoint-app-part-if-chrome-type-is-none-or-border-only/</url>
    <content><![CDATA[<h2 id="Issue"><a href="#Issue" class="headerlink" title="Issue"></a>Issue</h2><p>Today I met a bug in SharePoint 2013, I failed to resize my app part by using <code>postMessage</code>. Here is my code:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> message = <span class="string">&quot;&lt;Message senderId=&quot;</span> + senderId + <span class="string">&quot;&gt;&quot;</span> + <span class="string">&quot;resize(&quot;</span> + width + <span class="string">&quot;,&quot;</span> + height + <span class="string">&quot;)&lt;/Message&gt;&quot;</span>;</span><br><span class="line"><span class="built_in">window</span>.parent.postMessage(message, hostUrl);</span><br></pre></td></tr></table></figure>

<p>It fails to work if I set <code>Chrome Type</code> to <code>None</code> or <code>Border Only</code>. And I found an error message in console:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">Uncaught <span class="built_in">TypeError</span>: Cannot read property <span class="string">&#x27;style&#x27;</span> <span class="keyword">of</span> <span class="literal">null</span></span><br></pre></td></tr></table></figure>

<p>Then I located the code in my web part page which throws the error:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (resizeWidth)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">document</span>.getElementById(webPartDivId + <span class="string">&#x27;_ChromeTitle&#x27;</span>).style.cssText = widthCssText;</span><br><span class="line">    cssText = <span class="string">&#x27;width:100% !important;&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>It tries to find the title element and resize it. But <code>document.getElementById(webPartDivId + &#39;_ChromeTitle&#39;)</code> returns null if <code>Chrome Type</code> is <code>None</code> or <code>Border Only</code>!<br>Because the app part doesn’t have a title under these 2 modes. Of course it will throw exception.</p>
<h2 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h2><p>This bug is described <a href="http://social.msdn.microsoft.com/Forums/en-US/ea4b1ab6-3d44-4792-bce2-79056269852a/dynamic-width-and-height-for-iframe-app-part?forum=appsforsharepoint">here</a>, you can install a <a href="http://blogs.technet.com/b/stefan_gossner/archive/2013/03/21/march-public-update-for-sharepoint-2013-available-and-mandatory.aspx">patch</a> to fix this bug.</p>
<p>After the patch is installed, you can find that the original code is changed, it will resize the element only if it’s not null:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (resizeWidth)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">var</span> webPartChromeTitle = <span class="built_in">document</span>.getElementById(webPartDivId + <span class="string">&#x27;_ChromeTitle&#x27;</span>);</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">null</span> != webPartChromeTitle)</span><br><span class="line">    &#123;</span><br><span class="line">        webPartChromeTitle.style.cssText = widthCssText;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cssText = <span class="string">&#x27;width:100% !important;&#x27;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>Hope it’s helpful.</p>
<p>Reference:</p>
<ul>
<li><a href="http://social.msdn.microsoft.com/Forums/en-US/ea4b1ab6-3d44-4792-bce2-79056269852a/dynamic-width-and-height-for-iframe-app-part?forum=appsforsharepoint">Dynamic Width and Height for iFrame (App Part)</a></li>
</ul>
]]></content>
      <tags>
        <tag>SharePoint Add-in</tag>
      </tags>
  </entry>
  <entry>
    <title>Add new list field in SharePoint App upgrade</title>
    <url>/2015/12/21/add-new-list-field-in-sharepoint-app-upgrade/</url>
    <content><![CDATA[<p>I’m learning how to upgrade SharePoint App, and I met a problem when I added a new list field in the upgrade.</p>
<p>The <a href="http://msdn.microsoft.com/en-us/library/office/dn265911(v=office.15).aspx">document</a> mentioned that if you added a field to a content type in the feature, you should add an <code>AddContentTypeField</code> element to the <code>VersionRange</code> section. But there is no <code>ContentType</code> in my app, it only has a <code>ListDefinition</code>. I tried to add an <code>AddContentTypeField</code>, unfortunately it throws exception.</p>
<p>So I tried another way. The document also mentioned that if you have changed a file that is referenced in an elements manifest file, you have to copy the <code>ElementManifest</code> element for the component from the <code>ElementManifests</code> section to the <code>ApplyElementManifests</code> section. When we added a new field to list, the <code>Schema.xml</code> is changed, although it’s not referenced in a <code>ElementManifest</code>, I still copied <code>MyList/Elements.xml</code> to <code>ApplyElementManifests</code>, so it looks like this:</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">UpgradeActions</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">VersionRange</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">ApplyElementManifests</span>&gt;</span></span><br><span class="line">      ...</span><br><span class="line">      <span class="tag">&lt;<span class="name">ElementManifest</span> <span class="attr">Location</span>=<span class="string">&quot;MyList\Elements.xml&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">ApplyElementManifests</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">VersionRange</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">UpgradeActions</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>And it works. Hope it’s helpful.</p>
<p>Reference:</p>
<ul>
<li><a href="http://msdn.microsoft.com/en-us/library/office/dn265911(v=office.15).aspx">How to: Update app web components in SharePoint 2013</a></li>
</ul>
]]></content>
      <tags>
        <tag>SharePoint Add-in</tag>
      </tags>
  </entry>
  <entry>
    <title>You can only pass integers as parameters to resize SharePoint Add-in Client Web Part</title>
    <url>/2016/06/16/you-can-only-pass-integers-as-parameters-to-resize-sharepoint-add-in-client-web-part/</url>
    <content><![CDATA[<p>I tried to resize a Client Web Part with non integers as size, but it failed. And that’s why:</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line"><span class="keyword">var</span> regex = <span class="built_in">RegExp</span>(<span class="regexp">/(&lt;\s*[Mm]essage\s+[Ss]ender[Ii]d\s*=\s*([\dAaBbCcDdEdFf]&#123;8&#125;)(\d&#123;1,3&#125;)\s*&gt;[Rr]esize\s*\(\s*(\s*(\d*)\s*([^,\)\s\d]*)\s*,\s*(\d*)\s*([^,\)\s\d]*))?\s*\)\s*&lt;\/\s*[Mm]essage\s*&gt;)/</span>);</span><br><span class="line"><span class="keyword">var</span> results = regex.exec(e.data);</span><br><span class="line"><span class="keyword">if</span> (results == <span class="literal">null</span>)</span><br><span class="line">    <span class="keyword">return</span>;</span><br></pre></td></tr></table></figure>

<p>The regular expression shows that it doesn’t allow float numbers.</p>
]]></content>
      <tags>
        <tag>SharePoint Add-in</tag>
      </tags>
  </entry>
  <entry>
    <title>How to get access to other drives in Ubuntu on Windows 10</title>
    <url>/2018/12/02/how-to-get-access-to-other-drives-in-ubuntu-on-windows/</url>
    <content><![CDATA[<p>Run <code>cd /mnt/xx</code>, where <code>xx</code> is the drive name.</p>
<p>Reference:</p>
<ul>
<li><a href="https://superuser.com/questions/1118546/how-do-i-change-drive-with-bash-on-windows">How do I change Drive with bash on windows?</a></li>
</ul>
]]></content>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在 Gradle 的测试中显示详尽的错误信息</title>
    <url>/2019/02/02/how-to-show-more-information-about-failed-tests-in-gradle/</url>
    <content><![CDATA[<p>在<code>build.gradle</code>中添加如下设置：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">test</span> &#123;</span><br><span class="line">    testLogging &#123;</span><br><span class="line">        exceptionFormat = <span class="string">&#x27;full&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="http://mrhaki.blogspot.com/2013/05/gradle-goodness-show-more-information.html">Gradle Goodness: Show More Information About Failed Tests</a></li>
</ul>
]]></content>
      <tags>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title>VS Code remote development tool error - An SSH installation couldn&#39;t be found</title>
    <url>/2019/08/08/ssh-installation-couldnot-be-found-error-when-running-remote-ssh-in-vscode/</url>
    <content><![CDATA[<p>I ran into an error when running <code>Remote - SSH</code> in Visual Studio Code on Windows. The error shows that an SSH installation couldn’t be found, but I’ve installed the git client. Finally I found some useful info in the doc:</p>
<blockquote>
<p>VS Code will look for the <code>ssh</code> command in the PATH. Failing that, on Windows it will attempt to find <code>ssh.exe</code> in the default Git for Windows install path. You can also specifically tell VS Code where to find the SSH client by adding the <code>remote.SSH.path</code> property to <code>settings.json</code>.</p>
</blockquote>
<p>My git client was not installed in the default path, thus VS Code couldn’t find the <code>ssh</code> command. So I added the <code>remote.SSH.path</code> property to <code>settings.json</code> and problem solved.</p>
<p>Reference:</p>
<ul>
<li><a href="https://code.visualstudio.com/docs/remote/troubleshooting#_installing-a-supported-ssh-client">Installing a supported SSH client</a></li>
</ul>
]]></content>
      <tags>
        <tag>Visual Studio Code</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在 FileLocator Pro 中排除子文件夹</title>
    <url>/2019/02/26/how-to-exclude-sub-folder-in-filelocator-pro/</url>
    <content><![CDATA[<p>在搜索路径后加上 <code>-yourFolderName</code>，文件夹间以 <code>;</code> 分隔。</p>
<p>参考：</p>
<ul>
<li><a href="https://qa.mythicsoft.com/13603/there-tell-agent-ransack-ignore-particular-subfolder-search">Is there a way to tell Agent Ransack to ignore a particular subfolder in the path of its search?</a></li>
</ul>
]]></content>
      <tags>
        <tag>FileLocator Pro</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么 Integer.valueOf(127) == Integer.valueOf(127) 为 True</title>
    <url>/2019/11/16/why-Integer.valueOf(127)-==-Integer.valueOf(127)-is-true/</url>
    <content><![CDATA[<p><code>Integer</code> 类的内部维护了一个 <code>IntegerCache</code> 的静态类，默认缓存了-128到127的 <code>Integer</code> 对象，而 <code>java.lang.Integer#valueOf(int)</code> 方法执行时会判断参数是否在-128到127之间，如果在这个区间，则返回 <code>IntegerCache</code> 内部的缓存对象，所以 <code>Integer.valueOf(127) == Integer.valueOf(127)</code> 为 <code>True</code>。</p>
<p>不过，整型缓存只适用于自动装箱的情况，不适用于通过构造函数创建的 <code>Integer</code> 对象间的比较，在下述代码中，最终的输出结果是 <code>integer1 == integer2</code> 和 <code>integer3 != integer4</code>。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Integer integer1 = <span class="number">3</span>;</span><br><span class="line">Integer integer2 = <span class="number">3</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (integer1 == integer2) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;integer1 == integer2&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;integer1 != integer2&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">Integer integer3 = <span class="keyword">new</span> Integer(<span class="number">3</span>);</span><br><span class="line">Integer integer4 = <span class="keyword">new</span> Integer(<span class="number">3</span>);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (integer3 == integer4) &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;integer3 == integer4&quot;</span>);</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    System.out.println(<span class="string">&quot;integer3 != integer4&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>Integer integer1 = 3</code> 发生了自动装箱，编译器会将其等价转换为 <code>Integer integer1 = Integer.valueOf(3)</code>，所以 <code>integer1 == integer2</code>。而通过构造函数创建的 <code>Integer</code> 对象属于不同的对象，指向不同的内存地址，所以 <code>integer3 != integer4</code>。</p>
<p>另外，可以通过增加虚拟机的参数 <code>-XX:AutoBoxCacheMax=size</code> 来设置整型缓存的最大值，如 <code>-XX:AutoBoxCacheMax=500</code> 表示-128到500的整型会被缓存。</p>
<p>参考：</p>
<ul>
<li><a href="https://medium.com/@njnareshjoshi/java-integer-cache-why-integer-valueof-127-integer-valueof-127-is-true-e5076824a3d5">Java Integer Cache — Why Integer.valueOf(127) == Integer.valueOf(127) Is True</a></li>
<li><a href="https://javapapers.com/java/java-integer-cache/">Java Integer Cache</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>VS Code error - No source control providers registered</title>
    <url>/2019/11/24/vscode-no-source-control-providers-registered/</url>
    <content><![CDATA[<p>I opened a git repo by VS Code, but it shows <code>No source control providers registered</code>. One possible reason is that VS Code couldn’t find the executable git command, so we can set the executable path of git in settings. Open <code>File -&gt; Preferences -&gt; Settings</code>, then find the <code>Git: Path</code> setting, click <code>Edit in settings.json</code>, and add <code>&quot;git.path&quot;: &quot;full-path-to-git&quot;</code> to <code>settings.json</code>.</p>
<p>Reference:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/46609255/git-missing-in-vs-code-no-source-control-providers">Git missing in VS Code – No source control providers</a></li>
</ul>
]]></content>
      <tags>
        <tag>Visual Studio Code</tag>
      </tags>
  </entry>
  <entry>
    <title>How to enable word wrap in VS Code</title>
    <url>/2019/12/14/how-to-enable-word-wrap-in-vscode/</url>
    <content><![CDATA[<p>Open <code>File -&gt; Preferences -&gt; Settings</code>, then find the <code>Editor: Word Wrap</code> setting, and select the desired behaviour.</p>
<p>Reference:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/31025502/how-to-switch-word-wrap-on-and-off-in-vscode">How to switch word wrap on and off in VSCode?</a></li>
</ul>
]]></content>
      <tags>
        <tag>Visual Studio Code</tag>
      </tags>
  </entry>
  <entry>
    <title>Vagrant 镜像下载加速</title>
    <url>/2019/12/18/vagrant-box-speed-up/</url>
    <content><![CDATA[<p>可以使用<a href="https://mirrors.tuna.tsinghua.edu.cn/">清华大学开源软件镜像站</a>上的镜像。例如需要下载 <code>Ubuntu 18</code> 的镜像，先在站内找到对应镜像的地址（例如：<code>https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/bionic/20191211/bionic-server-cloudimg-amd64-vagrant.box</code>），然后在终端执行 <code>vagrant box add 镜像的地址 --name ubuntu/bionic</code>，下载完成后即可执行 <code>vagrant init ubuntu/bionic</code> 等操作。</p>
<p>参考：</p>
<ul>
<li><a href="https://segmentfault.com/q/1010000011063709/a-1020000011064302">vagrant box国内有镜像地址可以下载吗？</a></li>
</ul>
]]></content>
      <tags>
        <tag>Vagrant</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在 TypeScript 中定义属性名未知的对象类型</title>
    <url>/2020/03/14/how-to-define-interface-with-unknown-property-names-in-typescript/</url>
    <content><![CDATA[<p>在某些场景下，我们会使用 <code>&#123;&#125;</code> 来存储某类对象的映射关系，例如车主和车子的映射关系可记为：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">&#x27;Alice&#x27;</span>: <span class="keyword">new</span> Car(),</span><br><span class="line">    <span class="string">&#x27;Bob&#x27;</span>: <span class="keyword">new</span> Car()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>而在 <code>TypeScript</code> 中声明这种对象的类型时遇到了问题：该对象的属性名是未知的，不过所有属性名对应的值的类型是确定的。这种情况下可以借助 <a href="https://www.typescriptlang.org/docs/handbook/interfaces.html#indexable-types">Indexable Types</a> 解决，以上述的例子为例：</p>
<figure class="highlight ts"><table><tr><td class="code"><pre><span class="line"><span class="keyword">interface</span> CarOwners &#123;</span><br><span class="line">    [key: <span class="built_in">string</span>]: Car;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> carOwners: CarOwners = &#123;</span><br><span class="line">    <span class="string">&#x27;Alice&#x27;</span>: <span class="keyword">new</span> Car(),</span><br><span class="line">    <span class="string">&#x27;Bob&#x27;</span>: <span class="keyword">new</span> Car()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://github.com/Microsoft/TypeScript/issues/7803">Type annotation for object with unknown properties but known property types?</a></li>
</ul>
]]></content>
      <tags>
        <tag>TypeScript</tag>
      </tags>
  </entry>
  <entry>
    <title>如何解决“Waiting for another flutter command to release the startup lock...”</title>
    <url>/2020/03/14/how-to-fix-waiting-for-another-flutter-command-to-release-the-startup-lock/</url>
    <content><![CDATA[<p>执行 <code>Flutter</code> 包管理相关命令时有可能遇到 <code>Waiting for another flutter command to release the startup lock...</code> 这样的错误，可尝试杀死所有的 <code>dart</code> 进程解决：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">// Linux</span><br><span class="line">killall -9 dart</span><br><span class="line"></span><br><span class="line">// Windows</span><br><span class="line">taskkill /F /IM dart.exe</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/51679269/waiting-for-another-flutter-command-to-release-the-startup-lock">Waiting for another flutter command to release the startup lock</a></li>
</ul>
]]></content>
      <tags>
        <tag>Flutter</tag>
      </tags>
  </entry>
  <entry>
    <title>配置 Flutter 国内镜像</title>
    <url>/2020/03/15/how-to-config-flutter-to-use-a-mirror-site/</url>
    <content><![CDATA[<p>由于网络原因，<code>Flutter</code> 项目获取包依赖时有可能会失败，可通过设置镜像地址解决，新增如下两个环境变量即可：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PUB_HOSTED_URL=https://pub.flutter-io.cn</span><br><span class="line"><span class="built_in">export</span> FLUTTER_STORAGE_BASE_URL=https://storage.flutter-io.cn</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://flutter.dev/community/china#configuring-flutter-to-use-a-mirror-site">Configuring Flutter to use a mirror site</a></li>
</ul>
]]></content>
      <tags>
        <tag>Flutter</tag>
      </tags>
  </entry>
  <entry>
    <title>如何解决访问外部图片返回 403 Forbidden 错误</title>
    <url>/2020/03/16/how-to-fix-403-forbidden-on-image-urls/</url>
    <content><![CDATA[<p>在某个 <code>Web</code> 应用中，引用了 <code>豆瓣读书</code> 的图片，大部分图片会无法显示并返回 <code>403 Forbidden</code> 错误，一个可能的原因是触发了 <code>豆瓣</code> 的图片防盗链机制。</p>
<p>一般来说，防盗链机制会判断图片请求的 <code>Request Headers</code> 里的 <code>Referer</code> 字段的值是否是允许的地址，如果不是，则不允许访问相应的资源。所以，一种可能的解决办法是在 <code>HTML</code> 页面中设置 <code>Referrer-Policy</code> 为 <code>no-referrer</code>，在发送 <code>HTTP</code> 请求时不发送 <code>Referer</code> 信息：</p>
<figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">meta</span> <span class="attr">name</span>=<span class="string">&quot;referrer&quot;</span> <span class="attr">content</span>=<span class="string">&quot;no-referrer&quot;</span> /&gt;</span></span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/49433452/forbidden-403-on-image-urls">forbidden 403 on image URLS</a></li>
<li><a href="https://juejin.im/post/5cc50deff265da03a97af3e8">解决图片访问403 Forbidden问题</a></li>
</ul>
]]></content>
      <tags>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title>JaCoCo 配置 Maven 多模块覆盖率测试</title>
    <url>/2020/03/21/how-to-setup-jacoco-report-aggregation/</url>
    <content><![CDATA[<p>首先构建一个多模块的 <code>Maven</code> 项目，项目结构如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">├── product-service</span><br><span class="line">│   └── pom.xml</span><br><span class="line">├── sum-service</span><br><span class="line">│   └── pom.xml</span><br><span class="line">├── app</span><br><span class="line">│   └── pom.xml</span><br><span class="line">├── pom.xml</span><br></pre></td></tr></table></figure>

<p>其中 <code>product-service</code> 和 <code>sum-service</code> 表示功能代码，<code>app</code> 负责测试用例的整合。<code>product-service</code> 和 <code>sum-service</code> 分别包含一个 <code>ProductService</code> 类和 <code>SumService</code> 类，具体代码如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ProductService</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ProductService</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">product</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x * y;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">// SumService</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SumService</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> x, <span class="keyword">int</span> y)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x + y;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>app</code> 内的测试用例如下：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AppTest</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Test</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shouldCalculateCorrectSumAndProduct</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Assert.assertEquals(<span class="number">10</span>, <span class="keyword">new</span> ProductService().product(<span class="number">2</span>, <span class="number">5</span>));</span><br><span class="line">        Assert.assertEquals(<span class="number">5</span>, <span class="keyword">new</span> SumService().sum(<span class="number">2</span>, <span class="number">3</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后在 <code>root</code> 模块的 <code>pom.xml</code> 文件中配置 <code>JaCoCo</code> 插件：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.jacoco<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jacoco-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.8.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>prepare-agent<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>prepare-agent<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>最后在 <code>app</code> 模块的 <code>pom.xml</code> 文件中配置 <code>JaCoCo</code> 插件：</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">build</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">plugins</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-surefire-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.22.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">argLine</span>&gt;</span>$&#123;argLine&#125; -Xms256m -Xmx2048m<span class="tag">&lt;/<span class="name">argLine</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">forkCount</span>&gt;</span>1<span class="tag">&lt;/<span class="name">forkCount</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">runOrder</span>&gt;</span>random<span class="tag">&lt;/<span class="name">runOrder</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.jacoco<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jacoco-maven-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.8.5<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">id</span>&gt;</span>report-aggregate<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">phase</span>&gt;</span>test<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                        <span class="tag">&lt;<span class="name">goal</span>&gt;</span>report-aggregate<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">                    <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">plugins</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">build</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>此时在 <code>root</code> 模块下执行 <code>mvn test</code>，执行成功后在 <code>app/target/site/jacoco-aggregate</code> 目录下就会生成各个模块的覆盖测试报告：</p>
<p><img src="/images/jacoco-multiple-modules-demo.png" alt="alt"></p>
<p>完整的代码可参考 <a href="https://github.com/Frederick-S/jacoco-multiple-modules-demo">GitHub</a>。</p>
<p>参考：</p>
<ul>
<li><a href="https://prismoskills.appspot.com/lessons/Maven/Chapter_06_-_Jacoco_report_aggregation.jsp">Jacoco report aggregation for code coverage</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>JaCoCo</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>一些在线书籍（不定期更新）</title>
    <url>/2020/03/26/online-books/</url>
    <content><![CDATA[<h2 id="Math"><a href="#Math" class="headerlink" title="Math"></a>Math</h2><ul>
<li><a href="https://www.probabilitycourse.com/">Introduction to Probability, Statistics, and Random Processes</a></li>
<li><a href="http://textbooks.math.gatech.edu/ila/index.html">Interactive Linear Algebra</a></li>
<li><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a></li>
<li><a href="https://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/">Probabilistic Programming &amp; Bayesian Methods for Hackers</a></li>
<li><a href="https://people.math.wisc.edu/~keisler/calc.html">Elementary Calculus: An Infinitesimal Approach</a></li>
</ul>
<h2 id="Computer-Science"><a href="#Computer-Science" class="headerlink" title="Computer Science"></a>Computer Science</h2><ul>
<li><a href="https://www.cs.hmc.edu/twiki/bin/view/CSforAll/">CS for All</a></li>
<li><a href="http://infolab.stanford.edu/~ullman/focs.html">Foundations of Computer Science</a></li>
<li><a href="http://www.openbookproject.net/books/StudentCSP/">CS Principles: Big Ideas in Programming</a></li>
<li><a href="http://openbookproject.net/thinkcs/python/english3e/">How to Think Like a Computer Scientist</a></li>
<li><a href="https://www.bottomupcs.com/index.xhtml">Computer Science from the Bottom Up</a></li>
</ul>
<h2 id="Algorithm-amp-Data-Structures"><a href="#Algorithm-amp-Data-Structures" class="headerlink" title="Algorithm &amp; Data Structures"></a>Algorithm &amp; Data Structures</h2><ul>
<li><a href="http://jeffe.cs.illinois.edu/teaching/algorithms/">Algorithms</a></li>
<li><a href="http://www.openbookproject.net/books/pythonds/">Problem Solving with Algorithms and Data Structures using Python</a></li>
</ul>
<h2 id="Compiler-amp-Interpreter"><a href="#Compiler-amp-Interpreter" class="headerlink" title="Compiler &amp; Interpreter"></a>Compiler &amp; Interpreter</h2><ul>
<li><a href="http://craftinginterpreters.com/">Crafting Interpreters</a></li>
<li><a href="http://www.buildyourownlisp.com/">Build Your Own Lisp</a></li>
<li><a href="https://github.com/DoctorWkt/acwj">A Compiler Writing Journey</a></li>
<li><a href="https://c9x.me/compile/bib/">Resources for Amateur Compiler Writers</a></li>
</ul>
<h2 id="Operating-Systems"><a href="#Operating-Systems" class="headerlink" title="Operating Systems"></a>Operating Systems</h2><ul>
<li><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/">Operating Systems: Three Easy Pieces</a></li>
<li><a href="https://os.phil-opp.com/">Writing an OS in Rust</a></li>
<li><a href="http://greenteapress.com/thinkos/html/index.html">Think OS: A Brief Introduction to Operating Systems</a></li>
</ul>
<h2 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h2><ul>
<li><a href="http://webdam.inria.fr/Alice/">Foundations of Databases</a></li>
<li><a href="http://www.interdb.jp/pg/index.html">The Internals of PostgreSQL</a></li>
</ul>
<h2 id="Networking"><a href="#Networking" class="headerlink" title="Networking"></a>Networking</h2><ul>
<li><a href="http://www.tcpipguide.com/free/index.htm">The TCP/IP Guide</a></li>
<li><a href="https://book.systemsapproach.org/">Computer Networks: A Systems Approach</a></li>
</ul>
<h2 id="Linux"><a href="#Linux" class="headerlink" title="Linux"></a>Linux</h2><ul>
<li><a href="https://0xax.gitbooks.io/linux-insides/content/index.html">Linux Inside</a></li>
<li><a href="https://www.tldp.org/LDP/tlk/tlk.html">The Linux Kernel</a></li>
<li><a href="https://linux-kernel-labs.github.io/refs/heads/master/">Linux Kernel Teaching</a></li>
<li><a href="http://www.linuxfromscratch.org/lfs/view/stable/">Linux From Scratch</a></li>
<li><a href="http://linuxcommand.org/tlcl.php">The Linux Command Line</a></li>
<li><a href="http://cb.vu/unixtoolbox.xhtml">UNIX TOOLBOX</a></li>
</ul>
<h2 id="Programming"><a href="#Programming" class="headerlink" title="Programming"></a>Programming</h2><ul>
<li><a href="https://htdp.org/">How to Design Programs</a></li>
<li><a href="https://sarabander.github.io/sicp/html/index.xhtml">Structure and Interpretation of Computer Programs</a></li>
<li><a href="http://www.sicpdistilled.com/">SICP Distilled</a></li>
<li><a href="https://mostly-adequate.gitbooks.io/mostly-adequate-guide/">Mostly Adequate Guide to Functional Programming</a></li>
</ul>
<h2 id="Programming-Languages"><a href="#Programming-Languages" class="headerlink" title="Programming Languages"></a>Programming Languages</h2><h3 id="C"><a href="#C" class="headerlink" title="C"></a>C</h3><ul>
<li><a href="https://beej.us/guide/bgc/">Beej’s Guide to C Programming</a></li>
</ul>
<h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><ul>
<li><a href="https://wiki.sei.cmu.edu/confluence/display/java/SEI+CERT+Oracle+Coding+Standard+for+Java">SEI CERT Oracle Coding Standard for Java</a></li>
<li><a href="https://shipilev.net/jvm/anatomy-quarks/">JVM Anatomy Quarks</a></li>
</ul>
<h3 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript"></a>JavaScript</h3><ul>
<li><a href="https://eloquentjavascript.net/">Eloquent JavaScript</a></li>
<li><a href="http://speakingjs.com/">Speaking JavaScript: An In-Depth Guide for Programmers</a></li>
<li><a href="https://addyosmani.com/resources/essentialjsdesignpatterns/book/">Learning JavaScript Design Patterns</a></li>
<li><a href="https://javascript.info/">The Modern JavaScript Tutorial</a></li>
<li><a href="https://bonsaiden.github.io/JavaScript-Garden/">JavaScript Garden</a></li>
<li><a href="https://molily.de/robust-javascript/">Robust Client-Side JavaScript</a></li>
<li><a href="http://js4ds.org/">JavaScript for Data Science</a></li>
<li><a href="https://exploringjs.com/deep-js/toc.html">Deep JavaScript</a></li>
</ul>
<h3 id="TypeScript"><a href="#TypeScript" class="headerlink" title="TypeScript"></a>TypeScript</h3><ul>
<li><a href="https://basarat.gitbook.io/typescript/">TypeScript Deep Dive</a></li>
</ul>
<h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><ul>
<li><a href="https://docs.python-guide.org/">The Hitchhiker’s Guide to Python!</a></li>
<li><a href="http://book.pythontips.com/en/latest/">Intermediate Python</a></li>
<li><a href="https://www.fullstackpython.com/">Full Stack Python</a></li>
<li><a href="https://www.obeythetestinggoat.com/pages/book.html">Test-Driven Development with Python</a></li>
<li><a href="https://diveinto.org/python3/table-of-contents.html">Dive Into Python 3</a></li>
<li><a href="https://automatetheboringstuff.com/2e/">Automate the Boring Stuff with Python</a></li>
<li><a href="https://docs.quantifiedcode.com/python-anti-patterns/">The Little Book of Python Anti-Patterns</a></li>
</ul>
<h3 id="Clojure"><a href="#Clojure" class="headerlink" title="Clojure"></a>Clojure</h3><ul>
<li><a href="https://www.braveclojure.com/clojure-for-the-brave-and-true/">Clojure for the Brave and True</a></li>
</ul>
<h3 id="Ruby"><a href="#Ruby" class="headerlink" title="Ruby"></a>Ruby</h3><ul>
<li><a href="https://i-love-ruby.gitlab.io/">I Love Ruby</a></li>
<li><a href="https://www.railstutorial.org/book">Ruby on Rails Tutorial</a></li>
</ul>
<h3 id="Racket"><a href="#Racket" class="headerlink" title="Racket"></a>Racket</h3><ul>
<li><a href="https://beautifulracket.com/">Beautiful Racket</a></li>
</ul>
<h3 id="Rust"><a href="#Rust" class="headerlink" title="Rust"></a>Rust</h3><ul>
<li><a href="https://rust-unofficial.github.io/too-many-lists/index.html">Learn Rust With Entirely Too Many Linked Lists</a></li>
</ul>
<h3 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h3><ul>
<li><a href="https://dave.cheney.net/high-performance-go-workshop/dotgo-paris.html">High Performance Go Workshop</a></li>
<li><a href="https://go101.org/article/101.html">Go 101</a></li>
</ul>
<h3 id="OCaml"><a href="#OCaml" class="headerlink" title="OCaml"></a>OCaml</h3><ul>
<li><a href="https://www.cs.cornell.edu/courses/cs3110/2019sp/textbook/">Functional Programming in OCaml</a></li>
</ul>
<h3 id="Haskell"><a href="#Haskell" class="headerlink" title="Haskell"></a>Haskell</h3><ul>
<li><a href="http://dev.stephendiehl.com/hask/">What I Wish I Knew When Learning Haskell</a></li>
</ul>
<h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><ul>
<li><a href="https://redislabs.com/redis-in-action/">Redis in Action</a></li>
<li><a href="https://github.com/karlseguin/the-little-redis-book">The Little Redis Book</a></li>
</ul>
<h2 id="Git"><a href="#Git" class="headerlink" title="Git"></a>Git</h2><ul>
<li><a href="https://rogerdudler.github.io/git-guide/">git - the simple guide</a></li>
<li><a href="https://git-scm.com/book/en/v2">Pro Git</a></li>
<li><a href="http://www-cs-students.stanford.edu/~blynn/gitmagic/">Git Magic</a></li>
</ul>
<h2 id="German"><a href="#German" class="headerlink" title="German"></a>German</h2><ul>
<li><a href="https://courses.dcs.wisc.edu/wp/readinggerman/">A Foundation Course in Reading German</a></li>
</ul>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><ul>
<li><a href="https://www.aosabook.org/en/index.html">The Architecture of Open Source Applications</a></li>
<li><a href="https://mixmastamyk.bitbucket.io/pro_soft_dev/">Professional Software Development</a></li>
<li><a href="http://gee.cs.oswego.edu/dl/oosdw3/index.html">Object-Oriented System Development</a></li>
<li><a href="http://book.mixu.net/distsys/">Distributed systems for fun and profit</a></li>
<li><a href="https://hpbn.co/">High Performance Browser Networking</a></li>
<li><a href="https://97-things-every-x-should-know.gitbooks.io/97-things-every-programmer-should-know/content/en/">97 Things Every Programmer Should Know</a></li>
<li><a href="https://berb.github.io/diploma-thesis/community/index.html">Concurrent Programming for Scalable Web Architectures</a></li>
<li><a href="https://12factor.net/">The Twelve-Factor App</a></li>
<li><a href="https://dwheeler.com/secure-programs/Secure-Programs-HOWTO/index.html">Secure Programming HOWTO</a></li>
<li><a href="http://www.ibiblio.org/kuphaldt/electricCircuits/">Lessons In Electric Circuits</a></li>
<li><a href="https://toc.cryptobook.us/">A Graduate Course in Applied Cryptography</a></li>
<li><a href="http://imrannazar.com/GameBoy-Emulation-in-JavaScript">GameBoy Emulation in JavaScript</a></li>
<li><a href="https://www.learnlatex.org/en/">Learn LaTeX</a></li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>SSH 连接服务器时指定私钥的路径</title>
    <url>/2020/04/04/how-to-configure-ssh-key-path/</url>
    <content><![CDATA[<p>使用 <code>Visual Studio Code</code> 的 <code>Remote - SSH</code> 插件连接服务器开发时，有可能会遇到不同的服务器对应不同的私钥的情况，这时就需要单独为各个服务器指定私钥的位置。打开 <code>SSH</code> 配置文件（默认路径是 <code>~/.ssh/config</code>），在需要指定私钥路径的服务器下添加 <code>IdentityFile path-to-private-key</code> 即可，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Host your-host</span><br><span class="line">  HostName your-host-name</span><br><span class="line">  User your-host-user</span><br><span class="line">  ForwardAgent yes</span><br><span class="line">  IdentityFile path-to-private-key</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://superuser.com/questions/1276485/configure-ssh-key-path-to-use-for-a-specific-host">Configure ssh-key path to use for a specific host</a></li>
</ul>
]]></content>
      <tags>
        <tag>Visual Studio Code</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在 Dockerfile 中定义变量</title>
    <url>/2020/03/28/how-to-define-a-variable-in-dockerfile/</url>
    <content><![CDATA[<p>在某些场景下，编写 <code>Dockerfile</code> 时需要定义变量来避免重复出现的值，例如下面的例子中，<code>Gradle</code> 的版本号出现了三次，如果未来需要更新 <code>Gradle</code> 的版本号，则需要修改三次。</p>
<figure class="highlight docker"><table><tr><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> wget https://services.gradle.org/distributions/gradle-6.3-bin.zip</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> unzip gradle-6.3-bin.zip</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> gradle-6.3/bin/gradle task</span></span><br></pre></td></tr></table></figure>

<p>可以通过 <code>ARG variable-name=variable-value</code> 来定义一个变量，使用变量时通过 <code>$variable-name</code> 访问即可，对开头的例子使用变量修改后如下：</p>
<figure class="highlight docker"><table><tr><td class="code"><pre><span class="line"><span class="keyword">ARG</span> GRADLE_VERSION=<span class="number">6.3</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> wget https://services.gradle.org/distributions/gradle-<span class="variable">$GRADLE_VERSION</span>-bin.zip</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> unzip gradle-<span class="variable">$GRADLE_VERSION</span>-bin.zip</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> gradle-<span class="variable">$GRADLE_VERSION</span>/bin/gradle task</span></span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/33935807/how-to-define-a-variable-in-a-dockerfile">How to define a variable in a Dockerfile?</a></li>
</ul>
]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>在 Ubuntu 下使用 Puppeteer 时无法加载类库 libX11-xcb.so.1</title>
    <url>/2020/04/11/puppeteer-error-loading-libx11-xcb.so.1-on-ubuntu/</url>
    <content><![CDATA[<p>在 <code>Ubuntu</code> 下运行 <code>Puppeteer</code> 遇到了如下错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">error while loading shared libraries: libX11-xcb.so.1: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>

<p>需要安装以下依赖来解决：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt-get install gconf-service libxext6 libxfixes3 libxi6 libxrandr2 libxrender1 libcairo2 libcups2 libdbus-1-3 libexpat1 libfontconfig1 libgcc1 libgconf-2-4 libgdk-pixbuf2.0-0 libglib2.0-0 libgtk-3-0 libnspr4 libpango-1.0-0 libpangocairo-1.0-0 libstdc++6 libx11-6 libx11-xcb1 libxcb1 libxcomposite1 libxcursor1 libxdamage1 libxss1 libxtst6 libappindicator1 libnss3 libasound2 libatk1.0-0 libc6 ca-certificates fonts-liberation lsb-release xdg-utils wget</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://medium.com/@cloverinks/how-to-fix-puppetteer-error-ibx11-xcb-so-1-on-ubuntu-152c336368">How to fix puppetteer error ibX11-xcb.so.1 on Ubuntu</a></li>
</ul>
]]></content>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Puppeteer</tag>
      </tags>
  </entry>
  <entry>
    <title>.NET Core 覆盖率测试</title>
    <url>/2020/04/18/dotnet-core-test-coverage-demo/</url>
    <content><![CDATA[<h2 id="项目搭建"><a href="#项目搭建" class="headerlink" title="项目搭建"></a>项目搭建</h2><p>首先执行命令 <code>dotnet new classlib --name App</code> 来创建一个类库程序作为测试的对象，该类库只包含一个 <code>SumService</code> 类：</p>
<figure class="highlight cs"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> System;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> <span class="title">App</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">SumService</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="built_in">int</span> <span class="title">Sum</span>(<span class="params"><span class="built_in">int</span> a, <span class="built_in">int</span> b</span>)</span></span><br><span class="line"><span class="function"></span>        &#123;</span><br><span class="line">            <span class="keyword">return</span> a + b;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后创建一个基于 <code>xunit</code> 的单元测试项目来编写测试用例，并将 <code>App</code> 类库项目作为项目引用加入到 <code>App.Tests</code> 项目中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dotnet new xunit --name App.Tests</span><br><span class="line">dotnet add .\App.Tests\App.Tests.csproj reference .\App\App.csproj</span><br></pre></td></tr></table></figure>

<p>并编写一个测试用例 <code>SumServiceTest</code>：</p>
<figure class="highlight cs"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> System;</span><br><span class="line"><span class="keyword">using</span> Xunit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">namespace</span> <span class="title">App.Tests</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">class</span> <span class="title">SumServiceTest</span></span><br><span class="line">    &#123;</span><br><span class="line">        [<span class="meta">Fact</span>]</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">ShouldReturn5</span>(<span class="params"></span>)</span></span><br><span class="line"><span class="function"></span>        &#123;</span><br><span class="line">            Assert.Equal(<span class="number">5</span>, SumService.Sum(<span class="number">2</span>, <span class="number">3</span>));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>接着创建一个解决方案，并将 <code>App</code> 和 <code>App.Tests</code> 项目加入到该解决方案中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dotnet new sln --name App</span><br><span class="line">dotnet sln add .\App\App.csproj .\App.Tests\App.Tests.csproj</span><br></pre></td></tr></table></figure>

<p>最后项目结构如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">├── App</span><br><span class="line">│   └── App.csproj</span><br><span class="line">│   └── SumService.cs</span><br><span class="line">├── App.Tests</span><br><span class="line">│   └── App.Tests.csproj</span><br><span class="line">│   └── SumServiceTest.cs</span><br><span class="line">├── App.sln</span><br></pre></td></tr></table></figure>

<h2 id="覆盖率测试"><a href="#覆盖率测试" class="headerlink" title="覆盖率测试"></a>覆盖率测试</h2><p>覆盖率测试依赖 <code>coverlet</code>，在创建单元测试项目时已自动添加了该依赖，执行测试时添加 <code>coverlet</code> 相关的参数即可生成测试覆盖率报告：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dotnet test --collect:&quot;XPlat Code Coverage&quot;</span><br></pre></td></tr></table></figure>

<p>执行成功后会在 <code>App.Tests/TestResults/&#123;random-string&#125;</code> 目录下生成名为 <code>coverage.cobertura.xml</code> 的测试覆盖率报告。</p>
<p>但是，自动创建的单元测试项目默认添加的 <code>coverlet</code> 依赖是 <code>coverlet.collector</code>，目前还不支持在控制台中打印测试覆盖率报告：</p>
<blockquote>
<p>At the moment VSTest integration doesn’t support all features of msbuild and .NET tool, for instance show result on console, report merging and threshold validation. We’re working to fill the gaps.</p>
</blockquote>
<p>如果希望在控制台中打印测试覆盖率报告可将 <code>coverlet.collector</code> 依赖改为 <code>coverlet.msbuild</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dotnet remove .\App.Tests package coverlet.collector</span><br><span class="line">dotnet add .\App.Tests\ package coverlet.msbuild</span><br></pre></td></tr></table></figure>

<p>然后执行测试命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">dotnet test &#x2F;p:CollectCoverage&#x3D;true</span><br></pre></td></tr></table></figure>

<p>即可在控制台打印测试覆盖率报告：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Calculating coverage result...</span><br><span class="line">  Generating report &#39;D:\WorkSpace\dotnet-core-coverlet-msbuild-demo\App.Tests\coverage.json&#39;</span><br><span class="line"></span><br><span class="line">+--------+------+--------+--------+</span><br><span class="line">| Module | Line | Branch | Method |</span><br><span class="line">+--------+------+--------+--------+</span><br><span class="line">| App    | 100% | 100%   | 100%   |</span><br><span class="line">+--------+------+--------+--------+</span><br><span class="line"></span><br><span class="line">+---------+------+--------+--------+</span><br><span class="line">|         | Line | Branch | Method |</span><br><span class="line">+---------+------+--------+--------+</span><br><span class="line">| Total   | 100% | 100%   | 100%   |</span><br><span class="line">+---------+------+--------+--------+</span><br><span class="line">| Average | 100% | 100%   | 100%   |</span><br><span class="line">+---------+------+--------+--------+</span><br></pre></td></tr></table></figure>

<h2 id="集成-codecov"><a href="#集成-codecov" class="headerlink" title="集成 codecov"></a>集成 codecov</h2><h3 id="coverlet-msbuild"><a href="#coverlet-msbuild" class="headerlink" title="coverlet.msbuild"></a>coverlet.msbuild</h3><p>集成 <code>codecov</code> 需要指定测试覆盖率报告文件的路径，暂不支持 <code>coverlet.msbuild</code> 默认生成的 <code>json</code> 格式的文件，可以在执行测试时添加 <code>/p:CoverletOutputFormat=opencover</code> 参数来生成 <code>opencover</code> 格式的文件，相应的 <code>.appveyor.yml</code> 文件内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">image: Visual Studio 2019</span><br><span class="line">before_build:</span><br><span class="line">  - choco install codecov</span><br><span class="line">build_script:</span><br><span class="line">  - dotnet build</span><br><span class="line">test_script:</span><br><span class="line">  - dotnet test &#x2F;p:CollectCoverage&#x3D;true &#x2F;p:CoverletOutputFormat&#x3D;opencover</span><br><span class="line">  - codecov -f .&#x2F;App.Tests&#x2F;coverage.opencover.xml</span><br></pre></td></tr></table></figure>

<h3 id="coverlet-collector"><a href="#coverlet-collector" class="headerlink" title="coverlet.collector"></a>coverlet.collector</h3><p>使用 <code>coverlet.collector</code> 时每次生成的测试覆盖率报告所在的路径是随机的，所以需要将测试覆盖率报告复制到一个固定的路径中，可以使用如下的 <code>PowerShell</code> 脚本：</p>
<figure class="highlight ps"><table><tr><td class="code"><pre><span class="line"><span class="variable">$source</span> = <span class="string">&quot;./App.Tests/TestResults&quot;</span></span><br><span class="line"><span class="variable">$destination</span> = <span class="variable">$source</span></span><br><span class="line"><span class="variable">$filter</span> = <span class="string">&quot;coverage.cobertura.xml&quot;</span></span><br><span class="line"><span class="built_in">Get-ChildItem</span> <span class="literal">-Recurse</span> <span class="literal">-Path</span> <span class="variable">$source</span> | <span class="built_in">Where-Object</span> &#123; <span class="variable">$_</span>.Name <span class="operator">-match</span> <span class="variable">$filter</span> &#125; | <span class="built_in">Copy-Item</span> <span class="literal">-Destination</span> <span class="variable">$destination</span></span><br></pre></td></tr></table></figure>

<p>相应的 <code>.appveyor.yml</code> 文件内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">image: Visual Studio 2019</span><br><span class="line">before_build:</span><br><span class="line">  - choco install codecov</span><br><span class="line">build_script:</span><br><span class="line">  - dotnet build</span><br><span class="line">test_script:</span><br><span class="line">  - dotnet test --collect:&quot;XPlat Code Coverage&quot;</span><br><span class="line">  - ps: .&#x2F;FindCoverageFile.ps1</span><br><span class="line">  - codecov -f .&#x2F;App.Tests&#x2F;TestResults&#x2F;coverage.cobertura.xml</span><br></pre></td></tr></table></figure>

<p>完整的代码可参考 <a href="https://github.com/Frederick-S/dotnet-core-coverlet-msbuild-demo">dotnet-core-coverlet-msbuild-demo</a> 及 <a href="https://github.com/Frederick-S/dotnet-core-coverlet-collector-demo">dotnet-core-coverlet-collector-demo</a>。</p>
<p>参考：</p>
<ul>
<li><a href="https://codeburst.io/code-coverage-in-net-core-projects-c3d6536fd7d7?gi=4c835df2b1bf">Code Coverage in .NET Core Projects</a></li>
<li><a href="https://github.com/tonerdo/coverlet/blob/master/Documentation/VSTestIntegration.md">Coverlet integration with VSTest (a.k.a. Visual Studio Test Platform)</a></li>
<li><a href="https://github.com/codecov/codecov-exe">codecov-exe</a></li>
<li><a href="https://superuser.com/questions/149537/windows-file-copy-move-with-filename-regular-expressions">Windows: File copy/move with filename regular expressions?</a></li>
</ul>
]]></content>
      <tags>
        <tag>.NET Core</tag>
      </tags>
  </entry>
  <entry>
    <title>Flutter error - Building for iOS Simulator, but the linked and embedded framework &#39;App.framework&#39; was built for iOS</title>
    <url>/2020/05/04/flutter-error-linked-and-embedded-framework-app.framework-was-built-for-ios/</url>
    <content><![CDATA[<p><code>Flutter</code> 项目打包 <code>iOS</code> 应用的时候遇到个错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Building for iOS Simulator, but the linked and embedded framework &#39;App.framework&#39; was built for iOS. (in target &#39;Runner&#39; from project &#39;Runner&#39;)</span><br></pre></td></tr></table></figure>

<p>这个问题在 <code>Flutter</code> 的 <code>GitHub</code> 仓库中也有人提到，解决方法也比较简单，删除 <code>App.framework</code> 文件夹即可，即 <code>rm -rf ios/Flutter/App.framework</code>。</p>
<p>参考：</p>
<ul>
<li><a href="https://github.com/flutter/flutter/issues/50568">[App.framework] Linked and embedded framework ‘App.framework’ was built for iOS/iOS Simulator</a></li>
</ul>
]]></content>
      <tags>
        <tag>Flutter</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Travis CI 为 Flutter 项目打包 Android/iOS 应用</title>
    <url>/2020/05/02/how-to-build-flutter-app-for-android-and-ios-with-travisci/</url>
    <content><![CDATA[<h2 id="Travis-CI-构建"><a href="#Travis-CI-构建" class="headerlink" title="Travis CI 构建"></a>Travis CI 构建</h2><p><a href="https://medium.com/@yegorj/building-flutter-apks-and-ipas-on-travis-98d84d8e9b4">Building Flutter APKs and IPAs on Travis</a> 这篇文章详细介绍了如何在 Travis CI 上为 Flutter 项目打包 Android/iOS 应用，不过实际构建时存在几个问题，原文中的 <code>.travis.yml</code> 配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">matrix:</span><br><span class="line">  include:</span><br><span class="line">    - os: linux</span><br><span class="line">      language: android</span><br><span class="line">      licenses:</span><br><span class="line">        - &#39;android-sdk-preview-license-.+&#39;</span><br><span class="line">        - &#39;android-sdk-license-.+&#39;</span><br><span class="line">        - &#39;google-gdk-license-.+&#39;</span><br><span class="line">      android:</span><br><span class="line">        components:</span><br><span class="line">          - tools</span><br><span class="line">          - platform-tools</span><br><span class="line">          - build-tools-25.0.3</span><br><span class="line">          - android-25</span><br><span class="line">          - sys-img-armeabi-v7a-google_apis-25</span><br><span class="line">          - extra-android-m2repository</span><br><span class="line">          - extra-google-m2repository</span><br><span class="line">          - extra-google-android-support</span><br><span class="line">      jdk: oraclejdk8</span><br><span class="line">      sudo: false</span><br><span class="line">      addons:</span><br><span class="line">        apt:</span><br><span class="line">          # Flutter depends on &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libstdc++.so.6 version GLIBCXX_3.4.18</span><br><span class="line">          sources:</span><br><span class="line">            - ubuntu-toolchain-r-test # if we don&#39;t specify this, the libstdc++6 we get is the wrong version</span><br><span class="line">          packages:</span><br><span class="line">            - libstdc++6</span><br><span class="line">            - fonts-droid</span><br><span class="line">      before_script:</span><br><span class="line">        - wget http:&#x2F;&#x2F;services.gradle.org&#x2F;distributions&#x2F;gradle-3.5-bin.zip</span><br><span class="line">        - unzip -qq gradle-3.5-bin.zip</span><br><span class="line">        - export GRADLE_HOME&#x3D;$PWD&#x2F;gradle-3.5</span><br><span class="line">        - export PATH&#x3D;$GRADLE_HOME&#x2F;bin:$PATH</span><br><span class="line">        - git clone https:&#x2F;&#x2F;github.com&#x2F;flutter&#x2F;flutter.git -b alpha --depth 1</span><br><span class="line">      script:</span><br><span class="line">        - .&#x2F;flutter&#x2F;bin&#x2F;flutter -v build apk</span><br><span class="line"></span><br><span class="line">    - os: osx</span><br><span class="line">      language: generic</span><br><span class="line">      osx_image: xcode8.3</span><br><span class="line">      before_script:</span><br><span class="line">        - pip install six</span><br><span class="line">        - brew update</span><br><span class="line">        - brew install --HEAD libimobiledevice</span><br><span class="line">        - brew install ideviceinstaller</span><br><span class="line">        - brew install ios-deploy</span><br><span class="line">        - git clone https:&#x2F;&#x2F;github.com&#x2F;flutter&#x2F;flutter.git -b alpha --depth 1</span><br><span class="line">      script:</span><br><span class="line">        - .&#x2F;flutter&#x2F;bin&#x2F;flutter -v build ios --no-codesign</span><br><span class="line"></span><br><span class="line">cache:</span><br><span class="line">  directories:</span><br><span class="line">    - $HOME&#x2F;.pub-cache</span><br></pre></td></tr></table></figure>

<h3 id="Android"><a href="#Android" class="headerlink" title="Android"></a>Android</h3><h4 id="wget-403-Forbidden"><a href="#wget-403-Forbidden" class="headerlink" title="wget - 403 Forbidden"></a>wget - 403 Forbidden</h4><p>这个错误发生在执行 <code>wget http://services.gradle.org/distributions/gradle-3.5-bin.zip</code> 的时候，把 <code>gradle</code> 的下载路径替换成 <code>https</code> 即可。</p>
<h4 id="Remote-branch-alpha-not-found-in-upstream-origin"><a href="#Remote-branch-alpha-not-found-in-upstream-origin" class="headerlink" title="Remote branch alpha not found in upstream origin"></a>Remote branch alpha not found in upstream origin</h4><p>这个错误发生在下载 <code>Flutter</code> 代码的阶段，原文中的配置会下载 <code>Flutter</code> 的 <code>alpha</code> 分支代码，但是目前 <code>Flutter</code> 的仓库已经没有 <code>alpha</code> 分支，切换到 <code>stable</code> 分支即可，即：<code>git clone https://github.com/flutter/flutter.git -b stable --depth 1</code>。</p>
<h4 id="Failed-to-install-the-following-Android-SDK-packages-as-some-licences-have-not-been-accepted"><a href="#Failed-to-install-the-following-Android-SDK-packages-as-some-licences-have-not-been-accepted" class="headerlink" title="Failed to install the following Android SDK packages as some licences have not been accepted"></a>Failed to install the following Android SDK packages as some licences have not been accepted</h4><p>详细错误信息如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[        ] &gt; Failed to install the following Android SDK packages as some</span><br><span class="line"></span><br><span class="line">licences have not been accepted.</span><br><span class="line"></span><br><span class="line">[        ]      build-tools;28.0.3 Android SDK Build-Tools 28.0.3</span><br><span class="line"></span><br><span class="line">[        ]      platforms;android-29 Android SDK Platform 29</span><br><span class="line"></span><br><span class="line">[        ]   To build this project, accept the SDK license agreements and</span><br><span class="line"></span><br><span class="line">install the missing components using the Android Studio SDK Manager.</span><br></pre></td></tr></table></figure>

<p>这个错误是由于没有同意 <code>Android SDK</code> 的许可证协议，在 <code>before_script</code> 中加入如下配置即可：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">yes | sdkmanager &quot;platforms;android-29&quot;</span><br><span class="line">yes | sdkmanager &quot;build-tools;28.0.3&quot;</span><br></pre></td></tr></table></figure>

<h3 id="iOS"><a href="#iOS" class="headerlink" title="iOS"></a>iOS</h3><h4 id="pip-command-not-found"><a href="#pip-command-not-found" class="headerlink" title="pip: command not found"></a>pip: command not found</h4><p>这个错误在执行 <code>pip install six</code> 时遇到，经过实际验证构建 <code>iOS</code> 应用时并不需要此行配置，所以删掉即可。</p>
<h4 id="Xcode-11-0-or-greater-is-required-to-develop-for-iOS"><a href="#Xcode-11-0-or-greater-is-required-to-develop-for-iOS" class="headerlink" title="Xcode 11.0 or greater is required to develop for iOS"></a>Xcode 11.0 or greater is required to develop for iOS</h4><p>原文中的配置使用的是 <code>Xcode 8.3</code>，最后打包时会提示此错误，将 <code>osx_image</code> 设置为 <code>xcode11</code> 即可。</p>
<p>最后完整可用的 <code>.travis.yml</code> 配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">matrix:</span><br><span class="line">  include:</span><br><span class="line">    - os: linux</span><br><span class="line">      language: android</span><br><span class="line">      licenses:</span><br><span class="line">        - &#39;android-sdk-preview-license-.+&#39;</span><br><span class="line">        - &#39;android-sdk-license-.+&#39;</span><br><span class="line">        - &#39;google-gdk-license-.+&#39;</span><br><span class="line">      android:</span><br><span class="line">        components:</span><br><span class="line">          - tools</span><br><span class="line">          - platform-tools</span><br><span class="line">          - build-tools-25.0.3</span><br><span class="line">          - android-25</span><br><span class="line">          - sys-img-armeabi-v7a-google_apis-25</span><br><span class="line">          - extra-android-m2repository</span><br><span class="line">          - extra-google-m2repository</span><br><span class="line">          - extra-google-android-support</span><br><span class="line">      jdk: oraclejdk8</span><br><span class="line">      sudo: false</span><br><span class="line">      addons:</span><br><span class="line">        apt:</span><br><span class="line">          # Flutter depends on &#x2F;usr&#x2F;lib&#x2F;x86_64-linux-gnu&#x2F;libstdc++.so.6 version GLIBCXX_3.4.18</span><br><span class="line">          sources:</span><br><span class="line">            - ubuntu-toolchain-r-test # if we don&#39;t specify this, the libstdc++6 we get is the wrong version</span><br><span class="line">          packages:</span><br><span class="line">            - libstdc++6</span><br><span class="line">            - fonts-droid</span><br><span class="line">      before_script:</span><br><span class="line">        - wget https:&#x2F;&#x2F;services.gradle.org&#x2F;distributions&#x2F;gradle-3.5-bin.zip</span><br><span class="line">        - unzip -qq gradle-3.5-bin.zip</span><br><span class="line">        - export GRADLE_HOME&#x3D;$PWD&#x2F;gradle-3.5</span><br><span class="line">        - export PATH&#x3D;$GRADLE_HOME&#x2F;bin:$PATH</span><br><span class="line">        - git clone https:&#x2F;&#x2F;github.com&#x2F;flutter&#x2F;flutter.git -b stable --depth 1</span><br><span class="line">        - yes | sdkmanager &quot;platforms;android-29&quot;</span><br><span class="line">        - yes | sdkmanager &quot;build-tools;28.0.3&quot;</span><br><span class="line">      script:</span><br><span class="line">        - .&#x2F;flutter&#x2F;bin&#x2F;flutter -v build apk</span><br><span class="line"></span><br><span class="line">    - os: osx</span><br><span class="line">      language: generic</span><br><span class="line">      osx_image: xcode11</span><br><span class="line">      before_script:</span><br><span class="line">        - brew update</span><br><span class="line">        - brew install --HEAD libimobiledevice</span><br><span class="line">        - brew install ideviceinstaller</span><br><span class="line">        - brew install ios-deploy</span><br><span class="line">        - git clone https:&#x2F;&#x2F;github.com&#x2F;flutter&#x2F;flutter.git -b stable --depth 1</span><br><span class="line">      script:</span><br><span class="line">        - .&#x2F;flutter&#x2F;bin&#x2F;flutter -v build ios --no-codesign</span><br><span class="line"></span><br><span class="line">cache:</span><br><span class="line">  directories:</span><br><span class="line">    - $HOME&#x2F;.pub-cache</span><br></pre></td></tr></table></figure>

<p>完整的代码可参考 <a href="https://github.com/Frederick-S/flutter-travis-build-demo">flutter-travis-build-demo</a>。</p>
<h2 id="Codemagic"><a href="#Codemagic" class="headerlink" title="Codemagic"></a>Codemagic</h2><p>最后推荐 <a href="https://codemagic.io/">Codemagic</a> 这个服务，提供云端打包 <code>Flutter</code> 应用的功能，省去了 <code>Travis CI</code> 配置的步骤，免费用户每月有500分钟的额度来执行构建。</p>
<p>参考：</p>
<ul>
<li><a href="https://medium.com/@yegorj/building-flutter-apks-and-ipas-on-travis-98d84d8e9b4">Building Flutter APKs and IPAs on Travis</a></li>
<li><a href="https://stackoverflow.com/questions/54273412/failed-to-install-the-following-android-sdk-packages-as-some-licences-have-not-b">Failed to install the following Android SDK packages as some licences have not been accepted in jitpack</a></li>
</ul>
]]></content>
      <tags>
        <tag>Flutter</tag>
      </tags>
  </entry>
  <entry>
    <title>野生 NHK NEWS EASY 客户端</title>
    <url>/2020/05/06/unofficial-client-for-nhk-news-web-easy/</url>
    <content><![CDATA[<p>野生 NHK NEWS EASY 客户端，无广告，功能还比较单一，只上了 <code>Google Play</code>，<code>iOS</code> 没有通过：</p>
<ul>
<li><a href="https://play.google.com/store/apps/details?id=nhk.nhk_easy">Google Play</a></li>
<li><a href="https://github.com/Frederick-S/nhk-easy-mobile">GitHub</a></li>
</ul>
<p><img src="/images/nhk-1.png" alt="alt"></p>
<p><img src="/images/nhk-2.png" alt="alt"></p>
]]></content>
  </entry>
  <entry>
    <title>【分享】隐私政策生成器</title>
    <url>/2020/05/04/share-privacy-policy-generator/</url>
    <content><![CDATA[<p>对于发布到 <code>Google Play</code> 或者 <code>App Store</code> 的应用，需要提供一份隐私政策的说明，如果不知道怎么写的话推荐一个在线的网站来自动生成隐私政策。通过 <a href="https://app-privacy-policy-generator.firebaseapp.com/">App Privacy Policy Generator</a> 只需填写一些关键信息即可生成一份隐私政策说明，最终效果如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">**Privacy Policy**</span><br><span class="line"></span><br><span class="line">Awesome developer built the My awesome app app as an Open Source app. This SERVICE is provided by Awesome developer at no cost and is intended for use as is.</span><br><span class="line"></span><br><span class="line">This page is used to inform visitors regarding my policies with the collection, use, and disclosure of Personal Information if anyone decided to use my Service.</span><br><span class="line"></span><br><span class="line">If you choose to use my Service, then you agree to the collection and use of information in relation to this policy. The Personal Information that I collect is used for providing and improving the Service. I will not use or share your information with anyone except as described in this Privacy Policy.</span><br><span class="line"></span><br><span class="line">The terms used in this Privacy Policy have the same meanings as in our Terms and Conditions, which is accessible at My awesome app unless otherwise defined in this Privacy Policy.</span><br><span class="line"></span><br><span class="line">**Information Collection and Use**</span><br><span class="line"></span><br><span class="line">For a better experience, while using our Service, I may require you to provide us with certain personally identifiable information, including but not limited to ip. The information that I request will be retained on your device and is not collected by me in any way.</span><br><span class="line"></span><br><span class="line">The app does use third party services that may collect information used to identify you.</span><br><span class="line"></span><br><span class="line">Link to privacy policy of third party service providers used by the app</span><br><span class="line"></span><br><span class="line">*   [Google Play Services](https:&#x2F;&#x2F;www.google.com&#x2F;policies&#x2F;privacy&#x2F;)</span><br><span class="line"></span><br><span class="line">**Log Data**</span><br><span class="line"></span><br><span class="line">I want to inform you that whenever you use my Service, in a case of an error in the app I collect data and information (through third party products) on your phone called Log Data. This Log Data may include information such as your device Internet Protocol (“IP”) address, device name, operating system version, the configuration of the app when utilizing my Service, the time and date of your use of the Service, and other statistics.</span><br><span class="line"></span><br><span class="line">**Cookies**</span><br><span class="line"></span><br><span class="line">Cookies are files with a small amount of data that are commonly used as anonymous unique identifiers. These are sent to your browser from the websites that you visit and are stored on your device&#39;s internal memory.</span><br><span class="line"></span><br><span class="line">This Service does not use these “cookies” explicitly. However, the app may use third party code and libraries that use “cookies” to collect information and improve their services. You have the option to either accept or refuse these cookies and know when a cookie is being sent to your device. If you choose to refuse our cookies, you may not be able to use some portions of this Service.</span><br><span class="line"></span><br><span class="line">**Service Providers**</span><br><span class="line"></span><br><span class="line">I may employ third-party companies and individuals due to the following reasons:</span><br><span class="line"></span><br><span class="line">*   To facilitate our Service;</span><br><span class="line">*   To provide the Service on our behalf;</span><br><span class="line">*   To perform Service-related services; or</span><br><span class="line">*   To assist us in analyzing how our Service is used.</span><br><span class="line"></span><br><span class="line">I want to inform users of this Service that these third parties have access to your Personal Information. The reason is to perform the tasks assigned to them on our behalf. However, they are obligated not to disclose or use the information for any other purpose.</span><br><span class="line"></span><br><span class="line">**Security**</span><br><span class="line"></span><br><span class="line">I value your trust in providing us your Personal Information, thus we are striving to use commercially acceptable means of protecting it. But remember that no method of transmission over the internet, or method of electronic storage is 100% secure and reliable, and I cannot guarantee its absolute security.</span><br><span class="line"></span><br><span class="line">**Links to Other Sites**</span><br><span class="line"></span><br><span class="line">This Service may contain links to other sites. If you click on a third-party link, you will be directed to that site. Note that these external sites are not operated by me. Therefore, I strongly advise you to review the Privacy Policy of these websites. I have no control over and assume no responsibility for the content, privacy policies, or practices of any third-party sites or services.</span><br><span class="line"></span><br><span class="line">**Children’s Privacy**</span><br><span class="line"></span><br><span class="line">These Services do not address anyone under the age of 13. I do not knowingly collect personally identifiable information from children under 13\. In the case I discover that a child under 13 has provided me with personal information, I immediately delete this from our servers. If you are a parent or guardian and you are aware that your child has provided us with personal information, please contact me so that I will be able to do necessary actions.</span><br><span class="line"></span><br><span class="line">**Changes to This Privacy Policy**</span><br><span class="line"></span><br><span class="line">I may update our Privacy Policy from time to time. Thus, you are advised to review this page periodically for any changes. I will notify you of any changes by posting the new Privacy Policy on this page.</span><br><span class="line"></span><br><span class="line">This policy is effective as of 2020-05-04</span><br><span class="line"></span><br><span class="line">**Contact Us**</span><br><span class="line"></span><br><span class="line">If you have any questions or suggestions about my Privacy Policy, do not hesitate to contact me at dev@example.com.</span><br><span class="line"></span><br><span class="line">This privacy policy page was created at [privacypolicytemplate.net](https:&#x2F;&#x2F;privacypolicytemplate.net) and modified&#x2F;generated by [App Privacy Policy Generator](https:&#x2F;&#x2F;app-privacy-policy-generator.firebaseapp.com&#x2F;)</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>An enum switch case label must be the unqualified name of an enumeration constant</title>
    <url>/2020/07/18/an-enum-switch-case-label-must-be-the-unqualified-name-of-an-enumeration-constant/</url>
    <content><![CDATA[<p><code>An enum switch case label must be the unqualified name of an enumeration constant</code> 是 <code>Java</code> 中常见的编译错误，基本上 <code>Google</code> 搜索出来的错误场景都是因为在 <code>switch</code> 中使用枚举时搭配了类名造成，例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Season season = Season.SPRING;</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> (season) &#123;</span><br><span class="line">    <span class="comment">// 编译错误，直接使用 SPRING 即可</span></span><br><span class="line">    <span class="keyword">case</span> Season.SPRING:</span><br><span class="line">        System.out.println(<span class="string">&quot;spring&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> Season.SUMMER:</span><br><span class="line">        System.out.println(<span class="string">&quot;summer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然而，如果某个枚举值不存在，也会提示一样的错误，例如：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Season season = Season.SPRING;</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> (season) &#123;</span><br><span class="line">    <span class="keyword">case</span> SOME_VALUE_DOES_NOT_EXIST:</span><br><span class="line">        System.out.println(<span class="string">&quot;spring&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这种情况下的错误提示容易让人摸不着头脑，<code>IntelliJ IDEA</code> 的错误提示则较为友好：<code>Cannot resolve symbol &#39;SOME_VALUE_DOES_NOT_EXIST&#39;</code>。对于这种错误场景，实际工作中遇到一个例子：</p>
<ol>
<li>在开发阶段，<code>A</code> 拉了个 <code>some.package</code> 的分支，更新版本号为 <code>a.b-SNAPSHOT</code> 并发布，将其引入 <code>some.app</code>，推送代码后触发了 <code>some.app</code> 的 <code>Jenkins</code> 构建任务</li>
<li><code>B</code> 也拉了个 <code>some.package</code> 的分支，同样更新版本号为 <code>a.b-SNAPSHOT</code> 并发布，并增加了一个新的枚举值到 <code>SomeEnum</code>，同样将其引入 <code>some.app</code>，推送代码后触发了 <code>some.app</code> 的 <code>Jenkins</code> 构建任务，此时任务构建失败，提示编译错误：<code>An enum switch case label must be the unqualified name of an enumeration constant</code></li>
</ol>
<p>出现这样的原因是 <code>Jenkins</code> 执行构建任务时执行的编译命令是 <code>mvn compile</code>，在 <code>A</code> 提交任务时，构建服务器下载了 <code>some.package</code> 的 <code>a.b-SNAPSHOT</code> 版本，由于是 <code>SNAPSHOT</code> 版本，在 <code>B</code> 提交任务时，构建服务器没有重新下载 <code>some.package</code>，导致服务器中的 <code>some.package</code> 没有 <code>B</code> 新增的修改，从而出现编译错误，解决方法是在编译时增加 <code>-U</code> 参数来强制更新 <code>SNAPSHOT</code>。</p>
<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/54708788/error-an-enum-switch-case-label-must-be-the-unqualified-name-of-an-enumeration/54708876">error: an enum switch case label must be the unqualified name of an enumeration constant</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用 rsync 同步数据到其他服务器</title>
    <url>/2020/06/26/how-to-sync-data-to-remote-vps-with-rsync/</url>
    <content><![CDATA[<p>假设我们希望将 <code>server1</code> 下的 <code>/data1</code> 目录中的数据同步到 <code>server2</code> 下的 <code>/data2</code> 目录，首先需要建立 <code>server1</code> 和 <code>server2</code> 的免密登陆，在 <code>server1</code> 上执行 <code>ssh-keygen</code>，默认情况会在 <code>~/.ssh</code> 目录下生成 <code>id_rsa</code> 和 <code>id_rsa.pub</code> 两个文件，然后将 <code>~/.ssh/id_rsa.pub</code> 文件的内容复制到 <code>server2</code> 的 <code>~/.ssh/authorized_keys</code> 文件中即可。</p>
<p>接着，就可以使用 <code>rsync</code> 进行数据同步，具体命令为 <code>rsync -az --delete /data1/ server2-user@server2-ip:/data2</code>，其中 <code>-a</code> 表示递归同步 <code>/data1</code> 下的子文件夹及保留文件的权限、组、软连接等信息，如果不需要这些额外的文件信息而只想要递归同步可以使用 <code>-r</code> 来代替 <code>-a</code>；<code>-z</code> 表示开启文件压缩来减少网络传输；<code>--delete</code> 表示在 <code>/data1</code> 中删除的文件在 <code>/data2</code> 中也会同步删除。最后需要注意命令中 <code>/data1/</code> 末尾的 <code>/</code>，加了 <code>/</code> 表示将 <code>/data1</code> 下的所有文件同步到 <code>/data2</code>，没有 <code>/</code> 则表示将 <code>/data1</code> 这个文件夹同步到 <code>/data2</code> 下，假设 <code>/data1</code> 下有 <code>a</code>、<code>b</code>、<code>c</code> 三个文件，两种写法最后的同步区别为：</p>
<ul>
<li><code>/data1/</code>：<code>/data2/a,b,c</code></li>
<li><code>/data1</code>：<code>/data2/data1/a,b,c</code></li>
</ul>
<p>最后，我们需要将 <code>rsync</code> 加入到定时任务中进行自动备份。执行 <code>crontab -e</code>，将定时任务添加到文件中，如每小时执行一次：<code>0 * * * * rsync -az --delete /data1/ server2-user@server2-ip:/data2</code>。</p>
<p>参考：</p>
<ul>
<li><a href="https://www.digitalocean.com/community/tutorials/how-to-use-rsync-to-sync-local-and-remote-directories-on-a-vps">How To Use Rsync to Sync Local and Remote Directories on a VPS</a></li>
<li><a href="https://www.howtogeek.com/135533/how-to-use-rsync-to-backup-your-data-on-linux/">How to Use rsync to Backup Your Data on Linux</a></li>
</ul>
]]></content>
      <tags>
        <tag>rsync</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在 Finder 中显示隐藏文件</title>
    <url>/2020/07/26/how-to-show-hidden-files-in-mac-finder/</url>
    <content><![CDATA[<p><code>Finder</code> 默认并不显示隐藏文件，可以通过如下两种方式开启：</p>
<ol>
<li>在终端中输入 <code>defaults write com.apple.finder AppleShowAllFiles YES</code>，然后重启 <code>Finder</code></li>
<li>在 <code>Finder</code> 中使用快捷键 <code>Shift + Command + &quot;.&quot;</code></li>
</ol>
<p>参考：</p>
<ul>
<li><a href="https://apple.stackexchange.com/questions/250638/how-to-reveal-dot-files-in-finder">How to reveal dot files in finder?</a></li>
</ul>
]]></content>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title>如何解决 ModuleNotFoundError: No module named &#39;distutils.util&#39; 错误</title>
    <url>/2020/08/02/how-to-fix-no-module-named-distutils.util/</url>
    <content><![CDATA[<p><code>Ubuntu</code> 下安装 <code>pip</code> 时遇到 <code>ModuleNotFoundError: No module named &#39;distutils.util&#39;</code> 错误，执行以下命令即可：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt-get install python3-distutils</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://github.com/pypa/get-pip/issues/43">Issue with “python3 get-pip.py –user” with python 3.6.7</a></li>
</ul>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>如何解决 add-apt-repository: not found 错误</title>
    <url>/2020/08/01/how-to-fix-add-apt-repository-not-found-error/</url>
    <content><![CDATA[<p><code>Ubuntu</code> 下执行 <code>add-apt-repository</code> 添加第三方仓库时遇到 <code>add-apt-repository: not found</code> 错误，执行以下命令即可：</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install software-properties-common</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://phoenixnap.com/kb/add-apt-repository-command-not-found-ubuntu">How To Fix ‘Add-Apt-Repository Command Not Found’ On Ubuntu &amp; Debian</a></li>
</ul>
]]></content>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>如何减小 Docker 镜像的大小</title>
    <url>/2020/08/04/how-to-reduce-docker-image-size/</url>
    <content><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>首先来看一个例子，构建一个 <code>C</code> 语言版的 <code>hello world</code> 镜像：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* hello.c */</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">puts</span>(<span class="string">&quot;Hello, world!&quot;</span>);</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对应的 <code>Dockerfile</code> 为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM gcc</span><br><span class="line">COPY hello.c .</span><br><span class="line">RUN gcc -o hello hello.c</span><br><span class="line">CMD [&quot;.&#x2F;hello&quot;]</span><br></pre></td></tr></table></figure>

<p>然后执行 <code>docker build -t hello-world .</code> 构建一个名为 <code>hello-world</code> 的镜像，然而以这种方式构建的镜像的大小竟然有1.19 GB：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hello-world         latest              b11e170bd1d2        6 minutes ago       1.19GB</span><br></pre></td></tr></table></figure>

<p>因为这种构建方式生成的镜像会同时包含 <code>gcc</code> 镜像的内容，查看 <code>gcc</code> 镜像大小发现达到了1.19 GB：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">gcc                 latest              21f378ba43ec        11 days ago         1.19GB</span><br></pre></td></tr></table></figure>

<p>如果我们把基础镜像换成 <code>Ubuntu</code> 并安装 <code>gcc</code> 编译 <code>hello.c</code> 重新构建镜像，最后的镜像大小为213 MB：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">COPY hello.c .</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install gcc -y</span><br><span class="line">RUN gcc -o hello hello.c</span><br><span class="line">CMD [&quot;.&#x2F;hello&quot;]</span><br></pre></td></tr></table></figure>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED              SIZE</span><br><span class="line">hello-world         latest              42f17d1d12a5        About a minute ago   213MB</span><br></pre></td></tr></table></figure>

<p>虽然新镜像相比1.19 GB有大幅减少，但相比于 <code>hello-world</code> 程序本身的大小（17k）来说，213 MB依然是个庞大的数字：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ ls hello -hl</span><br><span class="line">-rwxr-xr-x 1 root root 17K Aug  4 13:54 hello</span><br></pre></td></tr></table></figure>

<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><h3 id="Multi-stage"><a href="#Multi-stage" class="headerlink" title="Multi-stage"></a>Multi-stage</h3><p>对于 <code>hello-world</code> 这个镜像来说，我们真正需要的只是最终的可执行程序，而并不关心中间的编译过程，如果能将编译阶段作为一个临时阶段而并不包含在最终的镜像中，则可有效减少最终的镜像大小。针对此，<code>Docker</code> 在 17.05 版本开始提供了名为 <code>multi-stage</code> 构建的功能。我们将原来的 <code>Dockerfile</code> 稍作修改，将原来的编译阶段抽取为一个 <code>stage</code>，然后将编译好的可执行文件复制到最终的 <code>stage</code> 中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM gcc AS mybuildstage</span><br><span class="line">COPY hello.c .</span><br><span class="line">RUN gcc -o hello hello.c</span><br><span class="line">FROM ubuntu</span><br><span class="line">COPY --from&#x3D;mybuildstage hello .</span><br><span class="line">CMD [&quot;.&#x2F;hello&quot;]</span><br></pre></td></tr></table></figure>

<p>最终的镜像大小只有73.9 MB：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hello-world         latest              7dd2b51c53b2        7 minutes ago       73.9MB</span><br></pre></td></tr></table></figure>

<h3 id="FROM-scratch"><a href="#FROM-scratch" class="headerlink" title="FROM scratch"></a><code>FROM scratch</code></h3><p>在上一步中，我们使用 <code>Ubuntu</code> 作为基础镜像来运行 <code>hello-world</code>，相比于一个可执行程序，<code>Ubuntu</code> 依然过于庞大，有没有比 <code>Ubuntu</code> 更轻量的镜像呢？有，那就是 <code>scratch</code>，这表示一个空的镜像，继续将 <code>Dockerfile</code> 稍作修改：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM gcc AS mybuildstage</span><br><span class="line">COPY hello.c .</span><br><span class="line">RUN gcc -o hello hello.c</span><br><span class="line">FROM scratch</span><br><span class="line">COPY --from&#x3D;mybuildstage hello .</span><br><span class="line">CMD [&quot;.&#x2F;hello&quot;]</span><br></pre></td></tr></table></figure>

<p>最终的镜像大小只有16.4 KB：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hello-world         latest              676253b0e9c4        31 minutes ago      16.4kB</span><br></pre></td></tr></table></figure>

<p>不过在运行该镜像时却提示错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">standard_init_linux.go:211: exec user process caused &quot;no such file or directory&quot;</span><br></pre></td></tr></table></figure>

<p>这是因为这种方式构建出的镜像缺少 <code>hello-world</code> 运行时依赖的库。我们可以在编译 <code>hello-world</code> 时通过指定 <code>-static</code> 参数将依赖的库包含到最后的可执行文件中来解决这个问题：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM gcc AS mybuildstage</span><br><span class="line">COPY hello.c .</span><br><span class="line">RUN gcc -o hello hello.c -static</span><br><span class="line">FROM scratch</span><br><span class="line">COPY --from&#x3D;mybuildstage hello .</span><br><span class="line">CMD [&quot;.&#x2F;hello&quot;]</span><br></pre></td></tr></table></figure>

<p>不过包含了依赖的库后最终镜像的大小也上涨为945 KB：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hello-world         latest              e6a1fccc2de7        9 seconds ago       945kB</span><br></pre></td></tr></table></figure>

<p>另外，如果不想将依赖的库包含到最终的镜像中，可以使用 <code>busybox:glibc</code> 这个基础镜像，该镜像包含了 <code>C</code> 语言的标准库，有了这个镜像在编译 <code>hello-world</code> 时则无需指定 <code>-static</code> 参数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">FROM gcc AS mybuildstage</span><br><span class="line">COPY hello.c .</span><br><span class="line">RUN gcc -o hello hello.c</span><br><span class="line">FROM busybox:glibc</span><br><span class="line">COPY --from&#x3D;mybuildstage hello .</span><br><span class="line">CMD [&quot;.&#x2F;hello&quot;]</span><br></pre></td></tr></table></figure>

<p>不过由于该镜像本身有一定大小，最终镜像的大小达到了5.22 MB：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">hello-world         latest              e2f2c0544800        7 seconds ago       5.22MB</span><br></pre></td></tr></table></figure>

<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过 <code>multi-stage</code> 构建可以有效的减少 <code>Docker</code> 镜像的大小，而基础镜像的选择则要具体情况分析，在满足需求的情况下选择合理的基础镜像。</p>
<p>参考：</p>
<ul>
<li><a href="https://www.ardanlabs.com/blog/2020/02/docker-images-part1-reducing-image-size.html">Docker Images : Part I - Reducing Image Size</a></li>
</ul>
]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用 JUnit 测试异步代码</title>
    <url>/2020/09/13/how-to-test-async-code-with-junit/</url>
    <content><![CDATA[<h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>对于以下的异步代码：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DemoService</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> CompletableFuture&lt;String&gt; <span class="title">hello</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> CompletableFuture.supplyAsync(() -&gt; <span class="string">&quot;hello&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们为其编写一个测试用例，并在 <code>CompletableFuture#whenComplete</code> 中判断返回值是否与预期相符，然而即使返回值与预期不符，该测试也不会抛出异常：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">exceptionWontBeCaptured</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    DemoService demoService = <span class="keyword">new</span> DemoService();</span><br><span class="line"></span><br><span class="line">    demoService.hello()</span><br><span class="line">            .whenComplete((result, e) -&gt; &#123;</span><br><span class="line">                Assert.assertEquals(<span class="string">&quot;wrongValue&quot;</span>, result);</span><br><span class="line">            &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><h3 id="CompletableFuture-get"><a href="#CompletableFuture-get" class="headerlink" title="CompletableFuture#get()"></a>CompletableFuture#get()</h3><p>我们可以借助 <code>CompletableFuture#get()</code> 阻塞主线程等待结果的特点，将异步代码转成同步：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">blockMainThreadByGet</span><span class="params">()</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">    DemoService demoService = <span class="keyword">new</span> DemoService();</span><br><span class="line"></span><br><span class="line">    Assert.assertEquals(<span class="string">&quot;hello&quot;</span>, demoService.hello().get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="CountDownLatch"><a href="#CountDownLatch" class="headerlink" title="CountDownLatch"></a>CountDownLatch</h3><p>上述方案依赖了一个具体的异步类方法，如果实际的异步类不提供相应的同步方法，上述方案则不适合。针对这种情况，可以借助 <code>CountDownLatch</code>，初始化一个计数为1的 <code>CountDownLatch</code> 的实例，在测试方法中调用 <code>CountDownLatch#await()</code> 方法进行等待，当异步方法执行成功后在其回调中调用 <code>CountDownLatch#countDown()</code> 使计数器减1变为0，从而继续执行后续的测试判断：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">waitOnCountDown</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    CountDownLatch countDownLatch = <span class="keyword">new</span> CountDownLatch(<span class="number">1</span>);</span><br><span class="line">    DemoService demoService = <span class="keyword">new</span> DemoService();</span><br><span class="line">    AtomicReference&lt;String&gt; actualValue = <span class="keyword">new</span> AtomicReference&lt;&gt;(<span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line">    demoService.hello()</span><br><span class="line">            .whenComplete((result, e) -&gt; &#123;</span><br><span class="line">                actualValue.set(result);</span><br><span class="line">                countDownLatch.countDown();</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">    countDownLatch.await();</span><br><span class="line"></span><br><span class="line">    Assert.assertEquals(<span class="string">&quot;hello&quot;</span>, actualValue.get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Awaitility"><a href="#Awaitility" class="headerlink" title="Awaitility"></a>Awaitility</h3><p><a href="https://github.com/awaitility/awaitility">Awaitility</a> 让测试异步代码变得简单明了：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">poweredByAwaitility</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    DemoService demoService = <span class="keyword">new</span> DemoService();</span><br><span class="line">    AtomicReference&lt;String&gt; actualValue = <span class="keyword">new</span> AtomicReference&lt;&gt;(<span class="string">&quot;&quot;</span>);</span><br><span class="line"></span><br><span class="line">    demoService.hello()</span><br><span class="line">            .whenComplete((result, e) -&gt; &#123;</span><br><span class="line">                actualValue.set(result);</span><br><span class="line">            &#125;);</span><br><span class="line"></span><br><span class="line">    await().atMost(<span class="number">5</span>, SECONDS).untilAsserted(() -&gt; &#123;</span><br><span class="line">        Assert.assertEquals(<span class="string">&quot;hello&quot;</span>, actualValue.get());</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>完整的代码可参考 <a href="https://github.com/Frederick-S/test-async-code-with-junit-demo">GitHub</a>。</p>
<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/631598/how-to-use-junit-to-test-asynchronous-processes">How to use JUnit to test asynchronous processes</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>JUnit</tag>
      </tags>
  </entry>
  <entry>
    <title>如何使用 JUnit 测试异常信息</title>
    <url>/2020/09/26/how-to-test-exception-message-with-junit/</url>
    <content><![CDATA[<p>假设有如下的 <code>SumService</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SumService</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">(<span class="keyword">int</span> a, <span class="keyword">int</span> b)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (a &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;a must be positive&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (b &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;b must be positive&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> a + b;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当 <code>a</code> 或者 <code>b</code> 非正数时会抛出 <code>IllegalArgumentException</code> 异常，由于两者抛出的是同一个异常，所以无法直接使用 <code>expected = IllegalArgumentException.class</code> 进行区分测试，故需要测试具体的异常信息。</p>
<h2 id="使用-try-catch"><a href="#使用-try-catch" class="headerlink" title="使用 try/catch"></a>使用 try/catch</h2><p>用一个 <code>try/catch</code> 包裹测试的方法，判断抛出的异常信息：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shouldAssertExceptionMessageByAssertThrows</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    IllegalArgumentException illegalArgumentException = </span><br><span class="line">            Assert.assertThrows(IllegalArgumentException.class, () -&gt; SumService.sum(<span class="number">0</span>, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">    Assert.assertEquals(<span class="string">&quot;a must be positive&quot;</span>, illegalArgumentException.getMessage());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="使用-assertThrows"><a href="#使用-assertThrows" class="headerlink" title="使用 assertThrows"></a>使用 assertThrows</h2><p>借助 <code>Assert.assertThrows</code> 执行测试方法返回一个异常，然后判断返回的异常信息：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shouldAssertExceptionMessageByAssertThrows</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    IllegalArgumentException illegalArgumentException = Assert.assertThrows(IllegalArgumentException.class, () -&gt; SumService.sum(<span class="number">0</span>, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">    Assert.assertEquals(<span class="string">&quot;a must be positive&quot;</span>, illegalArgumentException.getMessage());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="使用-ExpectedException"><a href="#使用-ExpectedException" class="headerlink" title="使用 ExpectedException"></a>使用 ExpectedException</h2><p>借助 <code>ExpectedException</code> 预先设定预期抛出的异常和异常信息，然后执行测试方法：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Rule</span></span><br><span class="line"><span class="keyword">public</span> ExpectedException expectedException = ExpectedException.none();</span><br><span class="line"></span><br><span class="line"><span class="meta">@Test</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shouldAssertExceptionMessageByRule</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    expectedException.expect(IllegalArgumentException.class);</span><br><span class="line">    expectedException.expectMessage(<span class="string">&quot;a must be positive&quot;</span>);</span><br><span class="line"></span><br><span class="line">    SumService.sum(<span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>完整的代码可参考 <a href="https://github.com/Frederick-S/test-exception-message-with-junit-demo">GitHub</a>。</p>
<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/2469911/how-do-i-assert-my-exception-message-with-junit-test-annotation">How do I assert my exception message with JUnit Test annotation?</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>JUnit</tag>
      </tags>
  </entry>
  <entry>
    <title>如何修改 AppVeyor 的 JDK 版本</title>
    <url>/2020/10/24/how-to-change-jdk-version-in-appveyor/</url>
    <content><![CDATA[<p>使用 <code>AppVeyor</code> 的<code>Visual Studio 2019</code> 镜像构建 <code>Java</code> 项目时默认使用的是 <code>JDK 1.8</code>（<a href="https://www.appveyor.com/docs/windows-images-software/#java">这里</a>说明了 <code>AppVeyor</code> 各个镜像下默认使用的 <code>JDK</code> 版本，虽然表格里写着 <code>Visual Studio 2019</code> 镜像下的默认 <code>JDK</code> 是1.7，不过实际是1.8），如果想更换 <code>JDK</code> 版本，比如更换为 <code>JDK 11</code>，可以重新设置 <code>JAVA_HOME</code> 和 <code>PATH</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">before_test:</span><br><span class="line">  - SET JAVA_HOME&#x3D;C:\Program Files\Java\jdk11</span><br><span class="line">  - SET PATH&#x3D;%JAVA_HOME%\bin;%PATH%</span><br></pre></td></tr></table></figure>

<p>完整的代码可参考 <a href="https://github.com/Frederick-S/appveyor-jdk11-demo">GitHub</a>。</p>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>AppVeyor</tag>
      </tags>
  </entry>
  <entry>
    <title>如何在 JDK 11 中建立 jstatd 连接</title>
    <url>/2020/11/21/how-to-use-jstatd-with-jdk11/</url>
    <content><![CDATA[<p>使用 <code>VisualVM</code> 的 <code>Virsual GC</code> 插件需要先和服务器建立 <code>jstatd</code> 连接，在 <code>JDK 9</code> 之前需要首先创建一个 <code>policy</code> 文件并声明权限：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grant codebase &quot;file:$&#123;java.home&#125;&#x2F;lib&#x2F;tools.jar&quot; &#123;</span><br><span class="line">   permission java.security.AllPermission;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>然而，从 <code>JDK 9</code> 开始，<code>tools.jar</code> 已被移除，需要将 <code>policy</code> 文件的内容修改为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">grant codebase &quot;jrt:&#x2F;jdk.jstatd&quot; &#123;    </span><br><span class="line">   permission java.security.AllPermission;    </span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">grant codebase &quot;jrt:&#x2F;jdk.internal.jvmstat&quot; &#123;    </span><br><span class="line">   permission java.security.AllPermission;    </span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/51032095/starting-jstatd-in-java-9">Starting jstatd in Java 9+</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>VisualVM</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么1不是质数</title>
    <url>/2021/07/04/why-is-1-not-a-prime/</url>
    <content><![CDATA[<p>如果一个数除了1和它本身外，没有其他约数，我们称这个数为质数，但在这个定义下，1却不是质数。要回答这个问题需要先了解质数的作用，质数的主要作用在于构建欧几里得的算数基本定理：</p>
<blockquote>
<p>任何一个大于1的自然数都可以唯一分解成有限个质数的乘积。</p>
</blockquote>
<p>如果把1列为质数，就会破坏这种唯一性，因为在这种情况下每个自然数都有无限种分解方式，即在原有分解的基础上再乘以任意个数的1，所以1不作为质数。</p>
<p>参考：</p>
<ul>
<li><a href="https://math.stackexchange.com/questions/120/why-is-1-not-a-prime-number">Why is 1 not a prime number?</a></li>
<li><a href="https://primes.utm.edu/notes/faq/one.html">FAQ: Why is the number one not prime?</a></li>
</ul>
]]></content>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title>Permissions 0644 for &#39;xxx.pem&#39; are too open</title>
    <url>/2021/07/10/permissions-0644-for-xx-are-too-open/</url>
    <content><![CDATA[<p>使用 <code>SSH</code> 连接到 <code>Azure</code> 的虚拟机时遇到错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">➜  ~ ssh -i &#x2F;path&#x2F;to&#x2F;some.pem xxx@x.x.x.x</span><br><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">@         WARNING: UNPROTECTED PRIVATE KEY FILE!          @</span><br><span class="line">@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@</span><br><span class="line">Permissions 0644 for &#39;&#x2F;path&#x2F;to&#x2F;some.pem&#39; are too open.</span><br><span class="line">It is required that your private key files are NOT accessible by others.</span><br><span class="line">This private key will be ignored.</span><br><span class="line">Load key &quot;&#x2F;path&#x2F;to&#x2F;some.pem&quot;: bad permissions</span><br><span class="line">xxx@x.x.x.x: Permission denied (publickey).</span><br></pre></td></tr></table></figure>

<p>这是因为创建虚拟机时从 <code>Azure</code> 下载的私钥默认权限太大，需要将其权限改为只读且仅当前用户可见：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">chmod 400 some.pem</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/8193768/trying-to-ssh-into-an-amazon-ec2-instance-permission-error">Trying to SSH into an Amazon Ec2 instance - permission error</a></li>
</ul>
]]></content>
      <tags>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker 磁盘占用清理</title>
    <url>/2021/07/11/clean-up-docker/</url>
    <content><![CDATA[<p>日常随着 <code>Docker</code> 的使用，<code>Docker</code> 会逐渐占用磁盘空间，通过 <code>docker system df</code> 可查看 <code>Docker</code> 所占用的空间：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE</span><br><span class="line">Images          20        14        22.21GB   17.07GB (76%)</span><br><span class="line">Containers      29        0         6.743GB   6.743GB (100%)</span><br><span class="line">Local Volumes   2         0         417MB     417MB (100%)</span><br><span class="line">Build Cache     0         0         0B        0B</span><br></pre></td></tr></table></figure>

<p>其中 <code>Images</code> 表示镜像，<code>Containers</code> 表示容器，<code>Local Volumes</code> 表示本地卷，<code>Build Cache</code> 表示构建缓存。</p>
<h2 id="整体清理"><a href="#整体清理" class="headerlink" title="整体清理"></a>整体清理</h2><p>可以通过 <code>docker system prune</code> 进行一次空间清理：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">WARNING! This will remove:</span><br><span class="line">  - all stopped containers</span><br><span class="line">  - all networks not used by at least one container</span><br><span class="line">  - all dangling images</span><br><span class="line">  - all dangling build cache</span><br><span class="line"></span><br><span class="line">Are you sure you want to continue? [y&#x2F;N]</span><br></pre></td></tr></table></figure>

<p>该操作会删除所有停止的容器，所有未被至少一个容器使用的网络，所有的 <code>dangling</code> 镜像（在构建镜像时产生的 <code>tag</code> 为 <code>none</code> 的镜像，没有和任何其他有 <code>tag</code> 的镜像有关联），所有的 <code>dangling</code> 构建缓存（和 <code>dangling</code> 镜像同理）。</p>
<p>更激进一点，还可以执行 <code>docker system prune -a</code>，该操作还会删除没有和运行中的容器有关联的镜像。</p>
<h2 id="镜像清理"><a href="#镜像清理" class="headerlink" title="镜像清理"></a>镜像清理</h2><p><code>Docker</code> 镜像是某个应用（如数据库、某个程序语言的运行时）的磁盘快照，可以通过 <code>docker image ls -a</code> 查看所有的镜像（活跃的以及 <code>dangling</code> 的镜像）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REPOSITORY    TAG       IMAGE ID       CREATED        SIZE</span><br><span class="line">hello-world   latest    d1165f221234   4 months ago   13.3kB</span><br></pre></td></tr></table></figure>

<p>可以通过 <code>docker image rm &lt;name_or_id&gt;</code> 来删除某个镜像，支持批量删除多个镜像，多个镜像 <code>id</code> 之间使用空格分隔即可。不过，删除镜像要求该镜像没有被某个容器所使用，否则会提示下述类似错误：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Error response from daemon: conflict: unable to delete 4cdc5dd7eaad (must be forced) - image is being used by stopped container 3d9f62acc483</span><br><span class="line">Error response from daemon: conflict: unable to delete d1165f221234 (must be forced) - image is being used by stopped container 57027ba35bdd</span><br></pre></td></tr></table></figure>

<p>可以通过在执行时增加 <code>-f</code> 来强制删除镜像。</p>
<h2 id="容器清理"><a href="#容器清理" class="headerlink" title="容器清理"></a>容器清理</h2><p>容器是某个镜像的一个运行实例，可以通过 <code>docker container ls -a</code> 查看所有的容器：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CONTAINER ID   IMAGE          COMMAND                  CREATED          STATUS                      PORTS     NAMES</span><br><span class="line">3d9f62acc483   4cdc5dd7eaad   &quot;&#x2F;docker-entrypoint.…&quot;   11 minutes ago   Exited (0) 11 minutes ago             sleepy_babbage</span><br></pre></td></tr></table></figure>

<p>要删除一个容器必须要先停止该容器（<code>docker container stop &lt;name_or_id&gt;</code>），然后通过 <code>docker container rm &lt;name_or_id&gt;</code> 删除，同样的，和删除镜像类似，该命令支持批量删除多个容器，多个容器 <code>id</code> 之间使用空格分隔。</p>
<h2 id="网络清理"><a href="#网络清理" class="headerlink" title="网络清理"></a>网络清理</h2><p><code>Docker</code> 网络用于容器间的通信，它们都是一些配置文件，并不会占用多大空间，可以通过 <code>docker network ls</code> 查看所有的网络：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">NETWORK ID     NAME      DRIVER    SCOPE</span><br><span class="line">b96312481a51   bridge    bridge    local</span><br><span class="line">85a64f881d4d   host      host      local</span><br><span class="line">e6808b80f888   none      null      local</span><br></pre></td></tr></table></figure>

<p>可以通过 <code>docker network rm &lt;name_or_id&gt;</code> 来删除一个网络。</p>
<h2 id="数据卷清理"><a href="#数据卷清理" class="headerlink" title="数据卷清理"></a>数据卷清理</h2><p><code>Docker</code> 数据卷用于持久化容器运行时保存的数据，例如通过 <code>Docker</code> 运行 <code>MySQL</code> 时指定数据卷，从而对 <code>MySQL</code> 的数据进行备份，可以通过 <code>docker volume ls</code> 查看所有的数据卷：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">DRIVER    VOLUME NAME</span><br><span class="line">local     test-volume</span><br></pre></td></tr></table></figure>

<p>同样的，可以通过 <code>docker volume rm &lt;name&gt;</code> 来删除指定的数据卷，或者使用 <code>docker volume prune</code> 来删除所有未和运行中的容器关联的数据卷，以及通过 <code>docker volume prune -a</code> 删除所有的数据卷。</p>
<p>最后，<code>docker system prune -a --volumes</code> 是在 <code>docker system prune -a</code> 的基础上删除所有未使用的卷。</p>
<p>参考：</p>
<ul>
<li><a href="https://dockerwebdev.com/tutorials/clean-up-docker/">How to clean your Docker data</a></li>
<li><a href="https://jinnabalu.medium.com/docker-frequently-used-commands-on-images-b812d76a4b8e">Dangling or Unused Images in Docker</a></li>
</ul>
]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Python heapq 自定义比较器</title>
    <url>/2021/07/31/python-heapq-custom-comparator/</url>
    <content><![CDATA[<p>使用 <code>Python</code> 的 <code>heapq</code> 模块时，如果处理的是较为复杂的数据结构，则需要实现自定义比较器来比较两个元素的大小。</p>
<h2 id="使用元组"><a href="#使用元组" class="headerlink" title="使用元组"></a>使用元组</h2><p>如果 <code>heapq</code> 中放入的是元组，那么元组的第一个元素会用于大小比较。假设有这样一个问题，给定一个数组，返回前 <code>k</code> 小的数字所在数组中的位置。<code>Top k</code> 的问题的一个解法是使用堆，但是这里要求的是数字在数组中的位置而不是数字本身，所以不能直接将数组堆化，可以先将数组中的每个数字转换成一个包含2个元素的元组，元组的第一个元素是数字本身，第二个元素则是数字在数组中的位置。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_k</span>(<span class="params">numbers, k</span>):</span></span><br><span class="line">  heap = [(n, i) <span class="keyword">for</span> i, n <span class="keyword">in</span> <span class="built_in">enumerate</span>(numbers)]</span><br><span class="line">  heapq.heapify(heap)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: heapq.heappop(heap)[<span class="number">1</span>], <span class="built_in">range</span>(k)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  print(top_k([<span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>], <span class="number">3</span>)) <span class="comment"># [4, 3, 2]</span></span><br></pre></td></tr></table></figure>

<h2 id="实现自定义比较器"><a href="#实现自定义比较器" class="headerlink" title="实现自定义比较器"></a>实现自定义比较器</h2><p>当放入堆中的是自定义类时，可以通过实现 <code>__lt__</code> 方法来比较元素大小。假设有一个自定义类为 <code>Node</code>，它包含一个 <code>value</code> 属性，现在问题改为给定一个 <code>Node</code> 的数组，返回前 <code>k</code> 小的 <code>Node</code> 的值，可通过实现 <code>__lt__</code> 方法求解。</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> heapq</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, value</span>):</span></span><br><span class="line">    self.value = value</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__lt__</span>(<span class="params">self, other</span>):</span></span><br><span class="line">    <span class="keyword">return</span> self.value &lt; other.value</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">top_k</span>(<span class="params">nodes, k</span>):</span></span><br><span class="line">  heap = [node <span class="keyword">for</span> node <span class="keyword">in</span> nodes]</span><br><span class="line">  heapq.heapify(heap)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: heapq.heappop(heap).value, <span class="built_in">range</span>(k)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">  print(top_k([Node(<span class="number">5</span>), Node(<span class="number">4</span>), Node(<span class="number">3</span>), Node(<span class="number">2</span>), Node(<span class="number">1</span>)], <span class="number">3</span>)) <span class="comment"># [1, 2, 3]</span></span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/8875706/heapq-with-custom-compare-predicate/8875823">heapq with custom compare predicate</a></li>
</ul>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python for/while else</title>
    <url>/2021/08/08/python-for-while-else/</url>
    <content><![CDATA[<p>和常见的语言不同，<code>Python</code> 的 <code>for/while</code> 可以配合 <code>else</code> 使用。简单来说，当 <code>for/while</code> 循环体中没有执行 <code>break</code> 时，就会执行 <code>else</code> 中的代码。假设需要判断数组中是否存在某个数，如果不存在的话则抛出异常，一种可能的写法是：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">target = <span class="number">10</span></span><br><span class="line">found = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">if</span> i == target:</span><br><span class="line">        found = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> found:</span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">&#x27;not found&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>借助 <code>for/while else</code> 可改写成：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line">target = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="keyword">if</span> i == target:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">&#x27;not found&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>虽然代码少了几行，但是对于不熟悉该语法特性的人来说可能无法一眼看穿代码的意图。</p>
<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/9979970/why-does-python-use-else-after-for-and-while-loops">Why does python use ‘else’ after for and while loops?</a></li>
</ul>
]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>为什么 Java 方法重载不允许仅返回值类型不同</title>
    <url>/2021/11/28/java-function-overload-return-different-type-only/</url>
    <content><![CDATA[<p>在 <code>Java</code> 中，如果两个同名方法仅返回值类型不同，这是不允许的，即编译器不会认为这是方法重载，如下述类中的方法 <code>f</code>：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Demo</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">f</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">f</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>编译器会提示 <code>&#39;f()&#39; is already defined in &#39;Demo&#39;</code>。假设编译器支持这种方式的方法重载，会有什么问题？在某些情况下，编译器无法区分调用的是哪个方法，例如当调用 <code>f()</code> 却忽略返回值时：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">f();</span><br></pre></td></tr></table></figure>

<p>所以仅返回值类型不同不能作为方法重载的形式。</p>
<p>参考：</p>
<ul>
<li>Thinking in Java</li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Commodity Hardware</title>
    <url>/2021/12/23/commodity-hardware/</url>
    <content><![CDATA[<p><code>Commodity Hardware</code> 指较为廉价的硬件设备，它具有如下特点：</p>
<ol>
<li>价格相对低廉</li>
<li>易采购</li>
<li>和同类型的硬件可相互替换</li>
</ol>
<p>由此相关的一个概念叫 <code>commodity computing</code>，即使用大量的廉价硬件来实现低成本、高性能的并行计算，与之相对的则是使用较少数高成本的超级计算机。</p>
<p>参考：</p>
<ul>
<li><a href="https://www.suse.com/suse-defines/definition/commodity-hardware/">Commodity Hardware</a></li>
<li><a href="https://en.wikipedia.org/wiki/Commodity_computing">Commodity computing</a></li>
</ul>
]]></content>
      <tags>
        <tag>English</tag>
      </tags>
  </entry>
  <entry>
    <title>迁移业余项目数据到 Azure MySQL</title>
    <url>/2021/12/19/how-to-import-data-to-azure-mysql/</url>
    <content><![CDATA[<p>创建了 <code>Azure MySQL</code> 实例后（这里使用的是 <code>Flexible Server</code>），首先导出原始数据库的数据，因为用的是 <code>Docker</code> 所以通过以下方式导出：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker exec $&#123;container_id&#125; &#x2F;usr&#x2F;bin&#x2F;mysqldump -u $&#123;user_name&#125; --password&#x3D;$&#123;password&#125; $&#123;database_name&#125; &gt; backup.sql</span><br></pre></td></tr></table></figure>

<p>然后通过 <code>Azure CLI</code> 创建一个新的数据库：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">az mysql flexible-server db create --resource-group $&#123;resource_group&#125; --server-name $&#123;server_name&#125; --database-name $&#123;database_name&#125;</span><br></pre></td></tr></table></figure>

<p>最后通过 <code>Azure CLI</code> 导入数据：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">az mysql flexible-server execute -n $&#123;server_name&#125; -u $&#123;user_name&#125; -p $&#123;password&#125; -d $&#123;database_name&#125; -f $&#123;path_to_backup_sql_file&#125;</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://github.com/Azure-samples/mysql-database-samples">Sample Databases for Azure Database for MySQL flexible server</a></li>
<li><a href="https://docs.microsoft.com/en-us/cli/azure/mysql/flexible-server?view=azure-cli-latest">az mysql flexible-server</a></li>
</ul>
]]></content>
      <tags>
        <tag>Azure</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 GitHub Actions 自动构建和推送 Docker 镜像到 Docker Hub</title>
    <url>/2021/12/26/build-and-push-docker-image-to-docker-hub-with-github-actions/</url>
    <content><![CDATA[<p><code>Docker Hub</code> 的免费账户已不再支持关联 <code>GitHub</code> 仓库并自动构建镜像的功能，不过可以通过 <code>GitHub Actions</code> 来自动构建和推送镜像。实现方式非常简单，<code>Docker</code> 官方已给出了示例（<a href="https://github.com/marketplace/actions/build-and-push-docker-images">Build and push Docker images</a>）：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">name: ci</span><br><span class="line"></span><br><span class="line">on:</span><br><span class="line">  push:</span><br><span class="line">    branches:</span><br><span class="line">      - &#39;master&#39;</span><br><span class="line"></span><br><span class="line">jobs:</span><br><span class="line">  docker:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">      -</span><br><span class="line">        name: Set up QEMU</span><br><span class="line">        uses: docker&#x2F;setup-qemu-action@v1</span><br><span class="line">      -</span><br><span class="line">        name: Set up Docker Buildx</span><br><span class="line">        uses: docker&#x2F;setup-buildx-action@v1</span><br><span class="line">      -</span><br><span class="line">        name: Login to DockerHub</span><br><span class="line">        uses: docker&#x2F;login-action@v1 </span><br><span class="line">        with:</span><br><span class="line">          username: $&#123;&#123; secrets.DOCKERHUB_USERNAME &#125;&#125;</span><br><span class="line">          password: $&#123;&#123; secrets.DOCKERHUB_TOKEN &#125;&#125;</span><br><span class="line">      -</span><br><span class="line">        name: Build and push</span><br><span class="line">        id: docker_build</span><br><span class="line">        uses: docker&#x2F;build-push-action@v2</span><br><span class="line">        with:</span><br><span class="line">          push: true</span><br><span class="line">          tags: user&#x2F;app:latest</span><br></pre></td></tr></table></figure>

<p>一共有三处要注意，第一开头的 <code>branches</code> 下对于新建的仓库需要填写 <code>main</code> 而不是 <code>master</code>。</p>
<p>第二需要为 <code>Login to DockerHub</code> 阶段设置 <code>Docker</code> 的 <code>Access Token</code>，<code>Access Token</code> 可以通过 <code>Docker Hub</code> 的 <code>Account Settings -&gt; Security -&gt; New Access Token</code> 创建，然后通过 <code>GitHub</code> 仓库的 <code>Settings -&gt; Secrets -&gt; New repository secret</code> 分别创建 <code>DOCKERHUB_USERNAME</code> 和 <code>DOCKERHUB_TOKEN</code>。</p>
<p>第三最后的 <code>tags: user/app:latest</code> 中的 <code>user</code> 和 <code>app</code> 需要修改为实际的用户名和镜像名。</p>
<p>参考：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/61989951/github-action-workflow-not-running">GitHub Action workflow not running</a></li>
</ul>
]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>GitHub Actions</tag>
      </tags>
  </entry>
  <entry>
    <title>二叉树非递归遍历</title>
    <url>/2022/02/02/binary-tree-traverse-with-stack/</url>
    <content><![CDATA[<p>二叉树的遍历直观的解法是使用递归求解，不过同样也可使用非递归方式求解。</p>
<h2 id="前序遍历"><a href="#前序遍历" class="headerlink" title="前序遍历"></a>前序遍历</h2><p>先来看前序遍历的递归求解：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=<span class="number">0</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preorderTraversal</span>(<span class="params">self, root: TreeNode</span>) -&gt; List[int]:</span></span><br><span class="line">        values = []</span><br><span class="line"></span><br><span class="line">        self._preorder_traversal(root, values)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> values</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_preorder_traversal</span>(<span class="params">self, root: TreeNode, values: List[<span class="built_in">int</span>]</span>) -&gt; <span class="keyword">None</span>:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        values.append(root.val)</span><br><span class="line"></span><br><span class="line">        self._preorder_traversal(root.left, values)</span><br><span class="line">        self._preorder_traversal(root.right, values)</span><br></pre></td></tr></table></figure>

<p>对于如下的二叉树：</p>
<p><img src="/images/binary-tree.jpg" alt="alt"></p>
<p>其调用链为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">_preorder_traversal(1)</span><br><span class="line">    _preorder_traversal(2)</span><br><span class="line">        _preorder_traversal(4)</span><br><span class="line">        _preorder_traversal(5)</span><br><span class="line">    _preorder_traversal(3)</span><br></pre></td></tr></table></figure>

<p>可以看到越深的节点对应的函数调用越先返回，对应先进后出的模型，即栈，所以递归转非递归可借助栈实现。</p>
<p>由于前序遍历是先访问根节点，所以对于每个子树，可以先将根节点入栈，然后依次弹出栈顶的节点，从而实现先访问根节点，然后将左右子树的根节点入栈，由于左子树需要先于右子树被访问，所以右子树的根节点要先入栈，然后再入栈左子树的根节点：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=<span class="number">0</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preorderTraversal</span>(<span class="params">self, root: TreeNode</span>) -&gt; List[int]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">        values = []</span><br><span class="line">        stack = [root]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> stack:</span><br><span class="line">            current = stack.pop()</span><br><span class="line">            values.append(current.val)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> current.right:</span><br><span class="line">                stack.append(current.right)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> current.left:</span><br><span class="line">                stack.append(current.left)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> values</span><br></pre></td></tr></table></figure>

<h2 id="中序遍历"><a href="#中序遍历" class="headerlink" title="中序遍历"></a>中序遍历</h2><p>在递归的方案下，前序遍历改为中序遍历只需改变 <code>values.append(root.val)</code> 的执行位置即可，而在非递归方案下，并不能通过直接改变 <code>values.append(current.val)</code> 的执行位置来实现，因为不管放到哪个位置，都会提前访问到根节点。</p>
<p>中序遍历下，最左下方的节点是最先被访问的，沿着左子树的根节点这条线，等同于一个单链表的倒序访问，单链表的倒序如果用栈来实现则是将单链表的所有节点从链表头开始遍历依次放入栈，然后再依次出栈，类似的，只要当前节点存在左子树，则持续将左子树的根节点压入栈，这样下次出栈时，就会先访问最左下方的节点。当某个节点出栈时，由于上述的操作，它必然是某个子树的最左下方的节点，此时需要转到该节点的右子树重复上述流程从而访问右子树的全部节点：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        self.val = x</span><br><span class="line">        self.left = <span class="literal">None</span></span><br><span class="line">        self.right = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inorderTraversal</span>(<span class="params">self, root: TreeNode</span>) -&gt; List[int]:</span></span><br><span class="line">        values = []</span><br><span class="line">        stack = []</span><br><span class="line">        current = root</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> current <span class="keyword">or</span> stack:</span><br><span class="line">            <span class="keyword">while</span> current:</span><br><span class="line">                stack.append(current)</span><br><span class="line">                current = current.left</span><br><span class="line"></span><br><span class="line">            current = stack.pop()</span><br><span class="line">            values.append(current.val)</span><br><span class="line">            current = current.right</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> values</span><br></pre></td></tr></table></figure>

<p>虽然前序遍历的非递归方案不适用于中序遍历，不过中序遍历的递归方案可略微修改适用于前序遍历，只需将 <code>values.append(current.val)</code> 放在不断入栈左子树的循环中即可：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=<span class="number">0</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">preorderTraversal</span>(<span class="params">self, root: TreeNode</span>) -&gt; List[int]:</span></span><br><span class="line">        values = []</span><br><span class="line">        stack = []</span><br><span class="line">        current = root</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> current <span class="keyword">or</span> stack:</span><br><span class="line">            <span class="keyword">while</span> current:</span><br><span class="line">                values.append(current.val)</span><br><span class="line">                stack.append(current)</span><br><span class="line">                current = current.left</span><br><span class="line"></span><br><span class="line">            current = stack.pop()</span><br><span class="line">            current = current.right</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> values</span><br></pre></td></tr></table></figure>

<h2 id="后序遍历"><a href="#后序遍历" class="headerlink" title="后序遍历"></a>后序遍历</h2><p>后序遍历和中序遍历相同，最先访问的都是最左下方的节点，所以对左子树不断入栈这段逻辑不变，不同的是当出栈时，当前出栈的节点有可能存在右子树，而右子树还还没有被访问，所以当前节点还不能出栈。因此，需要先判断栈顶的节点是否存在右子树，以及右子树是否被访问过，如果存在右子树且未被访问则转向右子树重复上述流程，否则可弹出栈顶节点。而判断栈顶的右子树是否被访问可通过比较栈顶的右子树和上一个被访问的节点来实现，如果两者相等，说明栈顶的右子树刚被访问过，否则未被访问过：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=<span class="number">0</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">postorderTraversal</span>(<span class="params">self, root: TreeNode</span>) -&gt; List[int]:</span></span><br><span class="line">        prev = <span class="literal">None</span></span><br><span class="line">        current = root</span><br><span class="line">        stack = []</span><br><span class="line">        values = []</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> current <span class="keyword">or</span> stack:</span><br><span class="line">            <span class="keyword">while</span> current:</span><br><span class="line">                stack.append(current)</span><br><span class="line">                current = current.left</span><br><span class="line"></span><br><span class="line">            top = stack[-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> top.right <span class="keyword">and</span> prev != top.right:</span><br><span class="line">                current = top.right</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                current = stack.pop()</span><br><span class="line">                values.append(current.val)</span><br><span class="line">                prev = current</span><br><span class="line">                current = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> values</span><br></pre></td></tr></table></figure>

<h2 id="通用模板"><a href="#通用模板" class="headerlink" title="通用模板"></a>通用模板</h2><p>上述各非递归方案各不相同，是否存在和递归方案类似的通用模板方案？<a href="https://leetcode.com/problems/binary-tree-preorder-traversal/discuss/1736072/Java-This-simple-template-can-be-used-for-3-traversals">这里</a> 给出了一种通用方案，首先需要额外引入一个数据结构来标记节点是否被访问过：</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Pair</span> </span>&#123;</span><br><span class="line">    <span class="keyword">boolean</span> visited;</span><br><span class="line">    TreeNode node;</span><br><span class="line"></span><br><span class="line">    Pair(TreeNode node, <span class="keyword">boolean</span> visited) &#123;</span><br><span class="line">        <span class="keyword">this</span>.node = node;</span><br><span class="line">        <span class="keyword">this</span>.visited = visited;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在 <code>Python</code> 中，可简单通过元组来实现，对应模板代码为：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> List</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Definition for a binary tree node.</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=<span class="number">0</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">xxxTraversal</span>(<span class="params">self, root: TreeNode</span>) -&gt; List[int]:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line">        </span><br><span class="line">        stack = [(root, <span class="literal">False</span>)]</span><br><span class="line">        values = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> stack:</span><br><span class="line">            current, visited = stack.pop()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> visited:</span><br><span class="line">                values.append(current.val)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="comment"># 在这里处理左子树，右子树，根节点的入栈顺序</span></span><br><span class="line">                <span class="keyword">pass</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> values</span><br></pre></td></tr></table></figure>

<p>对于三种遍历方式，上述模板方法仅在处理左子树，右子树，根节点的入栈顺序上不同，实际入栈顺序和遍历顺序相反：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 前序遍历</span></span><br><span class="line"><span class="keyword">if</span> current.right:</span><br><span class="line">    stack.append((current.right, <span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> current.left:</span><br><span class="line">    stack.append((current.left, <span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">stack.append((current, <span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中序遍历</span></span><br><span class="line"><span class="keyword">if</span> current.right:</span><br><span class="line">    stack.append((current.right, <span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line">stack.append((current, <span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> current.left:</span><br><span class="line">    stack.append((current.left, <span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 后序遍历</span></span><br><span class="line">stack.append((current, <span class="literal">True</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> current.right:</span><br><span class="line">    stack.append((current.right, <span class="literal">False</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> current.left:</span><br><span class="line">    stack.append((current.left, <span class="literal">False</span>))</span><br></pre></td></tr></table></figure>

<p>从出栈的角度来说，上述方法和理论遍历顺序并不一致，每个节点会入栈两次，第二次入栈时才会设置 <code>visited</code> 为 <code>True</code>，但从 <code>visited</code> 的角度来说顺序是和理论遍历顺序一致的。</p>
<p>参考：</p>
<ul>
<li><a href="https://leetcode.com/problems/binary-tree-preorder-traversal/discuss/1736072/Java-This-simple-template-can-be-used-for-3-traversals">[Java] This simple template can be used for 3 traversals</a></li>
<li><a href="https://leetcode.com/problems/binary-tree-postorder-traversal/discuss/45551/Preorder-Inorder-and-Postorder-Iteratively-Summarization">Preorder, Inorder, and Postorder Iteratively Summarization</a></li>
</ul>
]]></content>
      <tags>
        <tag>Data Structure</tag>
        <tag>Algorithm</tag>
        <tag>Binary Tree</tag>
      </tags>
  </entry>
  <entry>
    <title>二叉搜索树的插入</title>
    <url>/2022/02/07/add-node-in-binary-search-tree/</url>
    <content><![CDATA[<p>往一个二叉搜索树中插入一个节点后的结果并不唯一，例如对于下面的二叉搜索树：</p>
<p><img src="/images/bst-add-1.png" alt="alt"></p>
<p>如果要插入节点2，可以将2作为3的左子节点：</p>
<p><img src="/images/bst-add-2.png" alt="alt"></p>
<p>或者将2作为1的右子节点：</p>
<p><img src="/images/bst-add-3.png" alt="alt"></p>
<p>对于第一种方法，类似于往单链表的中间插入节点，既要更新前继节点的 <code>next</code> 指针，又要将新的节点的 <code>next</code> 指针指向下一个节点；而对于第二种方法，只需要将新节点挂载到目标节点的左子节点或右子节点即可，实现上较为简洁，可分为非递归和递归两种解法。</p>
<h2 id="非递归"><a href="#非递归" class="headerlink" title="非递归"></a>非递归</h2><p>整体算法分为两步：</p>
<ol>
<li>找到要挂载的叶子节点</li>
<li>将新节点挂载到该叶子节点的左子节点或右子节点上</li>
</ol>
<p>第一步等同于二叉搜索树的查找，从根节点开始，将目标值和当前节点的值进行比较，如果当前节点的值比目标值小，说明要找的节点在右子树中，移动到右子节点中查找；如果当前节点的值比目标值大，说明要找的节点在左子树中，移动到左子节点中查找。</p>
<p>找到目标叶子节点后，比较该叶子节点的值和目标值的大小，来决定新节点是作为左子节点还是右子节点插入：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=<span class="number">0</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insertIntoBST</span>(<span class="params">self, root: TreeNode, val: <span class="built_in">int</span></span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> TreeNode(val)</span><br><span class="line"></span><br><span class="line">        prev, current = <span class="literal">None</span>, root</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> current:</span><br><span class="line">            prev = current</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> current.val &lt; val:</span><br><span class="line">                current = current.right</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                current = current.left</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> prev.val &gt; val:</span><br><span class="line">            prev.left = TreeNode(val)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            prev.right = TreeNode(val)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>

<h2 id="递归"><a href="#递归" class="headerlink" title="递归"></a>递归</h2><p>一般的二叉树问题的递归解法遵循如下的模式：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        <span class="comment"># 处理终止条件</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 一种情况是左右子树只处理一边</span></span><br><span class="line">    <span class="keyword">if</span> some condition:</span><br><span class="line">        dfs(root.left)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dfs(root.right)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 另一种情况是左右子树都处理</span></span><br><span class="line">    dfs(root.left)</span><br><span class="line">    dfs(root.right)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> something</span><br></pre></td></tr></table></figure>

<p>在当前的问题下，终止条件发生的条件为找到了目标叶子节点，此时需要新建一个节点；而对于递归的处理，这里适用于第一种情况，即左右子树只处理一边，判断条件为比较当前节点的值和目标值的大小，所以可以粗略的构造出程序的框架：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dfs</span>(<span class="params">root, val</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">        create new node <span class="keyword">with</span> val</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> root.val &gt; val:</span><br><span class="line">        dfs(root.left)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        dfs(root.right)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> something</span><br></pre></td></tr></table></figure>

<p>下一个问题是，这个递归函数的返回值是什么？从终止条件的处理可以看到递归函数返回的是某个节点，联想到往一个二叉搜索树中插入一个节点后需要返回一个新的树，所以这里递归函数的返回值应该是根节点。</p>
<p>然而还缺少一步，就是新节点的挂载，目前新节点返回后并没有任何节点引用它，需要在终止条件的上层调用中处理，即每次递归调用时都重新赋值左子树或右子树的根节点：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=<span class="number">0</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">insertIntoBST</span>(<span class="params">self, root: TreeNode, val: <span class="built_in">int</span></span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> TreeNode(val)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> root.val &lt; val:</span><br><span class="line">            root.right = self.insertIntoBST(root.right, val)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            root.left = self.insertIntoBST(root.left, val)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Data Structure</tag>
        <tag>Algorithm</tag>
        <tag>Binary Search Tree</tag>
      </tags>
  </entry>
  <entry>
    <title>二叉搜索树的删除</title>
    <url>/2022/02/22/delete-node-in-binary-search-tree/</url>
    <content><![CDATA[<p>二叉搜索树的删除可以分为三种情况。第一，被删除的节点是叶子节点：</p>
<p><img src="/images/bst-delete-1.png" alt="alt"></p>
<p>第二，被删除的节点只有一个孩子节点：</p>
<p><img src="/images/bst-delete-2.png" alt="alt"></p>
<p>第三，被删除的节点有两个孩子节点：</p>
<p><img src="/images/bst-delete-3.png" alt="alt"></p>
<p>对于第一种情况，我们只需断开被删除的节点和其父节点的关联即可，即将节点3的左孩子节点指针置为空；对于第二种情况，我们可以用被删除的节点的孩子节点来替代被删除的节点，即将节点5的右孩子指针改为指向节点7；第三种情况是最为复杂的情况，相当于删除一个子树的根节点，为了保持二叉搜索树的性质，我们可以使用左子树中的最大值或右子树的最小值来替代被删除的根节点。</p>
<p>不过在实现时，考虑到实现的简便，对于第三种情况会通过直接修改当前节点的值来替代修改节点的指针指向，以上述例子来说，如果使用指针修改的方式，则需要修改节点5的左孩子指针，修改节点2的左孩子指针和右孩子指针（这里假设使用节点2来替代被删除的节点3），总共三处修改较为繁琐；而如果使用修改节点值的方式，只需要先将节点3的值改为2（这里假设使用节点2来替代被删除的节点3），然后就可以将问题转化为在余下的左子树中删除节点2。具体代码如下：</p>
<figure class="highlight py"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, val=<span class="number">0</span>, left=<span class="literal">None</span>, right=<span class="literal">None</span></span>):</span></span><br><span class="line">        self.val = val</span><br><span class="line">        self.left = left</span><br><span class="line">        self.right = right</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">deleteNode</span>(<span class="params">self, root: TreeNode, key: <span class="built_in">int</span></span>) -&gt; TreeNode:</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> root:</span><br><span class="line">            <span class="keyword">return</span> root</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> root.val &lt; key:</span><br><span class="line">            root.right = self.deleteNode(root.right, key)</span><br><span class="line">        <span class="keyword">elif</span> root.val &gt; key:</span><br><span class="line">            root.left = self.deleteNode(root.left, key)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> root.left <span class="keyword">and</span> root.right:</span><br><span class="line">                root.val = self._find_min(root.right)</span><br><span class="line">                root.right = self.deleteNode(root.right, root.val)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">return</span> root.left <span class="keyword">or</span> root.right</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_find_min</span>(<span class="params">self, root</span>):</span></span><br><span class="line">        <span class="keyword">while</span> root.left:</span><br><span class="line">            root = root.left</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> root.val</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>Data Structure</tag>
        <tag>Algorithm</tag>
        <tag>Binary Search Tree</tag>
      </tags>
  </entry>
  <entry>
    <title>发布 JAR 包到 Maven 中央仓库</title>
    <url>/2022/02/27/how-to-publich-java-package-to-maven-central-repo/</url>
    <content><![CDATA[<p><code>Sonatype OSSRH (OSS Repository Hosting)</code> 提供了 <code>JAR</code> 包发布服务，并支持自动将 <code>JAR</code> 包同步到 <code>Maven</code> 中央仓库，所以我们将 <code>JAR</code> 包发布到 <code>Sonatype OSSRH</code> 即可。</p>
<h2 id="创建-Sonatype-工单"><a href="#创建-Sonatype-工单" class="headerlink" title="创建 Sonatype 工单"></a>创建 Sonatype 工单</h2><p>第一步在 <a href="https://issues.sonatype.org/secure/Signup!default.jspa">Sonatype</a> 上注册一个账号，创建成功后在上面创建一个 <code>Issue</code>，<code>Project</code> 选择 <code>Community Support - Open Source Project Repository Hosting (OSSRH)</code>，<code>Issue Type</code> 选择 <code>New Project</code>：</p>
<p><img src="/images/sonatype.png" alt="alt"></p>
<p>这里要注意的是 <code>Group Id</code> 的填写，根据 <a href="https://central.sonatype.org/publish/requirements/coordinates/">Coordinates</a> 的描述，这里分两种情况：</p>
<ol>
<li>你拥有某个域名，如 <code>example.com</code></li>
<li>你没有域名，但是你的代码托管在了某个代码托管服务上，如 <code>GitHub</code></li>
</ol>
<p>对于第一种情况，你的 <code>Group Id</code> 可以是任何以 <code>com.example</code> 为前缀的字符串，如 <code>com.example.myawesomeproject</code>。不过，<code>Sonatype</code> 会要求你证明确实拥有 <code>example.com</code> 域名，你需要在你的域名注册商那创建一条 <code>TXT</code> 记录，其内容就是你创建的 <code>Issue</code> 的工单号，如 <code>OSSRH-12345</code>，具体步骤可参考 <a href="https://central.sonatype.org/faq/how-to-set-txt-record/">How do I set the TXT record needed to prove ownership of my Web Domain?</a>。</p>
<p>对于第二种情况，以 <code>GitHub</code> 为例，你的 <code>Group Id</code> 必须是 <code>io.github.myusername</code>，<code>myusername</code> 是你的 <code>GitHub</code> 账户名或者是组织名，类似的，为了证明你对 <code>myusername</code> 的所有权，你需要在 <code>myusername</code> 下创建一个公开的仓库，仓库名称为你所创建 <code>Issue</code> 的工单号，如 <code>OSSRH-12345</code>，认证完成之后你就可以删掉这个仓库。<code>Sonatype</code> 所支持的代码托管服务如下：</p>
<table>
<thead>
<tr>
<th>Service</th>
<th>Example groupId</th>
</tr>
</thead>
<tbody><tr>
<td>GitHub</td>
<td>io.github.myusername</td>
</tr>
<tr>
<td>GitLab</td>
<td>io.gitlab.myusername</td>
</tr>
<tr>
<td>Gitee</td>
<td>io.gitee.myusername</td>
</tr>
<tr>
<td>Bitbucket</td>
<td>io.bitbucket.myusername</td>
</tr>
<tr>
<td>SourceForge</td>
<td>io.sourceforge.myusername</td>
</tr>
</tbody></table>
<p>工单示例可参考 <a href="https://issues.sonatype.org/browse/OSSRH-78488">Publish my open source java package</a>。</p>
<h2 id="安装-GPG"><a href="#安装-GPG" class="headerlink" title="安装 GPG"></a>安装 GPG</h2><p><code>GPG</code> 用于对所发布的包进行签名，在 <a href="https://www.gnupg.org/download/index.html">GnuPG</a> 根据自己的操作系统下载 <code>GPG</code> 安装包，安装完成后执行 <code>gpg --full-gen-key</code> 生成秘钥对，选择默认选项即可，生成秘钥对时会要求输入姓名、邮箱、注释和密码，其中密码在发布阶段会用到，秘钥生成信息类似如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pub   rsa3072 2022-02-26 [SC]</span><br><span class="line">      E892F685E5EA9005E0A2DE31F0F732425A15D81D</span><br><span class="line">uid                      examplename &lt;examplename@example.com&gt;</span><br><span class="line">sub   rsa3072 2022-02-26 [E]</span><br></pre></td></tr></table></figure>

<p>其中 <code>E892F685E5EA9005E0A2DE31F0F732425A15D81D</code> 是秘钥的 <code>ID</code>，然后我们需要将公钥分发到公共的秘钥服务器上，这样 <code>Sonatype</code> 就可以通过这个公钥来验证我们所发布包的签名是否正确：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gpg --keyserver keyserver.ubuntu.com --send-keys E892F685E5EA9005E0A2DE31F0F732425A15D81D</span><br></pre></td></tr></table></figure>

<p>这里选择的公共秘钥服务器是 <code>keyserver.ubuntu.com</code>，也可以选择其他服务器，如 <code>keys.openpgp.org</code> 或者 <code>pgp.mit.edu</code>。</p>
<h2 id="配置-settings-xml"><a href="#配置-settings-xml" class="headerlink" title="配置 settings.xml"></a>配置 settings.xml</h2><p>为了将包发到 <code>Sonatype OSSRH</code>，需要在 <code>Maven</code> 的 <code>settings.xml</code> 中配置用户信息，即在 <code>servers</code> 下添加如下信息，这里的 <code>your-jira-id</code> 和 <code>your-jira-pwd</code> 对应第一步创建的账号和密码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;server&gt;</span><br><span class="line">    &lt;id&gt;ossrh&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;username&gt;your-jira-id&lt;&#x2F;username&gt;</span><br><span class="line">    &lt;password&gt;your-jira-pwd&lt;&#x2F;password&gt;</span><br><span class="line">&lt;&#x2F;server&gt;</span><br></pre></td></tr></table></figure>

<p>另外，为了在打包时对文件进行签名还需要在 <code>profiles</code> 下添加如下信息，这里的 <code>the_pass_phrase</code> 为生成 <code>GPG</code> 秘钥时设置的密码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;profile&gt;</span><br><span class="line">    &lt;id&gt;ossrh&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;activation&gt;</span><br><span class="line">    &lt;activeByDefault&gt;true&lt;&#x2F;activeByDefault&gt;</span><br><span class="line">    &lt;&#x2F;activation&gt;</span><br><span class="line">    &lt;properties&gt;</span><br><span class="line">    &lt;gpg.executable&gt;gpg&lt;&#x2F;gpg.executable&gt;</span><br><span class="line">    &lt;gpg.passphrase&gt;the_pass_phrase&lt;&#x2F;gpg.passphrase&gt;</span><br><span class="line">    &lt;&#x2F;properties&gt;</span><br><span class="line">&lt;&#x2F;profile&gt;</span><br></pre></td></tr></table></figure>

<h2 id="配置-pom-xml"><a href="#配置-pom-xml" class="headerlink" title="配置 pom.xml"></a>配置 pom.xml</h2><p>最后是配置 <code>pom.xml</code>，首先我们需要告诉 <code>Maven</code> 将包部署到 <code>Sonatype OSSRH</code>，需要增加一个 <code>nexus-staging-maven-plugin</code> 插件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;distributionManagement&gt;</span><br><span class="line">  &lt;snapshotRepository&gt;</span><br><span class="line">    &lt;id&gt;ossrh&lt;&#x2F;id&gt;</span><br><span class="line">    &lt;url&gt;https:&#x2F;&#x2F;s01.oss.sonatype.org&#x2F;content&#x2F;repositories&#x2F;snapshots&lt;&#x2F;url&gt;</span><br><span class="line">  &lt;&#x2F;snapshotRepository&gt;</span><br><span class="line">&lt;&#x2F;distributionManagement&gt;</span><br><span class="line">&lt;build&gt;</span><br><span class="line">  &lt;plugins&gt;</span><br><span class="line">    &lt;plugin&gt;</span><br><span class="line">      &lt;groupId&gt;org.sonatype.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;nexus-staging-maven-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">      &lt;version&gt;1.6.7&lt;&#x2F;version&gt;</span><br><span class="line">      &lt;extensions&gt;true&lt;&#x2F;extensions&gt;</span><br><span class="line">      &lt;configuration&gt;</span><br><span class="line">        &lt;serverId&gt;ossrh&lt;&#x2F;serverId&gt;</span><br><span class="line">        &lt;nexusUrl&gt;https:&#x2F;&#x2F;s01.oss.sonatype.org&#x2F;&lt;&#x2F;nexusUrl&gt;</span><br><span class="line">        &lt;autoReleaseAfterClose&gt;true&lt;&#x2F;autoReleaseAfterClose&gt;</span><br><span class="line">      &lt;&#x2F;configuration&gt;</span><br><span class="line">    &lt;&#x2F;plugin&gt;</span><br><span class="line">  &lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;build&gt;</span><br></pre></td></tr></table></figure>

<p>然后是配置 <code>Javadoc</code> 和源码插件，如果最后的 <code>JAR</code> 包没有包含 <code>Javadoc</code> 和源码，<code>Sonatype</code> 会不允许通过：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">  &lt;plugins&gt;</span><br><span class="line">    &lt;plugin&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;maven-source-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">      &lt;version&gt;2.2.1&lt;&#x2F;version&gt;</span><br><span class="line">      &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">          &lt;id&gt;attach-sources&lt;&#x2F;id&gt;</span><br><span class="line">          &lt;goals&gt;</span><br><span class="line">            &lt;goal&gt;jar-no-fork&lt;&#x2F;goal&gt;</span><br><span class="line">          &lt;&#x2F;goals&gt;</span><br><span class="line">        &lt;&#x2F;execution&gt;</span><br><span class="line">      &lt;&#x2F;executions&gt;</span><br><span class="line">    &lt;&#x2F;plugin&gt;</span><br><span class="line">    &lt;plugin&gt;</span><br><span class="line">      &lt;groupId&gt;org.apache.maven.plugins&lt;&#x2F;groupId&gt;</span><br><span class="line">      &lt;artifactId&gt;maven-javadoc-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">      &lt;version&gt;2.9.1&lt;&#x2F;version&gt;</span><br><span class="line">      &lt;executions&gt;</span><br><span class="line">        &lt;execution&gt;</span><br><span class="line">          &lt;id&gt;attach-javadocs&lt;&#x2F;id&gt;</span><br><span class="line">          &lt;goals&gt;</span><br><span class="line">            &lt;goal&gt;jar&lt;&#x2F;goal&gt;</span><br><span class="line">          &lt;&#x2F;goals&gt;</span><br><span class="line">        &lt;&#x2F;execution&gt;</span><br><span class="line">      &lt;&#x2F;executions&gt;</span><br><span class="line">    &lt;&#x2F;plugin&gt;</span><br><span class="line">  &lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;build&gt;</span><br></pre></td></tr></table></figure>

<p>不过上述配置不适合 <code>Kotlin</code> 项目，会提示 <code>Missing: no javadoc jar found in folder &#39;/com/example/username/awesomeproject&#39;</code>，需要将 <code>maven-javadoc-plugin</code> 替换为 <code>dokka-maven-plugin</code>：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;build&gt;</span><br><span class="line">  &lt;plugins&gt;</span><br><span class="line">    &lt;plugin&gt;</span><br><span class="line">        &lt;groupId&gt;org.jetbrains.dokka&lt;&#x2F;groupId&gt;</span><br><span class="line">        &lt;artifactId&gt;dokka-maven-plugin&lt;&#x2F;artifactId&gt;</span><br><span class="line">        &lt;executions&gt;</span><br><span class="line">            &lt;execution&gt;</span><br><span class="line">                &lt;phase&gt;package&lt;&#x2F;phase&gt;</span><br><span class="line">                &lt;id&gt;attach-javadocs-dokka&lt;&#x2F;id&gt;</span><br><span class="line">                &lt;goals&gt;</span><br><span class="line">                    &lt;goal&gt;javadocJar&lt;&#x2F;goal&gt;</span><br><span class="line">                &lt;&#x2F;goals&gt;</span><br><span class="line">            &lt;&#x2F;execution&gt;</span><br><span class="line">        &lt;&#x2F;executions&gt;</span><br><span class="line">    &lt;&#x2F;plugin&gt;</span><br><span class="line">  &lt;&#x2F;plugins&gt;</span><br><span class="line">&lt;&#x2F;build&gt;</span><br></pre></td></tr></table></figure>

<p>最后，剩下补充一些元数据，这个也是必填项，包括：</p>
<ul>
<li>项目名称，描述和地址</li>
<li>许可证信息</li>
<li>开发者信息</li>
<li>源码地址</li>
</ul>
<p>完整的示例可参考：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;</span><br><span class="line">&lt;project xmlns&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0&quot;</span><br><span class="line">xmlns:xsi&#x3D;&quot;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&quot;</span><br><span class="line">xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;maven.apache.org&#x2F;POM&#x2F;4.0.0 http:&#x2F;&#x2F;maven.apache.org&#x2F;maven-v4_0_0.xsd&quot;&gt;</span><br><span class="line">  &lt;modelVersion&gt;4.0.0&lt;&#x2F;modelVersion&gt;</span><br><span class="line"></span><br><span class="line">  &lt;groupId&gt;com.simpligility.training&lt;&#x2F;groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;ossrh-demo&lt;&#x2F;artifactId&gt;</span><br><span class="line">  &lt;version&gt;1.0&lt;&#x2F;version&gt;</span><br><span class="line">  &lt;packaging&gt;jar&lt;&#x2F;packaging&gt;</span><br><span class="line"></span><br><span class="line">  &lt;name&gt;ossrh-demo&lt;&#x2F;name&gt;</span><br><span class="line">  &lt;description&gt;A demo for deployment to the Central Repository via OSSRH&lt;&#x2F;description&gt;</span><br><span class="line">  &lt;url&gt;http:&#x2F;&#x2F;github.com&#x2F;simpligility&#x2F;ossrh-demo&lt;&#x2F;url&gt;</span><br><span class="line"></span><br><span class="line">  &lt;licenses&gt;</span><br><span class="line">    &lt;license&gt;</span><br><span class="line">      &lt;name&gt;The Apache Software License, Version 2.0&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;url&gt;http:&#x2F;&#x2F;www.apache.org&#x2F;licenses&#x2F;LICENSE-2.0.txt&lt;&#x2F;url&gt;</span><br><span class="line">    &lt;&#x2F;license&gt;</span><br><span class="line">  &lt;&#x2F;licenses&gt;</span><br><span class="line"></span><br><span class="line">  &lt;developers&gt;</span><br><span class="line">    &lt;developer&gt;</span><br><span class="line">      &lt;name&gt;Manfred Moser&lt;&#x2F;name&gt;</span><br><span class="line">      &lt;email&gt;manfred@sonatype.com&lt;&#x2F;email&gt;</span><br><span class="line">      &lt;organization&gt;Sonatype&lt;&#x2F;organization&gt;</span><br><span class="line">      &lt;organizationUrl&gt;http:&#x2F;&#x2F;www.sonatype.com&lt;&#x2F;organizationUrl&gt;</span><br><span class="line">    &lt;&#x2F;developer&gt;</span><br><span class="line">  &lt;&#x2F;developers&gt;</span><br><span class="line"></span><br><span class="line">  &lt;scm&gt;</span><br><span class="line">    &lt;connection&gt;scm:git:git:&#x2F;&#x2F;github.com&#x2F;simpligility&#x2F;ossrh-demo.git&lt;&#x2F;connection&gt;</span><br><span class="line">    &lt;developerConnection&gt;scm:git:ssh:&#x2F;&#x2F;github.com:simpligility&#x2F;ossrh-demo.git&lt;&#x2F;developerConnection&gt;</span><br><span class="line">    &lt;url&gt;http:&#x2F;&#x2F;github.com&#x2F;simpligility&#x2F;ossrh-demo&#x2F;tree&#x2F;master&lt;&#x2F;url&gt;</span><br><span class="line">  &lt;&#x2F;scm&gt;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;project&gt;</span><br></pre></td></tr></table></figure>

<h2 id="发包"><a href="#发包" class="headerlink" title="发包"></a>发包</h2><p>执行 <code>mvn clean deploy</code> 即可发包，如果执行成功，在提交的工单中会自动增加一条回复：</p>
<blockquote>
<p>Central sync is activated for com.example.awesomeproject. After you successfully release, your component will be available to the public on Central <a href="https://repo1.maven.org/maven2/">https://repo1.maven.org/maven2/</a>, typically within 30 minutes, though updates to <a href="https://search.maven.org/">https://search.maven.org</a> can take up to four hours.</p>
</blockquote>
<p>也就是30分钟内即可从 <code>Maven</code> 中央仓库下载 <code>JAR</code> 包，不过要想能在 <code>search.maven.org</code> 搜索到你的 <code>JAR</code> 包，需要等待至多4个小时。</p>
<p>另外，因为配置 <code>nexus-staging-maven-plugin</code> 时指定了 <code>autoReleaseAfterClose</code> 为 <code>true</code>，所以发包后不需要去 <code>https://oss.sonatype.org/#stagingRepositories</code> 手动执行 <code>close</code> 和 <code>release</code> 操作。</p>
<p>参考：</p>
<ul>
<li><a href="https://dzone.com/articles/publish-your-artifacts-to-maven-central">How to Publish Your Artifacts to Maven Central</a></li>
<li><a href="https://central.sonatype.org/publish/requirements/coordinates/">Coordinates</a></li>
<li><a href="https://central.sonatype.org/publish/requirements/gpg/">GPG</a></li>
</ul>
]]></content>
      <tags>
        <tag>Java</tag>
        <tag>Maven</tag>
        <tag>Kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title>CF 和 OF 标志位</title>
    <url>/2022/03/13/cf-and-of-flag/</url>
    <content><![CDATA[<p>看汇编语言时看到，标志寄存器中 <code>CF</code> 标志位表示无符号数运算时是否向最高有效位外的更高位产生进位或借位，而 <code>OF</code> 标志位表示有符号数运算时是否产生溢出。这里存在两个疑问：</p>
<ol>
<li>对于 <code>CPU</code> 来说，它并不区分处理的是无符号数还是有符号数，那什么时候设置 <code>CF</code>，什么时候设置 <code>OF</code> 呢</li>
<li><code>CF</code> 表示进位时也是一种溢出，能否和 <code>OF</code> 共用一个</li>
</ol>
<h2 id="CF"><a href="#CF" class="headerlink" title="CF"></a>CF</h2><p>首先来看 <code>CF</code> 进位的例子，这里我们以8位无符号数为例，其最大值为255，那么计算 <code>255 + 1</code> 则会产生进位。可以通过一段简单的汇编代码进行验证：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.section .text</span><br><span class="line">.globl _start</span><br><span class="line">_start:</span><br><span class="line">    mov $255, %al</span><br><span class="line">    add $1, %al</span><br><span class="line">    movl $1, %eax</span><br><span class="line">    movl $0, %ebx</span><br><span class="line">    int $0x80</span><br></pre></td></tr></table></figure>

<p>在上述代码中，<code>al</code> 是一个8位寄存器，是 <code>eax</code> 寄存器的低8位，这里首先将255放到 <code>al</code> 寄存器内，然后对 <code>al</code> 寄存器中的值加1并放回到 <code>al</code> 寄存器中，即实现 <code>255 +1</code> 的运算。</p>
<p>最后的 <code>int $0x80</code> 中的 <code>int</code> 表示 <code>interrupt</code>，即中断，当发生一个中断时会有一个与之对应的中断处理程序来处理，这里的 <code>$0x80</code> 就是声明由哪个中断处理程序处理，在 <code>Linux</code> 中，<code>$0x80</code> 对应的是操作系统内核，用于发起一个系统调用，而具体发起哪个系统调用则由 <code>eax</code> 中的值决定，这就是 <code>movl $1, %eax</code> 的作用，1对应的系统调用是 <code>exit</code>，用于退出程序，而程序退出时会伴有一个状态码，这个状态码的值来自于 <code>ebx</code>，也就是 <code>movl $0, %ebx</code> 的作用，这里使用0来表示程序正常退出。</p>
<p>接下来我们借助 <code>gdb</code> 来观察程序运行时 <code>CF</code> 的值的变化。首先将上述代码保存为 <code>demo.s</code> 后进行编译：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">as demo.s -o demo.o -gstabs+</span><br></pre></td></tr></table></figure>

<p>这里的 <code>-gstabs+</code> 表示生成机器码时同时生成调试信息，如果没有这个选项后续 <code>gdb</code> 加载时会提示 <code>(No debugging symbols found in ./demo)</code>。</p>
<p>然后进行链接：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ld demo.o -o demo</span><br></pre></td></tr></table></figure>

<p>这个时候就可以通过 <code>gdb</code> 加载生成的可执行文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">gdb .&#x2F;demo</span><br></pre></td></tr></table></figure>

<p><img src="/images/cf-of-1.png" alt="alt"></p>
<p>然后输入 <code>break 4</code> 在代码第四行设置一个断点，即 <code>mov $255, %al</code> 处，最后输入 <code>run</code> 开始调试执行：</p>
<p><img src="/images/cf-of-2.png" alt="alt"></p>
<p>此时可输入 <code>layout reg</code> 来观察各寄存器内的值，我们需要关注的是 <code>eflags</code> 寄存器，它展示了哪些标志位生效了：</p>
<p><img src="/images/cf-of-3.png" alt="alt"></p>
<p>或者通过执行 <code>info registers eflags</code> 来查看 <code>eflags</code> 的值：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(gdb) info registers eflags</span><br><span class="line">eflags         0x202               [ IF ]</span><br></pre></td></tr></table></figure>

<p>目前只有一个 <code>IF</code> 标志位，它用于表示是否响应中断。</p>
<p>接着，输入 <code>next</code> 来执行当前断点所在处的指令，可以看到，执行后 <code>rax</code> 寄存器内的值变成了255（<code>rax</code> 是64位 <code>CPU</code> 下的一个通用寄存器，32位 <code>CPU</code> 下对应为 <code>eax</code>）：</p>
<p><img src="/images/cf-of-4.png" alt="alt"></p>
<p>再输入一次 <code>next</code> 来执行加法运算，此时 <code>rax</code> 中的值变为了0（实际的二进制结果应该是100000000，因为 <code>al</code> 寄存器最多只能表示8位，所以最高位的1无法表示，最终结果为0），<code>eflags</code> 中出现了 <code>CF</code> 标志位，说明发生了进位：</p>
<p><img src="/images/cf-of-5.png" alt="alt"></p>
<p><code>rax</code> 中的值为0也说明了加法运算后产生的进位并不会体现在比参与运算的寄存器位数更多的寄存器中，否则 <code>rax</code> 中的值应该是256。</p>
<p>再来看借位，将程序稍加修改执行一个 <code>1 - 2</code> 的运算：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.section .text</span><br><span class="line">.globl _start</span><br><span class="line">_start:</span><br><span class="line">    mov $1, %al</span><br><span class="line">    sub $2, %al</span><br><span class="line">    movl $1, %eax</span><br><span class="line">    movl $0, %ebx</span><br><span class="line">    int $0x80</span><br></pre></td></tr></table></figure>

<p>最后 <code>rax</code> 中的值为255（存在高位借位的情况下最后的二进制结果为11111111，解释为无符号数为255），<code>eflags</code> 中同样出现了 <code>CF</code> 标志位。</p>
<p><img src="/images/cf-of-6.png" alt="alt"></p>
<p>所以，<code>CF</code> 的标记取决于两个二进制数的运算是否产生进位或借位。</p>
<h2 id="OF"><a href="#OF" class="headerlink" title="OF"></a>OF</h2><p>有符号数的溢出分两种情况，一种是运算结果应该是正数却返回负数，另一种是运算结果应该是负数却返回正数。</p>
<p>首先来看两个正数运算得到负数的例子，同样对代码稍加修改实现 <code>127 + 1</code> 的运算：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.section .text</span><br><span class="line">.globl _start</span><br><span class="line">_start:</span><br><span class="line">    mov $127, %al</span><br><span class="line">    add $1, %al</span><br><span class="line">    movl $1, %eax</span><br><span class="line">    movl $0, %ebx</span><br><span class="line">    int $0x80</span><br></pre></td></tr></table></figure>

<p>最后 <code>rax</code> 中的值为128（对应二进制表示为10000000，以有符号数的角度来看，其值为-128，即两个正数相加得到一个负数），<code>eflags</code> 中出现了 <code>OF</code> 标志位，说明发生了溢出：</p>
<p><img src="/images/cf-of-7.png" alt="alt"></p>
<p>从有符号数的角度来看，参与运算的两个数的符号位都是0，相加后符号位却是1，所以 <code>OF</code> 设置为1。</p>
<p>再来看两个负数运算得到正数的例子，再次对代码稍加修改实现 <code>-128 - 1</code> 的运算，-128的二进制补码表示为10000000，即无符号数角度下的128，-1的二进制补码表示为11111111，即无符号数角度下的255：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.section .text</span><br><span class="line">.globl _start</span><br><span class="line">_start:</span><br><span class="line">    mov $128, %al</span><br><span class="line">    add $255, %al</span><br><span class="line">    movl $1, %eax</span><br><span class="line">    movl $0, %ebx</span><br><span class="line">    int $0x80</span><br></pre></td></tr></table></figure>

<p>最后 <code>rax</code> 中的值为127（对应二进制表示为01111111，以有符号数的角度来看，其值为127，即两个负数相加得到一个正数），<code>eflags</code> 中出现了 <code>OF</code> 标志位，说明发生了溢出：</p>
<p><img src="/images/cf-of-8.png" alt="alt"></p>
<p>从有符号数的角度来看，参与运算的两个数的符号位都是1，相加后符号位却是0，所以 <code>OF</code> 设置为1。</p>
<p>所以，<code>OF</code> 的标记取决于运算结果的符号位是否发生变化，这里的变化指的是两个相同符号位的数的运算结果是一个不同符号位的数。</p>
<h2 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h2><p>注意到前面有符号数 <code>-128 - 1</code> 运算的例子中，最后 <code>CF</code> 和 <code>OF</code> 都被设置为了1，说明 <code>CF</code> 和 <code>OF</code> 并不是互斥的关系，在这个例子中即发生了进位又发生了符号位的变更，也就是说如果满足了设置 <code>CF</code> 的条件，那么 <code>CF</code> 就是1，如果满足了设置 <code>OF</code> 的条件，那么 <code>OF</code> 就是1。因此，回到文章开头的问题，<code>CPU</code> 并不是去判断该设置 <code>CF</code> 还是 <code>OF</code>，而是只要条件满足就会设置对应的标志位，而具体应该关注哪个标志位，则交由编译器去判断，因为对 <code>CPU</code> 而言它处理的只是比特运算，只有编译器知道当前的运算数是无符号数还是有符号数。</p>
<p>另外，<code>CF</code> 和 <code>OF</code> 也不能合二为一，无法相互替代，例如两个无符号数相加 <code>CF</code> 有可能是0，但是 <code>OF</code> 却是1，如 <code>127 + 1</code>；两个有符号数相加 <code>OF</code> 有可能是0，但是 <code>CF</code> 却是1，如 <code>-1 - 1</code>。也有可能 <code>CF</code> 和 <code>OF</code> 都是1，如有符号数运算 <code>-128 - 1</code>。</p>
<p>参考：</p>
<ul>
<li><a href="http://teaching.idallen.com/dat2343/10f/notes/040_overflow.txt">The CARRY flag and OVERFLOW flag in binary arithmetic</a></li>
<li><a href="https://niranjanmr.wordpress.com/2016/01/20/eflags-registers/">Eflags Registers</a></li>
<li><a href="https://stackoverflow.com/questions/1817577/what-does-int-0x80-mean-in-assembly-code">What does “int 0x80” mean in assembly code?</a></li>
<li>汇编语言（第4版），王爽</li>
</ul>
]]></content>
      <tags>
        <tag>CPU</tag>
        <tag>Assembly Language</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 Lab 1 (2) - Go Race Detector</title>
    <url>/2022/03/24/mit-6.824-lab1-go-race-detector/</url>
    <content><![CDATA[<p><code>Lab 1</code> 中遇到的第一个命令是 <code>go build -race -buildmode=plugin ../mrapps/wc.go</code>，其中 <code>-race</code> 表示启用 <code>Go</code> 的竞争检测，在多线程编程时，数据竞争是必须要考虑的问题，而数据竞争的问题往往难以察觉和排查，所以 <code>Go</code> 内置了竞争检测的工具来帮助开发人员提前发现问题。另外，<code>MIT 6.824</code> 是一门分布式系统课程，必然会涉及多线程编程，所以竞争检测也是校验 <code>Lab</code> 程序正确性的一种方式。</p>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><code>Go</code> 借助 <code>goroutine</code> 来实现并发编程，所以数据竞争发生在多个 <code>goroutine</code> 并发读写同一个共享变量时，并且至少有一个 <code>goroutine</code> 存在写操作。来看一个简单的例子：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;fmt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    done := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">bool</span>)</span><br><span class="line">    m := <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]<span class="keyword">string</span>)</span><br><span class="line">    m[<span class="string">&quot;name&quot;</span>] = <span class="string">&quot;world&quot;</span></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        m[<span class="string">&quot;name&quot;</span>] = <span class="string">&quot;data race&quot;</span></span><br><span class="line">        done &lt;- <span class="literal">true</span></span><br><span class="line">    &#125;()</span><br><span class="line">    fmt.Println(<span class="string">&quot;Hello,&quot;</span>, m[<span class="string">&quot;name&quot;</span>])</span><br><span class="line">    &lt;-done</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中 <code>m</code> 是一个共享变量，被两个 <code>goroutine</code> 并发读写，将上述代码保存为文件 <code>racy.go</code>，然后开启竞争检测执行：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go run -race racy.go</span><br></pre></td></tr></table></figure>

<p>会输出类似如下内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Hello, world</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">WARNING: DATA RACE</span><br><span class="line">Write at 0x00c00007e180 by goroutine 7:</span><br><span class="line">  runtime.mapassign_faststr()</span><br><span class="line">      &#x2F;usr&#x2F;local&#x2F;go&#x2F;src&#x2F;runtime&#x2F;map_faststr.go:203 +0x0</span><br><span class="line">  main.main.func1()</span><br><span class="line">      &#x2F;path&#x2F;to&#x2F;racy.go:10 +0x50</span><br><span class="line"></span><br><span class="line">Previous read at 0x00c00007e180 by main goroutine:</span><br><span class="line">  runtime.mapaccess1_faststr()</span><br><span class="line">      &#x2F;usr&#x2F;local&#x2F;go&#x2F;src&#x2F;runtime&#x2F;map_faststr.go:13 +0x0</span><br><span class="line">  main.main()</span><br><span class="line">      &#x2F;path&#x2F;to&#x2F;racy.go:13 +0x16b</span><br><span class="line"></span><br><span class="line">Goroutine 7 (running) created at:</span><br><span class="line">  main.main()</span><br><span class="line">      &#x2F;path&#x2F;to&#x2F;racy.go:9 +0x14e</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">WARNING: DATA RACE</span><br><span class="line">Write at 0x00c000114088 by goroutine 7:</span><br><span class="line">  main.main.func1()</span><br><span class="line">      &#x2F;path&#x2F;to&#x2F;racy.go:10 +0x5c</span><br><span class="line"></span><br><span class="line">Previous read at 0x00c000114088 by main goroutine:</span><br><span class="line">  main.main()</span><br><span class="line">      &#x2F;path&#x2F;to&#x2F;racy.go:13 +0x175</span><br><span class="line"></span><br><span class="line">Goroutine 7 (running) created at:</span><br><span class="line">  main.main()</span><br><span class="line">      &#x2F;path&#x2F;to&#x2F;racy.go:9 +0x14e</span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">Found 2 data race(s)</span><br><span class="line">exit status 66</span><br></pre></td></tr></table></figure>

<p>竞争检测会提示第13行和第10行存在数据竞争，一共涉及两个 <code>goroutine</code>，一个是主 <code>goroutine</code>，另一个是手动创建的 <code>goroutine</code>。</p>
<h2 id="典型数据竞争场景"><a href="#典型数据竞争场景" class="headerlink" title="典型数据竞争场景"></a>典型数据竞争场景</h2><h3 id="循环计数器竞争"><a href="#循环计数器竞争" class="headerlink" title="循环计数器竞争"></a>循环计数器竞争</h3><p>这个例子中每次循环时会创建一个 <code>goroutine</code>，每个 <code>goroutine</code> 会打印循环计数器 <code>i</code> 的值：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;sync&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	wg.Add(<span class="number">5</span>)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			fmt.Println(i) <span class="comment">// Not the &#x27;i&#x27; you are looking for.</span></span><br><span class="line">			wg.Done()</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们想要的结果是能输出 <code>01234</code> 这5个值（实际顺序并不一定是 <code>01234</code>），但由于主 <code>goroutine</code> 对 <code>i</code> 的更新和被创建的 <code>goroutine</code> 对 <code>i</code> 的读取之间存在数据竞争，最终的输出结果可能是 <code>55555</code> 也可能是其他值。</p>
<p>如果要修复这个问题，每次创建 <code>goroutine</code> 时复制一份 <code>i</code> 再传给 <code>goroutine</code> 即可：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;sync&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">	wg.Add(<span class="number">5</span>)</span><br><span class="line">	<span class="keyword">for</span> i := <span class="number">0</span>; i &lt; <span class="number">5</span>; i++ &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(j <span class="keyword">int</span>)</span></span> &#123;</span><br><span class="line">			fmt.Println(j) <span class="comment">// Good. Read local copy of the loop counter.</span></span><br><span class="line">			wg.Done()</span><br><span class="line">		&#125;(i)</span><br><span class="line">	&#125;</span><br><span class="line">	wg.Wait()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="意外地共享变量"><a href="#意外地共享变量" class="headerlink" title="意外地共享变量"></a>意外地共享变量</h3><p>在日常开发中，我们可能不经意间在多个 <code>goroutine</code> 间共享了某个变量。在下面的例子中，首先 <code>f1, err := os.Create(&quot;file1&quot;)</code> 会创建一个 <code>err</code> 变量，接着在第一个 <code>goroutine</code> 中对 <code>file1</code> 写入时会对 <code>err</code> 进行更新（<code>_, err = f1.Write(data)</code>），然而在主 <code>goroutine</code> 中创建 <code>file2</code> 时同样会对 <code>err</code> 进行更新（<code>f2, err := os.Create(&quot;file2&quot;)</code>，这里虽然用的是 <code>:=</code>，不过 <code>err</code> 并不是一个新的变量，在同一个作用域下是不允许重复对某个同名变量使用 <code>:=</code> 创建的，因为 <code>f2</code> 是一个新的变量，所以这里可用 <code>:=</code>），这就产生了数据竞争：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;os&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ParallelWrite writes data to file1 and file2, returns the errors.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ParallelWrite</span><span class="params">(data []<span class="keyword">byte</span>)</span> <span class="title">chan</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	res := <span class="built_in">make</span>(<span class="keyword">chan</span> error, <span class="number">2</span>)</span><br><span class="line">	f1, err := os.Create(<span class="string">&quot;file1&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		res &lt;- err</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			<span class="comment">// This err is shared with the main goroutine,</span></span><br><span class="line">			<span class="comment">// so the write races with the write below.</span></span><br><span class="line">			_, err = f1.Write(data)</span><br><span class="line">			res &lt;- err</span><br><span class="line">			f1.Close()</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	f2, err := os.Create(<span class="string">&quot;file2&quot;</span>) <span class="comment">// The second conflicting write to err.</span></span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		res &lt;- err</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			_, err = f2.Write(data)</span><br><span class="line">			res &lt;- err</span><br><span class="line">			f2.Close()</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	err := ParallelWrite([]<span class="keyword">byte</span>(<span class="string">&quot;Hello, world!&quot;</span>))</span><br><span class="line">	&lt;-err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>修复方法也很简单，在每个 <code>goroutine</code> 中使用 <code>:=</code> 创建 <code>err</code> 变量即可：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> <span class="string">&quot;os&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ParallelWrite writes data to file1 and file2, returns the errors.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ParallelWrite</span><span class="params">(data []<span class="keyword">byte</span>)</span> <span class="title">chan</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	res := <span class="built_in">make</span>(<span class="keyword">chan</span> error, <span class="number">2</span>)</span><br><span class="line">	f1, err := os.Create(<span class="string">&quot;file1&quot;</span>)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		res &lt;- err</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			<span class="comment">// This err is shared with the main goroutine,</span></span><br><span class="line">			<span class="comment">// so the write races with the write below.</span></span><br><span class="line">			_, err := f1.Write(data)</span><br><span class="line">			res &lt;- err</span><br><span class="line">			f1.Close()</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	f2, err := os.Create(<span class="string">&quot;file2&quot;</span>) <span class="comment">// The second conflicting write to err.</span></span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		res &lt;- err</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">			_, err := f2.Write(data)</span><br><span class="line">			res &lt;- err</span><br><span class="line">			f2.Close()</span><br><span class="line">		&#125;()</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> res</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	err := ParallelWrite([]<span class="keyword">byte</span>(<span class="string">&quot;Hello, world!&quot;</span>))</span><br><span class="line">	&lt;-err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="未受保护的全局变量"><a href="#未受保护的全局变量" class="headerlink" title="未受保护的全局变量"></a>未受保护的全局变量</h3><p>某个包下对外暴露了 <code>RegisterService</code> 和 <code>LookupService</code> 两个方法，而这两个方法会对同一个 <code>map</code> 变量进行读写，客户端调用时有可能多个 <code>goroutine</code> 并发调用，从而存在数据竞争：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;net&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> service <span class="keyword">map</span>[<span class="keyword">string</span>]net.Addr = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]net.Addr)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">RegisterService</span><span class="params">(name <span class="keyword">string</span>, addr net.Addr)</span></span> &#123;</span><br><span class="line">	service[name] = addr</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">LookupService</span><span class="params">(name <span class="keyword">string</span>)</span> <span class="title">net</span>.<span class="title">Addr</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> service[name]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		RegisterService(<span class="string">&quot;hello&quot;</span>, &amp;net.IPAddr&#123;IP: net.ParseIP(<span class="string">&quot;127.0.0.1&quot;</span>)&#125;)</span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		fmt.Println(LookupService(<span class="string">&quot;hello&quot;</span>))</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以通过 <code>sync.Mutex</code> 来保证可见性：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;net&quot;</span></span><br><span class="line">	<span class="string">&quot;sync&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">	service   <span class="keyword">map</span>[<span class="keyword">string</span>]net.Addr = <span class="built_in">make</span>(<span class="keyword">map</span>[<span class="keyword">string</span>]net.Addr)</span><br><span class="line">	serviceMu sync.Mutex</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">RegisterService</span><span class="params">(name <span class="keyword">string</span>, addr net.Addr)</span></span> &#123;</span><br><span class="line">	serviceMu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> serviceMu.Unlock()</span><br><span class="line">	service[name] = addr</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">LookupService</span><span class="params">(name <span class="keyword">string</span>)</span> <span class="title">net</span>.<span class="title">Addr</span></span> &#123;</span><br><span class="line">	serviceMu.Lock()</span><br><span class="line">	<span class="keyword">defer</span> serviceMu.Unlock()</span><br><span class="line">	<span class="keyword">return</span> service[name]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		RegisterService(<span class="string">&quot;hello&quot;</span>, &amp;net.IPAddr&#123;IP: net.ParseIP(<span class="string">&quot;127.0.0.1&quot;</span>)&#125;)</span><br><span class="line">	&#125;()</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		fmt.Println(LookupService(<span class="string">&quot;hello&quot;</span>))</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="未受保护的基本类型变量"><a href="#未受保护的基本类型变量" class="headerlink" title="未受保护的基本类型变量"></a>未受保护的基本类型变量</h3><p>除了 <code>map</code> 这样的复杂数据类型外，基本类型变量同样会存在数据竞争，如 <code>bool</code>，<code>int</code>，<code>int64</code>。例如在下面的例子中，主 <code>goroutine</code> 对 <code>w.last</code> 的更新和创建的 <code>goroutine</code> 中对 <code>w.last</code> 的读取间存在数据竞争：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;os&quot;</span></span><br><span class="line">	<span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Watchdog <span class="keyword">struct</span>&#123; last <span class="keyword">int64</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *Watchdog)</span> <span class="title">KeepAlive</span><span class="params">()</span></span> &#123;</span><br><span class="line">	w.last = time.Now().UnixNano() <span class="comment">// First conflicting access.</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *Watchdog)</span> <span class="title">Start</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">for</span> &#123;</span><br><span class="line">			time.Sleep(time.Second)</span><br><span class="line">			<span class="comment">// Second conflicting access.</span></span><br><span class="line">			<span class="keyword">if</span> w.last &lt; time.Now().Add(<span class="number">-10</span>*time.Second).UnixNano() &#123;</span><br><span class="line">				fmt.Println(<span class="string">&quot;No keepalives for 10 seconds. Dying.&quot;</span>)</span><br><span class="line">				os.Exit(<span class="number">1</span>)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	watchdog := &amp;Watchdog&#123;&#125;</span><br><span class="line">	watchdog.Start()</span><br><span class="line">	watchdog.KeepAlive()</span><br><span class="line">	<span class="keyword">select</span> &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们依然可以借助 <code>channel</code> 或 <code>sync.Mutex</code> 来修复这个问题，不过类似于 <code>Java</code>，<code>Go</code> 中同样有相应的原子变量来处理基本类型的并发读写，上述例子就可以通过原子包下的 <code>atomic.StoreInt64</code> 和 <code>atomic.LoadInt64</code> 来解决：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;os&quot;</span></span><br><span class="line">	<span class="string">&quot;sync/atomic&quot;</span></span><br><span class="line">	<span class="string">&quot;time&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Watchdog <span class="keyword">struct</span>&#123; last <span class="keyword">int64</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *Watchdog)</span> <span class="title">KeepAlive</span><span class="params">()</span></span> &#123;</span><br><span class="line">	atomic.StoreInt64(&amp;w.last, time.Now().UnixNano())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *Watchdog)</span> <span class="title">Start</span><span class="params">()</span></span> &#123;</span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">		<span class="keyword">for</span> &#123;</span><br><span class="line">			time.Sleep(time.Second)</span><br><span class="line">			<span class="keyword">if</span> atomic.LoadInt64(&amp;w.last) &lt; time.Now().Add(<span class="number">-10</span>*time.Second).UnixNano() &#123;</span><br><span class="line">				fmt.Println(<span class="string">&quot;No keepalives for 10 seconds. Dying.&quot;</span>)</span><br><span class="line">				os.Exit(<span class="number">1</span>)</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;()</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	watchdog := &amp;Watchdog&#123;&#125;</span><br><span class="line">	watchdog.Start()</span><br><span class="line">	watchdog.KeepAlive()</span><br><span class="line">	<span class="keyword">select</span> &#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="未同步的-send-和-close-操作"><a href="#未同步的-send-和-close-操作" class="headerlink" title="未同步的 send 和 close 操作"></a>未同步的 send 和 close 操作</h3><p>虽然对一个 <code>channel</code> 的发送和相应的读取完成之间存在 <code>happens-before</code> 的关系，但是对 <code>channel</code> 的发送和关闭间并没有 <code>happens-before</code> 的保证，依然存在数据竞争：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;) <span class="comment">// or buffered channel</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// The race detector cannot derive the happens before relation</span></span><br><span class="line">	<span class="comment">// for the following send and close operations. These two operations</span></span><br><span class="line">	<span class="comment">// are unsynchronized and happen concurrently.</span></span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c &lt;- <span class="keyword">struct</span>&#123;&#125;&#123;&#125; &#125;()</span><br><span class="line">	<span class="built_in">close</span>(c)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>所以在关闭 <code>channel</code> 前，增加对 <code>channel</code> 的读取操作来保证数据发送完成：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">struct</span>&#123;&#125;) <span class="comment">// or buffered channel</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; c &lt;- <span class="keyword">struct</span>&#123;&#125;&#123;&#125; &#125;()</span><br><span class="line">	&lt;-c</span><br><span class="line">	<span class="built_in">close</span>(c)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="竞争检测的开销"><a href="#竞争检测的开销" class="headerlink" title="竞争检测的开销"></a>竞争检测的开销</h2><p>在开启竞争检测的情况下，程序的内存使用可能会增加5到10倍，性能可能会增加2到20倍，所以一般建议在压力测试或集成测试阶段开启，或者线上集群选择某台机器单独开启。</p>
<p>参考：</p>
<ul>
<li><a href="https://go.dev/blog/race-detector">Introducing the Go Race Detector</a></li>
<li><a href="https://go.dev/doc/articles/race_detector">Data Race Detector</a></li>
<li><a href="https://go.dev/ref/mem">The Go Memory Model</a></li>
</ul>
]]></content>
      <tags>
        <tag>MIT 6.824</tag>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 Lab 1 (3) - Go buildmode</title>
    <url>/2022/03/26/mit-6.824-lab1-go-buildmode-plugin/</url>
    <content><![CDATA[<p><code>Lab 1</code> 中遇到的第一个命令是 <code>go build -race -buildmode=plugin ../mrapps/wc.go</code>，其中 <code>-buildmode=plugin</code> 表示以插件的形式打包源文件，这里的 <code>wc.go</code> 是用户实现的 <code>map</code> 和 <code>reduce</code> 方法，这体现了面向接口编程的思想，只要用户编写的 <code>map</code> 和 <code>reduce</code> 方法遵循统一的签名，则可以在不重新编译 <code>MapReduce</code> 框架代码的情况下，实时替换运行不同的用户应用。</p>
<p>假设有个 <code>sum.go</code> 文件，里面只有一个 <code>Sum</code> 方法：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Sum</span><span class="params">(a <span class="keyword">int</span>, b <span class="keyword">int</span>)</span> <span class="title">int</span></span> &#123;</span><br><span class="line">	<span class="keyword">return</span> a + b</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>对 <code>sum.go</code> 以插件形式编译：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">go build -buildmode&#x3D;plugin sum.go</span><br></pre></td></tr></table></figure>

<p>会生成一个 <code>sum.so</code> 文件。</p>
<p>接着，在 <code>main.go</code> 中就可以通过 <code>plugin.Open</code> 读取 <code>sum.so</code>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">	<span class="string">&quot;fmt&quot;</span></span><br><span class="line">	<span class="string">&quot;log&quot;</span></span><br><span class="line">	<span class="string">&quot;plugin&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">	fileName := <span class="string">&quot;sum.so&quot;</span></span><br><span class="line">	p, err := plugin.Open(fileName)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">&quot;cannot load plugin %v&quot;</span>, fileName)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	sumSymbol, err := p.Lookup(<span class="string">&quot;Sum&quot;</span>)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">&quot;cannot find Map in %v&quot;</span>, fileName)</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	sum := sumSymbol.(<span class="function"><span class="keyword">func</span><span class="params">(<span class="keyword">int</span>, <span class="keyword">int</span>)</span> <span class="title">int</span>)</span></span><br><span class="line"></span><br><span class="line">	fmt.Println(<span class="string">&quot;1 + 2 is&quot;</span>, sum(<span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后通过 <code>Lookup</code> 根据方法名找到 <code>Sum</code> 方法，按照指定方法签名转换后即可进行调用。而如果需要换一个 <code>Sum</code> 的实现，则无需重新编译 <code>main.go</code>。</p>
<p>参考：</p>
<ul>
<li><a href="https://pkg.go.dev/cmd/go#hdr-Build_modes">Build modes</a></li>
</ul>
]]></content>
      <tags>
        <tag>MIT 6.824</tag>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 Lab 1 (4) - 示例程序</title>
    <url>/2022/03/27/mit-6.824-lab1-sequential-mapreduce/</url>
    <content><![CDATA[<p><code>Lab 1</code> 提供了一个串行化的示例 <code>MapReduce</code> 程序，整体分两部分，第一部分是用户自定义的 <code>map</code> 和 <code>reduce</code> 函数，第二部分是框架代码。</p>
<h2 id="用户自定义-map-和-reduce-函数"><a href="#用户自定义-map-和-reduce-函数" class="headerlink" title="用户自定义 map 和 reduce 函数"></a>用户自定义 map 和 reduce 函数</h2><p>以单词计数应用 <code>wc.go</code> 为例，对于 <code>map</code> 函数来说，它的输入键值对类型为 <code>&lt;string, string&gt;</code>，中间结果数据类型为框架定义的 <code>KeyValue</code> 类型，本质上也是个 <code>&lt;string, string&gt;</code> 类型。<code>map</code> 函数首先将文件内容拆分为单词，然后遍历每个单词，输出对应中间结果数据 <code>&lt;w, &quot;1&quot;&gt;</code>：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The map function is called once for each file of input. The first</span></span><br><span class="line"><span class="comment">// argument is the name of the input file, and the second is the</span></span><br><span class="line"><span class="comment">// file&#x27;s complete contents. You should ignore the input file name,</span></span><br><span class="line"><span class="comment">// and look only at the contents argument. The return value is a slice</span></span><br><span class="line"><span class="comment">// of key/value pairs.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Map</span><span class="params">(filename <span class="keyword">string</span>, contents <span class="keyword">string</span>)</span> []<span class="title">mr</span>.<span class="title">KeyValue</span></span> &#123;</span><br><span class="line">	<span class="comment">// function to detect word separators.</span></span><br><span class="line">	ff := <span class="function"><span class="keyword">func</span><span class="params">(r <span class="keyword">rune</span>)</span> <span class="title">bool</span></span> &#123; <span class="keyword">return</span> !unicode.IsLetter(r) &#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// split contents into an array of words.</span></span><br><span class="line">	words := strings.FieldsFunc(contents, ff)</span><br><span class="line"></span><br><span class="line">	kva := []mr.KeyValue&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> _, w := <span class="keyword">range</span> words &#123;</span><br><span class="line">		kv := mr.KeyValue&#123;w, <span class="string">&quot;1&quot;</span>&#125;</span><br><span class="line">		kva = <span class="built_in">append</span>(kva, kv)</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> kva</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>reduce</code> 函数的输出类型为 <code>string</code>，其逻辑较为简单，中间结果数组的长度就是单词的个数：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The reduce function is called once for each key generated by the</span></span><br><span class="line"><span class="comment">// map tasks, with a list of all the values created for that key by</span></span><br><span class="line"><span class="comment">// any map task.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Reduce</span><span class="params">(key <span class="keyword">string</span>, values []<span class="keyword">string</span>)</span> <span class="title">string</span></span> &#123;</span><br><span class="line">	<span class="comment">// return the number of occurrences of this word.</span></span><br><span class="line">	<span class="keyword">return</span> strconv.Itoa(<span class="built_in">len</span>(values))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="框架代码"><a href="#框架代码" class="headerlink" title="框架代码"></a>框架代码</h2><p>我们可以通过 <code>go run -race mrsequential.go wc.so pg*.txt</code> 来运行串行化的 <code>MapReduce</code> 程序，这里的 <code>wc.so</code> 内包含了用户自定义的 <code>map</code> 和 <code>reduce</code> 函数，<code>pg*.txt</code> 则是本次 <code>MapReduce</code> 程序的原始输入数据。</p>
<p>首先，根据入参提供的插件找到用户自定义的 <code>map</code> 和 <code>reduce</code> 函数：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">mapf, reducef := loadPlugin(os.Args[<span class="number">1</span>])</span><br></pre></td></tr></table></figure>

<p>接着，依次读取输入文件的内容，并调用用户自定义的 <code>map</code> 函数，生成一组中间结果数据：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// read each input file,</span></span><br><span class="line"><span class="comment">// pass it to Map,</span></span><br><span class="line"><span class="comment">// accumulate the intermediate Map output.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line">intermediate := []mr.KeyValue&#123;&#125;</span><br><span class="line"><span class="keyword">for</span> _, filename := <span class="keyword">range</span> os.Args[<span class="number">2</span>:] &#123;</span><br><span class="line">	file, err := os.Open(filename)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">&quot;cannot open %v&quot;</span>, filename)</span><br><span class="line">	&#125;</span><br><span class="line">	content, err := ioutil.ReadAll(file)</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Fatalf(<span class="string">&quot;cannot read %v&quot;</span>, filename)</span><br><span class="line">	&#125;</span><br><span class="line">	file.Close()</span><br><span class="line">	kva := mapf(filename, <span class="keyword">string</span>(content))</span><br><span class="line">	intermediate = <span class="built_in">append</span>(intermediate, kva...)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>然后，对所有中间结果数据按照键进行排序，而在 <code>MapReduce</code> 论文中，中间结果数据会经过分片函数分发给不同的 <code>reduce</code> 节点，由 <code>reduce</code> 节点自行排序处理：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// a big difference from real MapReduce is that all the</span></span><br><span class="line"><span class="comment">// intermediate data is in one place, intermediate[],</span></span><br><span class="line"><span class="comment">// rather than being partitioned into NxM buckets.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line">sort.Sort(ByKey(intermediate))</span><br></pre></td></tr></table></figure>

<p>最后，遍历所有中间结果数据，对同键的中间结果数据调用用户自定义的 <code>reduce</code> 函数，并将结果写入到最终输出文件中，同样的，这里也只有一个最终输出文件而不是多个：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">oname := <span class="string">&quot;mr-out-0&quot;</span></span><br><span class="line">ofile, _ := os.Create(oname)</span><br><span class="line"></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// call Reduce on each distinct key in intermediate[],</span></span><br><span class="line"><span class="comment">// and print the result to mr-out-0.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line">i := <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i &lt; <span class="built_in">len</span>(intermediate) &#123;</span><br><span class="line">	j := i + <span class="number">1</span></span><br><span class="line">	<span class="keyword">for</span> j &lt; <span class="built_in">len</span>(intermediate) &amp;&amp; intermediate[j].Key == intermediate[i].Key &#123;</span><br><span class="line">		j++</span><br><span class="line">	&#125;</span><br><span class="line">	values := []<span class="keyword">string</span>&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> k := i; k &lt; j; k++ &#123;</span><br><span class="line">		values = <span class="built_in">append</span>(values, intermediate[k].Value)</span><br><span class="line">	&#125;</span><br><span class="line">	output := reducef(intermediate[i].Key, values)</span><br><span class="line"></span><br><span class="line">	<span class="comment">// this is the correct format for each line of Reduce output.</span></span><br><span class="line">	fmt.Fprintf(ofile, <span class="string">&quot;%v %v\n&quot;</span>, intermediate[i].Key, output)</span><br><span class="line"></span><br><span class="line">	i = j</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ofile.Close()</span><br></pre></td></tr></table></figure>

<p>至此，一个串行化的 <code>MapReduce</code> 程序就完成了。</p>
<p>参考：</p>
<ul>
<li><a href="https://pdos.csail.mit.edu/6.824/labs/lab-mr.html">6.824 Lab 1: MapReduce</a></li>
</ul>
]]></content>
      <tags>
        <tag>MIT 6.824</tag>
        <tag>Go</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 Lab 1 (5) - Go RPC</title>
    <url>/2022/04/04/mit-6.824-lab1-go-rpc/</url>
    <content><![CDATA[<p><code>Lab 1</code> 虽然是个单机器多线程、多进程的程序，但主节点和工作节点的交互依然通过 <code>RPC</code> 实现，<code>Go</code> 本身也提供了开箱即用的 <code>RPC</code> 功能，下面将通过一个简单的求和服务来了解在 <code>Go</code> 中如何实现一个 <code>RPC</code> 服务。</p>
<h2 id="定义请求体和响应体"><a href="#定义请求体和响应体" class="headerlink" title="定义请求体和响应体"></a>定义请求体和响应体</h2><p>请求体和响应体都非常简单，<code>SumRequest</code> 中包含要求和的两个数字，<code>SumReply</code> 中存放求和的结果：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> pb</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> SumRequest <span class="keyword">struct</span> &#123;</span><br><span class="line">	A <span class="keyword">int</span></span><br><span class="line">	B <span class="keyword">int</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> SumReply <span class="keyword">struct</span> &#123;</span><br><span class="line">	Result <span class="keyword">int</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="服务端"><a href="#服务端" class="headerlink" title="服务端"></a>服务端</h2><p>首先定义服务类 <code>SumService</code> 和提供的方法：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="keyword">type</span> SumService <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(sumService *SumService)</span> <span class="title">Sum</span><span class="params">(sumRequest *pb.SumRequest, sumReplay *pb.SumReply)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">	sumReplay.Result = sumRequest.A + sumRequest.B</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>SumService</code> 只有一个 <code>Sum</code> 方法，接收 <code>SumRequest</code> 和 <code>SumReply</code> 两个参数，求和后将结果放回到 <code>SumReply</code> 中（<code>Sum</code> 的方法签名必须是这样的形式，即两个入参和一个 <code>error</code> 类型的出参，具体规则见下文描述）。</p>
<p>然后进行服务注册：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">sumService := &amp;SumService&#123;&#125;</span><br><span class="line">rpc.Register(sumService)</span><br><span class="line">rpc.HandleHTTP()</span><br></pre></td></tr></table></figure>

<p>通过 <code>rpc.Register</code> 这个方法可以知道，一个服务类及其提供的方法必须满足以下条件才能注册成功：</p>
<ol>
<li>服务类必须是公共的</li>
<li>服务类提供的方法必须是公共的</li>
<li>服务类提供的方法入参必须是两个，一个表示请求，一个表示响应（从编码的角度来说方法入参是两个，但是实际代码是判断是否等于3个，因为在这种场景下定义的方法的第一个入参类似于 <code>Java</code> 中的 <code>this</code>）</li>
<li>服务类提供的方法的第一个参数类型必须是公共的或者是 <code>Go</code> 内置的数据类型</li>
<li>服务类提供的方法的第二个参数类型也必须是公共的或者是 <code>Go</code> 内置的数据类型，且必须是指针类型</li>
<li>服务类提供的方法的出参个数只能是1个</li>
<li>服务类提供的方法的出参类型必须是 <code>error</code></li>
</ol>
<p>而 <code>rpc.HandleHTTP()</code> 表示通过 <code>HTTP</code> 作为客户端和服务端间的通信协议，当客户端发起一个 <code>RPC</code> 调用时，本质上是将要调用的方法和参数包装成一个 <code>HTTP</code> 请求，服务端收到 <code>HTTP</code> 请求后，解码出要调用的本地方法名称和入参，然后调用本地方法，在本地方法调用完成后再将结果写入到 <code>HTTP</code> 响应中，客户端收到响应后，再解析出远程调用的结果。</p>
<p><code>rpc.HandleHTTP()</code> 本质上是个 <code>HTTP</code> 路由注册，实际上是调用 <code>Handle(pattern string, handler Handler)</code> 方法，当请求路由匹配 <code>pattern</code> 时，会调用对应的 <code>handler</code> 执行，对于 <code>Go RPC</code> 来说，固定路由路径是 <code>/_goRPC_</code>。</p>
<p>所以，在完成 <code>HTTP</code> 路由注册后，还需要配合开启一个 <code>HTTP</code> 服务，这样才能接受远程服务调用：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">listener, err := net.Listen(<span class="string">&quot;tcp&quot;</span>, <span class="string">&quot;:1234&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">	log.Fatal(<span class="string">&quot;listen error:&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println(<span class="string">&quot;Listening on port 1234&quot;</span>)</span><br><span class="line">http.Serve(listener, <span class="literal">nil</span>)</span><br></pre></td></tr></table></figure>

<p><code>http.Serve</code> 方法中对于每一个客户端的连接，最终会分配一个 <code>goroutine</code> 来调用 <code>Handler</code> 的 <code>ServeHTTP(ResponseWriter, *Request)</code> 方法来处理，对于 <code>Go</code> 的 <code>RPC</code> 包来说，则可以实现该方法来处理 <code>RPC</code> 请求：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ServeHTTP implements an http.Handler that answers RPC requests.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(server *Server)</span> <span class="title">ServeHTTP</span><span class="params">(w http.ResponseWriter, req *http.Request)</span></span> &#123;</span><br><span class="line">	<span class="keyword">if</span> req.Method != <span class="string">&quot;CONNECT&quot;</span> &#123;</span><br><span class="line">		w.Header().Set(<span class="string">&quot;Content-Type&quot;</span>, <span class="string">&quot;text/plain; charset=utf-8&quot;</span>)</span><br><span class="line">		w.WriteHeader(http.StatusMethodNotAllowed)</span><br><span class="line">		io.WriteString(w, <span class="string">&quot;405 must CONNECT\n&quot;</span>)</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	conn, _, err := w.(http.Hijacker).Hijack()</span><br><span class="line">	<span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">		log.Print(<span class="string">&quot;rpc hijacking &quot;</span>, req.RemoteAddr, <span class="string">&quot;: &quot;</span>, err.Error())</span><br><span class="line">		<span class="keyword">return</span></span><br><span class="line">	&#125;</span><br><span class="line">	io.WriteString(conn, <span class="string">&quot;HTTP/1.0 &quot;</span>+connected+<span class="string">&quot;\n\n&quot;</span>)</span><br><span class="line">	server.ServeConn(conn)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h2><p>对于客户端来说，发起远程方法调用前需要先和服务端建立连接：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">client, err := rpc.DialHTTP(<span class="string">&quot;tcp&quot;</span>, <span class="string">&quot;:1234&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">	log.Fatal(<span class="string">&quot;dialing:&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">defer</span> client.Close()</span><br></pre></td></tr></table></figure>

<p>该方法同时返回了一个 <code>RPC</code> 客户端类，内部同时负责对 <code>RPC</code> 请求的编码和解码。</p>
<p>然后通过 <code>client.Call</code> 来发起远程调用：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">sumRequest := &amp;pb.SumRequest&#123;</span><br><span class="line">	A: <span class="number">1</span>,</span><br><span class="line">	B: <span class="number">2</span>,</span><br><span class="line">&#125;</span><br><span class="line">sumReply := &amp;pb.SumReply&#123;&#125;</span><br><span class="line">err = client.Call(<span class="string">&quot;SumService.Sum&quot;</span>, sumRequest, sumReply)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">	log.Fatal(<span class="string">&quot;call error:&quot;</span>, err)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">fmt.Println(<span class="string">&quot;Result:&quot;</span>, sumReply.Result)</span><br></pre></td></tr></table></figure>

<p>这里的调用一共有三个参数，第一个是被调用的远程方法名，需要是 <code>类名.方法名</code> 的形式，后两个则是远程方法的约定入参。</p>
<p>完整的代码可参考 <a href="https://github.com/Frederick-S/go-rpc-demo">go-rpc-demo</a>。</p>
<p>参考：</p>
<ul>
<li><a href="https://pdos.csail.mit.edu/6.824/labs/lab-mr.html">6.824 Lab 1: MapReduce</a></li>
</ul>
]]></content>
      <tags>
        <tag>MIT 6.824</tag>
        <tag>Go</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 Lab 1 (6) - 实现</title>
    <url>/2022/04/10/mit-6.824-lab1-implementation/</url>
    <content><![CDATA[<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p><code>Lab 1</code> 需要我们实现一个单机多线程、多进程的 <code>MapReduce</code> 程序，通过 <code>test-mr.sh</code> 可以看到该实验会先启动一个主节点进程，然后再启动多个工作节点进程。</p>
<h2 id="主节点"><a href="#主节点" class="headerlink" title="主节点"></a>主节点</h2><p>主节点的入口是 <code>mrcoordinator.go</code>，通过 <code>go run mrcoordinator.go pg*.txt</code> 可运行一个主节点程序，其中 <code>pg*.txt</code> 是本次 <code>MapReduce</code> 程序的输入数据。同时，主节点和工作节点间通过 <code>RPC</code> 进行交互，本实验需要我们实现以下 <code>RPC</code> 接口：</p>
<ol>
<li>实验中主节点的任务分发采用的是拉模式，工作节点会定期向主节点请求一个任务，这个任务可以是 <code>map</code> 任务也可以是 <code>reduce</code> 任务，由主节点根据当前任务的状态决定应该推送 <code>map</code> 任务还是 <code>reduce</code> 任务。由于 <code>reduce</code> 任务会不间断的拉取中间结果数据，这里为了方便处理，当某个工作节点正在处理 <code>reduce</code> 任务时，在向主节点请求任务时可指明要求分发对应的 <code>reduce</code> 任务</li>
<li><code>map</code> 任务完成后需要通知主节点生成的中间结果文件地址，主节点收到请求后需要将中间结果文件地址保存到内部数据结构中，供后续发送给对应 <code>reduce</code> 任务</li>
<li><code>reduce</code> 任务完成后同样需要通知主节点任务完成，否则主节点无法知晓所有 <code>reduce</code> 任务是否已完成，从而无法退出主节点</li>
</ol>
<h3 id="任务管理"><a href="#任务管理" class="headerlink" title="任务管理"></a>任务管理</h3><p>主节点需要维护所有 <code>map</code> 任务和 <code>reduce</code> 任务的状态，由于工作节点有可能失败，所以主节点需要同时记录每个任务已执行了多久，如果超过一定时间还没有收到任务完成的通知，则认为执行这个任务的工作节点已失联，然后需要将该任务重新分配给其他工作节点，在本实验中主节点等待每个任务完成的时间为10秒。</p>
<h2 id="工作节点"><a href="#工作节点" class="headerlink" title="工作节点"></a>工作节点</h2><p>工作节点的入口是 <code>mrworker.go</code>，通过 <code>go run mrworker.go wc.so</code> 可运行一个工作节点程序，其中 <code>wc.so</code> 是本次 <code>MapReduce</code> 程序用到的用户自定义 <code>map</code> 和 <code>reduce</code> 函数。工作节点只有一个 <code>Worker</code> 主方法，需要不断向主节点轮询请求任务，那么工作节点什么时候结束轮询？根据实验建议有两种方法，一种是当本次 <code>MapReduce</code> 任务完成后，主节点进程退出，当工作节点再次请求主节点任务时，<code>RPC</code> 请求必然失败，此时工作节点可认为本次任务已完成主节点已退出，从而结束轮询并退出；另一种是当主节点完成后，在一定时间内，在收到工作节点新的任务请求时，返回一个要求工作节点退出的标识（或者也可抽象为一种任务类型），工作节点收到 <code>RPC</code> 响应后退出，主节点在等待时间到了之后也进行退出。</p>
<h3 id="空任务"><a href="#空任务" class="headerlink" title="空任务"></a>空任务</h3><p>当工作节点向主节点申请任务，而此时主节点没有可分发的任务时，主节点可返回一个自定义任务类型的任务，来表示空任务，工作节点收到响应后则直接睡眠等待下次唤醒。</p>
<h3 id="map-任务"><a href="#map-任务" class="headerlink" title="map 任务"></a>map 任务</h3><p><code>map</code> 任务负责调用用户自定义的 <code>map</code> 函数，生成一组中间结果数据，然后将中间结果数据保存为文件，实验建议的文件名是 <code>mr-X-Y</code>，其中 <code>X</code> 表示 <code>map</code> 任务的编号，<code>Y</code> 表示 <code>reduce</code> 任务的编号，<code>map</code> 任务编号的范围可简单使用 <code>[1, 输入文件的数量]</code> 来表示，<code>reduce</code> 任务编号的范围为 <code>[1, nReduce]</code>。每个 <code>map</code> 任务会生成 <code>R</code> 个中间结果文件，实验已提供了分片函数，对中间结果的每个键使用 <code>ihash(key) % nReduce</code> 来决定写入到哪个中间结果文件中。</p>
<p>从数据结构角度来说，所有的中间结果数据是一个 <code>nReduce * nMap</code> 的二维矩阵，每一行对应一个 <code>reduce</code> 任务。</p>
<p>由于 <code>map</code> 节点有可能执行失败，为避免 <code>reduce</code> 节点读取到的是未写入完成的中间结果文件，在写入中间结果文件时可以先写入一个临时文件，在写入完成后再重命名为最终的文件名。在本实验中，可以使用 <code>ioutil.TempFile</code> 来创建临时文件，以及使用 <code>os.Rename</code> 来原子性的重命名文件。</p>
<p>在当前 <code>map</code> 任务的中间结果文件写入完成后，需要通过 <code>RPC</code> 请求通知主节点所有中间结果文件的文件地址。在本实验中，各个工作节点运行在同一台机器上，实验要求保存 <code>map</code> 任务的中间结果文件到当前文件夹，这样 <code>reduce</code> 任务就能通过中间结果文件的文件名读取中间结果数据。</p>
<p>对中间结果数据的写文件可以借助 <code>Go</code> 的 <code>encoding/json</code> 模块，例如：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">enc := json.NewEncoder(file)</span><br><span class="line"><span class="keyword">for</span> _, kv := ... &#123;</span><br><span class="line">    err := enc.Encode(&amp;kv)</span><br></pre></td></tr></table></figure>

<p>然后 <code>reduce</code> 任务读取文件：</p>
<figure class="highlight go"><table><tr><td class="code"><pre><span class="line">dec := json.NewDecoder(file)</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">    <span class="keyword">var</span> kv KeyValue</span><br><span class="line">    <span class="keyword">if</span> err := dec.Decode(&amp;kv); err != <span class="literal">nil</span> &#123;</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    &#125;</span><br><span class="line">    kva = <span class="built_in">append</span>(kva, kv)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="reduce-任务"><a href="#reduce-任务" class="headerlink" title="reduce 任务"></a>reduce 任务</h3><p><code>reduce</code> 任务负责将所有中间结果数据按照键排序后应用用户自定义的 <code>reduce</code> 函数，并生成最终输出文件，文件格式为 <code>mr-out-X</code>，其中 <code>X</code> 表示 <code>reduce</code> 任务的编号。文件中的每一行对应一个 <code>reduce</code> 函数调用的结果，需要按照 <code>Go</code> 的 <code>%v %v</code> 形式对键值对进行格式化。</p>
<p>在收到所有的中间结果数据之前，<code>reduce</code> 任务无法开始执行，所以在这个期间当工作节点请求 <code>reduce</code> 任务时，如果主节点暂时没有新的 <code>reduce</code> 任务可分发，则可返回一个空任务，工作节点收到响应后则暂时等待一段时间再重新请求任务。<code>reduce</code> 每次收到中间结果数据后会暂存在内存中，如果暂存的中间结果数据的数量等于 <code>map</code> 任务的数量（这个值可以放在 <code>RPC</code> 响应中），则说明所有中间结果数据已经接收完毕，可以开始执行 <code>reduce</code> 任务。</p>
<h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p><code>mrworker.go</code> 中注释描述通过 <code>go run mrworker.go wc.so</code> 来运行工作节点，不过如果构建 <code>wc.so</code> 时开启了竞争检测（<code>-race</code>），则运行 <code>mrworker.go</code> 时也同样需要开启竞争检测，否则会提示 <code>cannot load plugin wc.so</code>，如果打印 <code>err</code> 则会显示 <code>plugin.Open(&quot;wc&quot;): plugin was built with a different version of package runtime</code>。</p>
<p>同样的，如果使用 <code>GoLand</code> 调试程序，由于在调试模式下 <code>GoLand</code> 编译 <code>Go</code> 文件时会增加 <code>-gcflags=&quot;all=-N -l&quot;</code> 参数，所以也需要在打包 <code>wc.so</code> 时增加相同的参数。</p>
<h2 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h2><p>在最后的 <code>crash test</code> 遇到个类似活锁的问题，在前文提到，如果某个工作节点开始了 <code>reduce</code> 任务但是还没有接收全部的中间结果数据，则该节点下次申请任务时会继续申请该 <code>reduce</code> 任务（普通工作节点对申请的任务类型没有要求）。在 <code>crash test</code> 下，工作节点在执行用户自定义的 <code>map</code> 或 <code>reduce</code> 函数时有一定概率结束进程，假设现在有4个工作节点，其中一个在执行 <code>map</code> 任务，另外三个各自在执行 <code>reduce</code> 任务（轮询获取中间结果数据），不幸的是<br>这个时候 <code>map</code> 节点挂了，此时 <code>test-mr.sh</code> 会自动再启动一个工作节点，然后更不幸的是挂掉的 <code>map</code> 任务在主节点看来还没有到超时时间，所以主节点此时不会分配 <code>map</code> 任务给新的节点（假设没有其他 <code>map</code> 任务），会再分配一个 <code>reduce</code> 任务给新的节点，至此所有工作节点都在执行 <code>reduce</code> 任务，又都在等待中间结果数据完成，却又不可能完成。</p>
<p>造成这个问题的主要原因是任务分配顺序，上述问题下的任务分配顺序是：</p>
<ol>
<li>指定的 <code>reduce</code> 任务</li>
<li>空闲或超时的 <code>map</code> 任务</li>
<li>空闲或超时的 <code>reduce</code> 任务</li>
</ol>
<p>解决方法就是把前两个换下顺序即可，即：</p>
<ol>
<li>空闲或超时的 <code>map</code> 任务</li>
<li>指定的 <code>reduce</code> 任务</li>
<li>空闲或超时的 <code>reduce</code> 任务</li>
</ol>
<p>参考：</p>
<ul>
<li><a href="https://pdos.csail.mit.edu/6.824/labs/lab-mr.html">6.824 Lab 1: MapReduce</a></li>
</ul>
]]></content>
      <tags>
        <tag>MIT 6.824</tag>
        <tag>Go</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 Lab 1 (1) - MapReduce: Simplified Data Processing on Large Clusters</title>
    <url>/2022/02/13/mit-6.824-lab1-map-reduce/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><code>MapReduce: Simplified Data Processing on Large Clusters</code> 是 <a href="https://pdos.csail.mit.edu/6.824/">6.824: Distributed Systems</a> 中所介绍的第一篇论文。它提出了一种针对大数据处理的编程模型和实现，使得编程人员无需并行和分布式系统经验就可以轻松构建大数据处理应用。该模型将大数据处理问题拆解为两步，即 <code>map</code> 和 <code>reduce</code>，<code>map</code> 阶段将一组输入的键值对转化为中间结果键值对，<code>reduce</code> 阶段对中间结果键值对按照相同的键进行值的合并，从而得到最终的结果。</p>
<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>对于 <code>Google</code> 来说，每天运行的系统会产生大量的原始数据，同时又要对这些原始数据进行加工产生各种衍生数据，虽然大部分数据加工的逻辑都较为简单，然而由于数据量过于庞大，为了在合理的时间内完成数据处理，通常需要将待处理的数据分发到几百或几千台机器上并行计算，这就存在几个问题：</p>
<ol>
<li>如何使计算可并行</li>
<li>如何分发数据</li>
<li>如何处理异常</li>
</ol>
<p>如果每一个数据加工任务都需要独立去解决上述的问题，一方面会使得原本简单的代码逻辑变得庞大、复杂和难以维护，另一方面也是在重复工作。受 <code>Lisp</code> 等其他函数式编程语言中的 <code>map</code> 和 <code>reduce</code> 函数的启发，<code>Google</code> 的工程师们发现大部分的数据处理遵循如下的模式：</p>
<ol>
<li>对输入的每一条数据应用一个 <code>map</code> 函数产生一组中间结果键值对</li>
<li>对中间结果键值对按照相同的键聚合后，应用 <code>reduce</code> 函数生成最终的衍生数据</li>
</ol>
<p>因此，<code>Google</code> 的工程师们抽象出了 <code>MapReduce</code> 框架，使得应用开发人员可以专注于计算逻辑实现而无需关心底层运行细节，统一由框架层处理并行、容错、数据分发和负载均衡等系统问题。现在再来看前面提到的问题是如何解决的：</p>
<ol>
<li>如何使计算可并行：在 <code>map</code> 阶段，对数据分发后，各任务间无依赖，可并行执行；在 <code>reduce</code> 阶段，不同 <code>key</code> 的数据处理间无依赖，可并行执行</li>
<li>如何分发数据：在 <code>map</code> 阶段，可按执行 <code>map</code> 任务的节点数量平均分发（这只是一种可能的策略，具体分发策略见后文描述）；在 <code>reduce</code> 阶段，可按 <code>key</code> 相同的数据聚合后分发</li>
<li>如何处理异常：重新执行某个节点上失败的 <code>map</code> 或 <code>reduce</code> 任务作为首要的容错手段</li>
</ol>
<h2 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h2><p>假设需要统计一组文档中每个单词出现的次数，在 <code>MapReduce</code> 框架下用户需要编写 <code>map</code> 和 <code>reduce</code> 函数，近似的伪代码表示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">map(String key, String value):</span><br><span class="line">    &#x2F;&#x2F; key: document name</span><br><span class="line">    &#x2F;&#x2F; value: document contents</span><br><span class="line">    for each word w in value:</span><br><span class="line">        EmitIntermediate(w, &quot;1&quot;);</span><br><span class="line"></span><br><span class="line">reduce(String key, Iterator values):</span><br><span class="line">    &#x2F;&#x2F; key: a word</span><br><span class="line">    &#x2F;&#x2F; values: a list of counts</span><br><span class="line">    int result &#x3D; 0;</span><br><span class="line">    for each v in values:</span><br><span class="line">        result +&#x3D; ParseInt(v);</span><br><span class="line">    Emit(AsString(result));</span><br></pre></td></tr></table></figure>

<p>假设有两个文档 <code>hello.txt</code> 和 <code>world.txt</code>，其内容分别为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hello.txt:</span><br><span class="line">It was the best of times</span><br><span class="line"></span><br><span class="line">world.txt:</span><br><span class="line">it was the worst of times</span><br></pre></td></tr></table></figure>

<p>对上述 <code>map</code> 和 <code>reduce</code> 函数来说，<code>map</code> 函数每次处理一个文档，<code>key</code> 为文档的名称，<code>value</code> 为文档的内容，即：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">map(&quot;hello.txt&quot;, &quot;It was the best of times&quot;)</span><br><span class="line">map(&quot;world.txt&quot;, &quot;it was the worst of times&quot;)</span><br></pre></td></tr></table></figure>

<p><code>map</code> 函数执行时会遍历文档的内容，对每个单词输出中间结果键值对（作为示例，这里省去了将文档内容拆分为单词的过程，同时也忽略了标点符号、大小写等与示例无关的内容），键为单词，值为 <code>&quot;1&quot;</code>，所有 <code>map</code> 函数执行完成后生成的中间结果为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hello.txt:</span><br><span class="line">it 1</span><br><span class="line">was 1</span><br><span class="line">the 1</span><br><span class="line">best 1</span><br><span class="line">of 1</span><br><span class="line">times 1</span><br><span class="line"></span><br><span class="line">world.txt:</span><br><span class="line">it 1</span><br><span class="line">was 1</span><br><span class="line">the 1</span><br><span class="line">worst 1</span><br><span class="line">of 1</span><br><span class="line">times 1</span><br></pre></td></tr></table></figure>

<p>然后，<code>MapReduce</code> 框架对所有中间结果按照相同的键进行聚合，即：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">it [&quot;1&quot;, &quot;1&quot;]</span><br><span class="line">was [&quot;1&quot;, &quot;1&quot;]</span><br><span class="line">the [&quot;1&quot;, &quot;1&quot;]</span><br><span class="line">best [&quot;1&quot;]</span><br><span class="line">worst [&quot;1&quot;]</span><br><span class="line">of [&quot;1&quot;, &quot;1&quot;]</span><br><span class="line">times [&quot;1&quot;, &quot;1&quot;]</span><br></pre></td></tr></table></figure>

<p>最后，<code>MapReduce</code> 框架将上述聚合后的数据分发给 <code>reduce</code> 函数执行，即：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reduce(&quot;it&quot;, [&quot;1&quot;, &quot;1&quot;])</span><br><span class="line">reduce(&quot;was&quot;, [&quot;1&quot;, &quot;1&quot;])</span><br><span class="line">reduce(&quot;the&quot;, [&quot;1&quot;, &quot;1&quot;])</span><br><span class="line">reduce(&quot;best&quot;, [&quot;1&quot;])</span><br><span class="line">reduce(&quot;worst&quot;, [&quot;1&quot;])</span><br><span class="line">reduce(&quot;of&quot;, [&quot;1&quot;, &quot;1&quot;])</span><br><span class="line">reduce(&quot;times&quot;, [&quot;1&quot;, &quot;1&quot;])</span><br></pre></td></tr></table></figure>

<p><code>reduce</code> 函数执行时会遍历 <code>values</code>，将每个字符串转换为整型后累加，然后作为 <code>reduce</code> 的结果返回，最终得到所有单词出现的次数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">it 2</span><br><span class="line">was 2</span><br><span class="line">the 2</span><br><span class="line">best 1</span><br><span class="line">worst 1</span><br><span class="line">of 2</span><br><span class="line">times 2</span><br></pre></td></tr></table></figure>

<p>实际执行 <code>reduce</code> 函数时，并不会将 <code>values</code> 一次性传给某个 <code>reduce</code> 函数，因为有可能数据量太大无法完全载入内存，所以 <code>values</code> 在实现时是个迭代器，<code>reduce</code> 函数能以流式的形式获取值。</p>
<p>另外，虽然在上述的例子中 <code>map</code> 和 <code>reduce</code> 处理的都是字符串类型的数据，但是也可以支持其他类型的数据，<code>map</code> 和 <code>reduce</code> 处理的数据类型遵循如下的模式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">map (k1, v1) -&gt; list(k2, v2)</span><br><span class="line">reduce (k2, list(v2)) -&gt; list(v2)</span><br></pre></td></tr></table></figure>

<p>可以看到，<code>map</code> 产生的中间结果的数据类型和最终结果的数据类型是一致的。对整个框架来说，最初的输入和最终的输出都是某种形式的字节流或字符串，因此在 <code>Google</code> 的 <code>C++</code> 实现中，提供了专门的数据转换接口，用户可实现该接口用于字符串和 <code>map</code>、<code>reduce</code> 需要的数据类型之间转换。</p>
<h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p><code>MapReduce</code> 的具体实现视硬件环境的不同而不同，论文中描述的实现是针对 <code>Google</code> 内部广泛使用的硬件环境，即通过交换以太网相连的大量廉价 <code>PC</code> 组成的集群：</p>
<ol>
<li>每台机器的配置一般为双核 <code>x86</code> 处理器，<code>2-4 GB</code> 内存，运行 <code>Linux</code> 系统</li>
<li>使用廉价网络硬件，带宽一般为 <code>100 Mbit/s</code> 或 <code>1 Gbit/s</code>，不过平均来说会小于 <code>bisection bandwidth</code>（<code>bisection bandwidth</code> 指当某个网络被分成两部分时，这两部分间的带宽）</li>
<li>一个集群一般由几百上千台机器组成，所以机器异常是家常便饭</li>
<li>存储使用的是廉价的 <code>IDE</code> 硬盘，并直接装载到了机器上。不过 <code>Google</code> 内部实现了一套分布式文件存储系统来管理这些硬盘上的数据，并通过数据冗余作为在不可靠的硬件上实现可用性和可靠性的手段。</li>
<li>用户向调度系统提交一组任务，每个任务包含多个子任务，调度系统会为每个任务分配一批集群内的机器执行。</li>
</ol>
<h3 id="执行概览"><a href="#执行概览" class="headerlink" title="执行概览"></a>执行概览</h3><p>在 <code>map</code> 执行阶段，框架会自动将输入数据分为 <code>M</code> 片，从而将 <code>map</code> 任务分发到多台机器上并行执行，每台机器只处理某一片的数据。同样的，在 <code>reduce</code> 阶段，框架首先将中间结果数据根据分片函数（例如 <code>hash(key) mod R</code>）拆分为 <code>R</code> 片，然后分发给 <code>reduce</code> 任务执行，用户可自行指定 <code>R</code> 的值和实现具体的分片函数。</p>
<p>下图展示了 <code>Google</code> 所实现的 <code>MapReduce</code> 框架的整体执行流程：</p>
<p><img src="/images/map-reduce.png" alt="alt"></p>
<p>当用户提交 <code>MapReduce</code> 任务后，框架会执行以下一系列流程（下文中的序号和上图中的序号对应）：</p>
<ol>
<li>首先 <code>MapReduce</code> 框架将输入数据分为 <code>M</code> 片，每片数据大小一般为 <code>16 MB</code> 至 <code>64 MB</code>（具体大小可由用户入参控制），然后将 <code>MapReduce</code> 程序复制到集群中的一批机器上运行。</li>
<li>在所有的程序拷贝中，某台机器上的程序会成为主节点（<code>master</code>），其余称为工作节点（<code>worker</code>），由主节点向工作节点分派任务，一共有 <code>M</code> 个 <code>map</code> 任务和 <code>R</code> 个 <code>reduce</code> 任务需要分派。主节点会选择空闲的工作节点分派 <code>map</code> 或 <code>reduce</code> 任务。</li>
<li>如果某个工作节点被分派了 <code>map</code> 任务则会读取当前的数据分片，然后将输入数据解析为一组键值对后传递给用户自定义的 <code>map</code> 函数执行。<code>map</code> 函数产生的中间结果键值对会暂存在内存中。</li>
<li>暂存在内存中的中间结果键值对会周期性的写入到本地磁盘中，并根据某个分片函数将这些数据写入到本地磁盘下的 <code>R</code> 个区，这样相同键的中间结果数据在不同的 <code>map</code> 节点下属于同一个区号，就可以在后续将同一个键的中间结果数据全部发给同一个 <code>reduce</code> 节点。同时，这些数据写入后的地址会回传给 <code>master</code> 节点，<code>master</code> 节点会将这些数据的地址发送给相应的 <code>reduce</code> 节点。</li>
<li>当 <code>reduce</code> 节点接收到 <code>master</code> 节点发送的中间结果数据地址通知后，将通过 <code>RPC</code> 请求根据数据地址读取 <code>map</code> 节点生成的数据。在所有中间结果数据都读取完成后，<code>reduce</code> 节点会先将所有中间结果数据按照键进行排序，这样所有键相同的数据就聚合在了一起。之所以要排序是因为一个 <code>reduce</code> 节点会分发处理多个键下的中间结果数据。如果中间结果数据量太大不足以完全载入内存，则需要使用外部排序。</li>
<li><code>reduce</code> 节点执行时会先遍历排序后的中间结果数据，每遇到一个新的键就会将该键及其对应的所有中间结果数据传递给用户自定义的 <code>reduce</code> 函数执行。<code>reduce</code> 函数执行的结果数据会追加到当前 <code>reduce</code> 节点的最终输出文件里。</li>
<li>当所有 <code>map</code> 任务和 <code>reduce</code> 任务都执行完成后，<code>master</code> 节点会唤醒用户程序，并将控制权交还给用户代码。</li>
</ol>
<p>当成功结束 <code>MapReduce</code> 任务后，其执行结果就保存在了 <code>R</code> 个文件中（每个文件对应一个 <code>reduce</code> 节点的产出，文件的名字由用户所指定）。一般来说，用户不必将这 <code>R</code> 个输出文件合并成一个，它们通常会作为另一个 <code>MapReduce</code> 任务的输入，或交由其他分布式应用处理。</p>
<p>基于上述流程，再来看在 <code>编程模型</code> 这节中的例子。假设有6个文档，分别是 <code>1.txt</code> 到 <code>6.txt</code>，每个文档中的内容为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.txt:</span><br><span class="line">It was the best of times</span><br><span class="line"></span><br><span class="line">2.txt:</span><br><span class="line">it was the worst of times</span><br><span class="line"></span><br><span class="line">3.txt:</span><br><span class="line">it was the age of wisdom</span><br><span class="line"></span><br><span class="line">4.txt:</span><br><span class="line">it was the age of foolishness</span><br><span class="line"></span><br><span class="line">5.txt:</span><br><span class="line">it was the epoch of belief</span><br><span class="line"></span><br><span class="line">6.txt:</span><br><span class="line">it was the epoch of incredulity</span><br></pre></td></tr></table></figure>

<p>对应 <code>MapReduce</code> 执行流程为：</p>
<ol>
<li>我们假设每两个文档的数据大小为 <code>16 MB</code>，则6个文档对应3片数据</li>
<li>由1所知一共有3个 <code>map</code> 任务，不妨将 <code>reduce</code> 任务也设为3个，并将6个文档按顺序每两个一组依次分发给每个 <code>map</code> 节点</li>
<li>每个 <code>map</code> 节点处理的数据分片为两个文档，所产生的中间结果数据分别为： <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">map worker 1:</span><br><span class="line">it 1</span><br><span class="line">was 1</span><br><span class="line">the 1</span><br><span class="line">best 1</span><br><span class="line">of 1</span><br><span class="line">times 1</span><br><span class="line">it 1</span><br><span class="line">was 1</span><br><span class="line">the 1</span><br><span class="line">worst 1</span><br><span class="line">of 1</span><br><span class="line">times 1</span><br><span class="line"></span><br><span class="line">map worker 2:</span><br><span class="line">it 1</span><br><span class="line">was 1</span><br><span class="line">the 1</span><br><span class="line">age 1</span><br><span class="line">of 1</span><br><span class="line">wisdom 1</span><br><span class="line">it 1</span><br><span class="line">was 1</span><br><span class="line">the 1</span><br><span class="line">age 1</span><br><span class="line">of 1</span><br><span class="line">foolishness 1</span><br><span class="line"></span><br><span class="line">map worker 3:</span><br><span class="line">it 1</span><br><span class="line">was 1</span><br><span class="line">the 1</span><br><span class="line">epoch 1</span><br><span class="line">of 1</span><br><span class="line">belief 1</span><br><span class="line">it 1</span><br><span class="line">was 1</span><br><span class="line">the 1</span><br><span class="line">epoch 1</span><br><span class="line">of 1</span><br><span class="line">incredulity 1</span><br></pre></td></tr></table></figure></li>
<li>在每个 <code>map</code> 节点上将中间结果数据按照某个哈希函数分发到3个区，不妨为以下结果： <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">map worker 1:</span><br><span class="line">    region 1:</span><br><span class="line">    it 1</span><br><span class="line">    best 1</span><br><span class="line">    it 1</span><br><span class="line"></span><br><span class="line">    region 2:</span><br><span class="line">    was 1</span><br><span class="line">    of 1</span><br><span class="line">    was 1</span><br><span class="line">    worst 1</span><br><span class="line">    of 1</span><br><span class="line"></span><br><span class="line">    region 3:</span><br><span class="line">    the 1</span><br><span class="line">    times 1</span><br><span class="line">    the 1</span><br><span class="line">    times 1</span><br><span class="line"></span><br><span class="line">map worker 2:</span><br><span class="line">    region 1:</span><br><span class="line">    it 1</span><br><span class="line">    age 1</span><br><span class="line">    it 1</span><br><span class="line">    age 1</span><br><span class="line">    foolishness 1</span><br><span class="line"></span><br><span class="line">    region 2:</span><br><span class="line">    was 1</span><br><span class="line">    of 1</span><br><span class="line">    of 1</span><br><span class="line">    wisdom 1</span><br><span class="line">    was 1</span><br><span class="line"></span><br><span class="line">    region 3:</span><br><span class="line">    the 1</span><br><span class="line">    the 1</span><br><span class="line"></span><br><span class="line">map worker 3:</span><br><span class="line">    region 1:</span><br><span class="line">    it 1</span><br><span class="line">    epoch 1</span><br><span class="line">    belief 1</span><br><span class="line">    it 1</span><br><span class="line">    epoch 1</span><br><span class="line">    </span><br><span class="line">    region 2:</span><br><span class="line">    was 1</span><br><span class="line">    of 1</span><br><span class="line">    was 1</span><br><span class="line">    of 1</span><br><span class="line">    </span><br><span class="line">    region 3:</span><br><span class="line">    the 1</span><br><span class="line">    the 1</span><br><span class="line">    incredulity 1</span><br></pre></td></tr></table></figure></li>
<li><code>reduce</code> 节点按照数据分区接收到所有中间结果数据后将其按照键排序： <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reduce worker 1:</span><br><span class="line">age 1</span><br><span class="line">age 1</span><br><span class="line">belief 1</span><br><span class="line">best 1</span><br><span class="line">epoch 1</span><br><span class="line">epoch 1</span><br><span class="line">foolishness 1</span><br><span class="line">it 1</span><br><span class="line">it 1</span><br><span class="line">it 1</span><br><span class="line">it 1</span><br><span class="line">it 1</span><br><span class="line">it 1</span><br><span class="line"></span><br><span class="line">reduce worker 2:</span><br><span class="line">of 1</span><br><span class="line">of 1</span><br><span class="line">of 1</span><br><span class="line">of 1</span><br><span class="line">of 1</span><br><span class="line">of 1</span><br><span class="line">was 1</span><br><span class="line">was 1</span><br><span class="line">was 1</span><br><span class="line">was 1</span><br><span class="line">was 1</span><br><span class="line">was 1</span><br><span class="line">wisdom 1</span><br><span class="line">worst 1</span><br><span class="line"></span><br><span class="line">reduce worker 3:</span><br><span class="line">incredulity 1</span><br><span class="line">the 1</span><br><span class="line">the 1</span><br><span class="line">the 1</span><br><span class="line">the 1</span><br><span class="line">the 1</span><br><span class="line">the 1</span><br><span class="line">times 1</span><br><span class="line">times 1</span><br></pre></td></tr></table></figure></li>
<li><code>reduce</code> 节点调用用户自定义 <code>reduce</code> 函数计算单词出现次数，最终每个 <code>reduce</code> 节点的输出文件为： <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reduce worker 1 output:</span><br><span class="line">age 2</span><br><span class="line">belief 1</span><br><span class="line">best 1</span><br><span class="line">epoch 2</span><br><span class="line">foolishness 1</span><br><span class="line">it 6</span><br><span class="line"></span><br><span class="line">reduce worker 2 output:</span><br><span class="line">of 6</span><br><span class="line">was 6</span><br><span class="line">wisdom 1</span><br><span class="line">worst 1</span><br><span class="line"></span><br><span class="line">reduce worker 3 output:</span><br><span class="line">incredulity 1</span><br><span class="line">the 6</span><br><span class="line">times 2</span><br></pre></td></tr></table></figure></li>
<li>将代码控制权交还给用户代码</li>
</ol>
<h3 id="Master-节点数据结构"><a href="#Master-节点数据结构" class="headerlink" title="Master 节点数据结构"></a>Master 节点数据结构</h3><p><code>master</code> 节点需要维护当前所有的 <code>map</code> 和 <code>reduce</code> 任务，每个任务需区分不同的状态（空闲、进行中、完成），同时还需要知道每个任务对应的工作节点。作为 <code>map</code> 节点和 <code>reduce</code> 节点间中间结果数据的传输媒介，<code>master</code> 节点需保存 <code>R</code> 个中间结果分区，每当一个 <code>map</code> 节点执行成功时，会将生成的 <code>R</code> 个中间结果文件地址发送给 <code>master</code> 节点，当 <code>master</code> 节点收到通知后，会将其转发给对应进行中的 <code>reduce</code> 节点。</p>
<p>对应数据结构简单示例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 任务状态</span><br><span class="line">enum TaskState &#123;</span><br><span class="line">    &#x2F;&#x2F; 空闲</span><br><span class="line">    Idle,</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 进行中</span><br><span class="line">    InProgress,</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 完成</span><br><span class="line">    Completed</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 一个 map 或 reduce 任务</span><br><span class="line">class Task &#123;</span><br><span class="line">    &#x2F;&#x2F; 任务状态</span><br><span class="line">    TaskState state;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 对应的工作节点 id</span><br><span class="line">    int workerId;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 工作节点</span><br><span class="line">class Worker &#123;</span><br><span class="line">    &#x2F;&#x2F; 节点 id</span><br><span class="line">    int id;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Map 任务产生的中间结果文件，一个 map 任务一般会产生多个中间结果文件</span><br><span class="line">class IntermediateFile &#123;</span><br><span class="line">    &#x2F;&#x2F; 文件地址</span><br><span class="line">    string location;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 文件大小</span><br><span class="line">    long size;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 中间结果文件集，所有 map 任务产生的中间结果文件会根据分片函数划分到本地磁盘下的 R 个区</span><br><span class="line">class IntermediateFileRegion &#123;</span><br><span class="line">    &#x2F;&#x2F; 中间结果文件</span><br><span class="line">    IntermediateFile[] intermediateFiles;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Map 节点</span><br><span class="line">class MapWorker : Worker &#123;</span><br><span class="line">    &#x2F;&#x2F; 中间结果文件集，一共有 R 个</span><br><span class="line">    IntermediateFileRegion[] intermediateFileRegions;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Reduce 节点</span><br><span class="line">class ReduceWorker : Worker &#123;</span><br><span class="line">    &#x2F;&#x2F; 中间结果文件，master 节点会不断发送中间结果文件给 reduce 节点，当所有中间结果文件都收到后，reduce 节点开始工作</span><br><span class="line">    IntermediateFile[] intermediateFiles;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 主节点</span><br><span class="line">class Master &#123;</span><br><span class="line">    &#x2F;&#x2F; Map 任务，一共有 M 个</span><br><span class="line">    Task[] mapTasks;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; Reduce 任务，一共有 R 个</span><br><span class="line">    Task[] reduceTasks;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 工作节点，最多有 M + R 个，一个工作节点并不是只负责 map 或者 reduce 任务，master 节点会选择空闲节点分派 map 或者 reduce 任务</span><br><span class="line">    Worker[] workers;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; 中间结果文件集，一共有 R 个，由 map 节点下的中间结果文件集聚合而来，某个 map 节点执行成功后会将生成的 R 个中间结果文件地址发送给 master 节点，由 master 节点将某个区下的中间结果文件地址转发给对应 reduce 节点</span><br><span class="line">    IntermediateFileRegion[] intermediateFileRegions;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="容错"><a href="#容错" class="headerlink" title="容错"></a>容错</h3><p>因为 <code>MapReduce</code> 框架借助几百或几千台机器来处理海量数据，所以必须优雅的应对机器异常。</p>
<h4 id="工作节点异常"><a href="#工作节点异常" class="headerlink" title="工作节点异常"></a>工作节点异常</h4><p><code>master</code> 节点会周期性的对工作节点进行探活。如果某个工作节点在一段时间内无响应，则 <code>master</code> 节点会将该工作节点标记为异常。该工作节点完成的所有 <code>map</code> 任务的状态都会被重置为空闲，可重新被 <code>master</code> 节点调度到其他工作节点上执行。类似的，该工作节点所有进行中的 <code>map</code> 或 <code>reduce</code> 任务也都会被重置为空闲，并重新接受调度。</p>
<p>之所以这里已完成的 <code>map</code> 任务也需要重新执行是因为所产生的中间结果文件是保存在 <code>map</code> 节点的本地磁盘上，当该节点无响应时便认为无法与之连通从而认为无法通过 <code>RPC</code> 请求获取这些数据。而如果 <code>reduce</code> 节点异常，它所完成的 <code>reduce</code> 任务不需要重新执行是因为 <code>reduce</code> 节点执行成功后产生的输出文件是保存在全局的文件系统上。</p>
<p>如果某个 <code>map</code> 任务一开始由工作节点 <code>A</code> 执行，之后由工作节点 <code>B</code> 执行（因为节点 <code>A</code> 发生了异常），则所有执行 <code>reduce</code> 任务的节点都会被通知，其中所有要从节点 <code>A</code> 读取数据但还未读取的 <code>reduce</code> 节点会转而从节点 <code>B</code> 读取数据。</p>
<p><code>MapReduce</code> 框架能从容应对大量的节点异常。例如，在某次 <code>MapReduce</code> 任务中，由于对运行中的集群进行网络维护一次性造成了80台机器在几分钟内无法连通。<code>MapReduce</code> 框架可直接重新分发和执行这些不连通的节点正在处理的任务，然后继续后续流程，并最终完成当次任务。</p>
<h4 id="主节点异常"><a href="#主节点异常" class="headerlink" title="主节点异常"></a>主节点异常</h4><p>类似于游戏的自动存档，我们可以定期为主节点内部的数据结构保存检查点。如果主节点发生异常，则可以重新启动一个主节点程序并加载最新的检查点数据。然而对于单个主节点来说，主节点异常发生的概率较小，所以在 <code>Google</code> 的实现中，如果主节点发生异常，则会直接中断当次 <code>MapReduce</code> 任务。客户端可捕获到这种情况，并根据自身需要决定是否进行重试。</p>
<h4 id="执行语义"><a href="#执行语义" class="headerlink" title="执行语义"></a>执行语义</h4><p>如果用户编写的 <code>map</code> 和 <code>reduce</code> 函数是确定性的函数（即对于相同的输入始终返回相同的输出），则对于同一份输入，分布式的 <code>MapReduce</code> 框架的执行结果和一个串行执行且没有任何异常的 <code>MapReduce</code> 框架的执行结果相同。</p>
<p>不论是 <code>map</code> 还是 <code>task</code> 任务，都需要将执行结果写入到文件系统上，通过原子性的写入提交，可实现上述的语义保证。每个进行中的任务会先将输出结果写入到私有临时文件中，对 <code>reduce</code> 任务来说，最终只产生一个文件，而对于 <code>map</code> 任务则会产生 <code>R</code> 个文件（每个文件对应一个 <code>reduce</code> 任务）。当一个 <code>map</code> 任务执行完成时，<code>map</code> 节点会发送一条消息给 <code>master</code> 节点，这条消息中包含了 <code>map</code> 任务所生成的 <code>R</code> 个临时文件的名字。如果 <code>master</code> 节点收到了一条已经完成的 <code>map</code> 任务的消息，则会忽略该消息，否则将 <code>R</code> 个临时文件的名字保存在内部的数据结构中。</p>
<p>当 <code>reduce</code> 任务执行完成时，<code>reduce</code> 节点能原子性的将其生成的临时文件重命名为最终的输出文件。如果同一个 <code>reduce</code> 任务有多个工作节点执行（因为网络连通问题导致 <code>master</code> 重新分发 <code>reduce</code> 任务），则对同一个最终输出文件会有多个文件重命名的请求。通过底层文件系统的原子性重命名保证，最终的输出文件只会对应一个 <code>reduce</code> 任务的结果。</p>
<p>在 <code>Google</code> 内部大部分的 <code>map</code> 和 <code>reduce</code> 函数都是确定性的，在这种情况下分布式程序执行的结果和串行程序执行的结果相同的语义性保证使得开发人员能很容易的审视所编写的程序的行为（即如果程序的执行结果不符合预期，那么可以基本肯定的是开发人员编写的 <code>map</code> 或者 <code>reduce</code> 函数存在问题，而不是 <code>MapReduce</code> 框架存在问题）。当 <code>map</code> 或者 <code>reduce</code> 函数不具有确定性时，框架能提供稍弱一级但仍是合理的语义性保证。在非确定性的函数下，某个 <code>reduce</code> 任务 <code>R1</code> 由分布式执行的结果等价于一个串行执行的程序 <code>A</code> 执行 <code>R1</code> 后的结果。但是，另一个 <code>reduce</code> 任务 <code>R2</code> 的执行结果也可能等同于由另一个不同的串行执行的程序 <code>B</code> 执行后的结果。</p>
<p>假设有一个 <code>map</code> 任务 <code>M</code>，以及总共有两个 <code>reduce</code> 任务 <code>R1</code> 和 <code>R2</code>，记 <code>e(Ri)</code> 表示 <code>Ri</code> 执行并提交成功的结果。以前面的单词统计为例，假设发送给 <code>map</code> 任务的只有两个文档：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1.txt:</span><br><span class="line">It was the best of times</span><br><span class="line"></span><br><span class="line">2.txt:</span><br><span class="line">it was the worst of times</span><br></pre></td></tr></table></figure>

<p>在 <code>map</code> 函数是非确定性的情况下，不妨这样实现 <code>map</code> 函数：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">map(String key, String value):</span><br><span class="line">    &#x2F;&#x2F; key: document name</span><br><span class="line">    &#x2F;&#x2F; value: document contents</span><br><span class="line">    for each word w in value:</span><br><span class="line">        r &#x3D; Random(0, 1)</span><br><span class="line"></span><br><span class="line">        if r &gt; 0.5:</span><br><span class="line">            EmitIntermediate(w, &quot;1&quot;);</span><br><span class="line">        else:</span><br><span class="line">            EmitIntermediate(w, &quot;0&quot;);</span><br></pre></td></tr></table></figure>

<p>即对于某个单词，<code>map</code> 函数有一半的概率计数为1，一半的概率计数为0。</p>
<p>类似的，以同样的手段来实现 <code>reduce</code> 函数，对于某个单词的所有出现次数，<code>reduce</code> 函数有一半的概率会计数，一半的概率会忽略：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reduce(String key, Iterator values):</span><br><span class="line">    &#x2F;&#x2F; key: a word</span><br><span class="line">    &#x2F;&#x2F; values: a list of counts</span><br><span class="line">    int result &#x3D; 0;</span><br><span class="line">    for each v in values:</span><br><span class="line">        r &#x3D; Random(0, 1)</span><br><span class="line"></span><br><span class="line">        if r &gt; 0.5:</span><br><span class="line">            result +&#x3D; ParseInt(v);</span><br><span class="line">        else:</span><br><span class="line">            result +&#x3D; 0;</span><br><span class="line">    Emit(AsString(result));</span><br></pre></td></tr></table></figure>

<p>令 <code>R1</code> 为统计单词 <code>it</code> 的个数，经过 <code>map</code> 任务后，生成的中间结果键值对可能为以下四种情况：</p>
<ol>
<li>[0, 1]</li>
<li>[1, 0]</li>
<li>[1, 1]</li>
<li>[0, 0]</li>
</ol>
<p>最后由 <code>reduce</code> 任务执行后的结果可能为0、1、2三种情况，而相同的输入由一个串行执行的程序来执行也是同样的结果，即不管是分布式的程序还是串行的程序最终结果都是相同的集合，所以认为两者是等价的，也是合理的。</p>
<p>在确定性的函数下，相同的输入必然返回相同的输出，而在不确定性的函数下，不同的输入可能返回相同的输出或者相同的输入可能返回不同的输出。这就类似于知道 <code>x</code> 的定义域是 <code>&#123;1, 2, 3&#125;</code>，<code>y</code> 值域是 <code>&#123;4, 5, 6&#125;</code>，求 <code>f(x)</code>，显然 <code>f(x)</code> 存在不止唯一的解。</p>
<p>记上述的 <code>map</code> 和 <code>reduce</code> 函数组成的串行程序为 <code>A</code>，假设有另一个串行程序 <code>B</code>，其中 <code>map</code> 函数不变，<code>reduce</code> 函数变为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">reduce(String key, Iterator values):</span><br><span class="line">    &#x2F;&#x2F; key: a word</span><br><span class="line">    &#x2F;&#x2F; values: a list of counts</span><br><span class="line">    int result &#x3D; 0;</span><br><span class="line">    for each v in values:</span><br><span class="line">        r &#x3D; Random(0, 1)</span><br><span class="line"></span><br><span class="line">        if r &gt; 0.5:</span><br><span class="line">            result +&#x3D; 0;</span><br><span class="line">        else:</span><br><span class="line">            result +&#x3D; ParseInt(v);</span><br><span class="line">    Emit(AsString(result));</span><br></pre></td></tr></table></figure>

<p>令 <code>R2</code> 为统计单词 <code>was</code> 的个数，由 <code>A</code> 或 <code>B</code> 执行的最终结果都等于集合 <code>&#123;0, 1, 2&#125;</code>，相比于确定性的函数，开发人员因此无法有效的审视所编写函数的行为。</p>
<h3 id="局部性"><a href="#局部性" class="headerlink" title="局部性"></a>局部性</h3><p>在 <code>Google</code> 内部的运行环境中网络带宽属于稀缺资源，不管是 <code>map</code> 还是 <code>reduce</code> 任务都依托于文件的读取，不可避免的会产生大量网络 <code>IO</code>。而在前面提到，<code>Google</code> 内部实现了一套分布式文件存储系统（<code>GFS</code>）来管理存储在集群内机器本地磁盘上的文件，对于每一个文件 <code>GFS</code> 会将其切分为若干个 <code>64MB</code> 的数据块，每个数据块存有多份冗余（一般是3份）保存在不同的机器上。对于 <code>MapReduce</code> 框架来说，原始的数据输入是保存在本地磁盘上的，依据这个特性，框架在分发 <code>map</code> 任务时，根据输入数据在 <code>GFS</code> 内的位置会优先选择本地磁盘上存有对应输入数据的工作节点。如果找不到这样的工作节点，则会选择一个距离输入数据最近的工作节点（例如工作节点和存有输入数据的节点由同一个交换机相连）。当运行大量的 <code>MapReduce</code> 任务时，大部分的输入数据都是从本地读取从而不消耗任何网络带宽。</p>
<h3 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h3><p>如前文所述 <code>MapReduce</code> 框架会根据输入数据拆分为 <code>M</code> 个 <code>map</code> 任务和 <code>R</code> 个 <code>reduce</code> 任务。理想情况下，<code>M</code> 和 <code>R</code> 的值应该远大于工作节点的数量。为什么需要远大于？首先，<code>M</code> 和 <code>R</code> 的数量比工作节点的数量少是不适合的，会造成资源空闲；其次，如果 <code>M</code> 和 <code>R</code> 的数量和工作节点相等，由于每台机器的处理能力有差异或者输入数据不同，每个工作节点完成某个任务需要的时间也不同，会存在部分机器先完成任务的情况，同样会造成资源空闲，另一方面 <code>MapReduce</code> 面向的是大数据处理，输入数据的数据量远大于工作节点的数量，<code>M</code> 和 <code>R</code> 数量较少的情况下单个工作节点需要处理的数据量则较大，单次处理时间可能较慢，而如果发生了异常，重新执行的成本也较高。所以 <code>M</code> 和 <code>R</code> 的数量设置较大能更好的应对负载均衡，性能好的机器在完成任务后可以继续处理其他任务，同时当某个任务执行异常时也能更快的恢复：该异常的工作节点已完成的 <code>map</code> 任务可分发给余下的工作节点执行。</p>
<p>当然 <code>M</code> 和 <code>R</code> 的数量也是存在上限的，对于 <code>master</code> 节点来说，它需要维护 <code>M</code> 个 <code>map</code> 任务和 <code>R</code> 个 <code>reduce</code> 任务，时间复杂度是 <code>O(M + R)</code>，另一方面每个 <code>map</code> 任务会产出 <code>R</code> 份中间结果数据，对应 <code>R</code> 个 <code>reduce</code> 任务，所以 <code>master</code> 节点也需要 <code>O(M * R)</code> 的空间复杂度来维护这样的对应关系（<code>Google</code> 实际实现时，每个 <code>map/reduce</code> 关系对约占据 <code>1 byte</code> 内存）。</p>
<p>另外，由于每个 <code>reduce</code> 任务的最终产出结果是一个单独的文件所以 <code>R</code> 的数量受用户设置限制。在实践中，会趋向于让每个 <code>map</code> 任务处理 <code>16 MB</code> 到 <code>64 MB</code> 的输入数据来确定 <code>M</code> 的大小，因为 <code>64 MB</code> 正好是 <code>GFS</code> 单个数据块的大小，这样每个 <code>map</code> 任务必然能从本地磁盘读取输入数据而不会涉及网络 <code>IO</code>（如果能将任务分发给存有对应输入数据的节点的话），而 <code>R</code> 的数量会在工作节点的数量上乘上一个较小的常数得到。<code>Google</code> 内部运行 <code>MapReduce</code> 任务时通常设置 <code>M</code> 为200000，使用2000台机器的情况下设置 <code>R</code> 为5000。</p>
<h3 id="后备任务"><a href="#后备任务" class="headerlink" title="后备任务"></a>后备任务</h3><p>类似于木桶原理，一次 <code>MapReduce</code> 任务完成的时间取决于最慢的机器完成 <code>map</code> 或 <code>reduce</code> 任务的时间，这也是造成 <code>MapReduce</code> 任务耗时长的常见原因之一。某台机器执行慢可能有好几个原因造成，例如某台机器的磁盘存在异常，可能频繁遭遇可校正的异常，从而使得磁盘的读速度从 <code>30 MB/s</code> 降低到 <code>1 MB/s</code>。而调度系统同时有可能分配了其他的任务给这台机器，会进一步引发 <code>CPU</code>、内存、本地磁盘、网络带宽的竞争，从而造成执行 <code>MapReduce</code> 任务的耗时更长。<code>Google</code> 内部曾经遇到一个问题，由于机器初始化代码中的一个 <code>bug</code> 造成处理器的缓存被禁用，在这些受影响的机器上运行的任务耗时增长了超过100倍。</p>
<p>针对这个问题，<code>Google</code> 提出了一个通用的缓解机制。当一次 <code>MapReduce</code> 任务快执行结束时，框架会将剩余还在进行中的任务分配给其他机器执行。不管是原先分配的机器执行完成，还是新分配的机器执行完成，对应的任务都将标记为完成。让一个任务由两台机器同时执行势必存在资源浪费，<code>Google</code> 通过调优使得耗费的计算资源控制在了增加几个百分比以内。这个机制在处理一个数据量巨大的 <code>MapReduce</code> 任务时能大幅降低整体耗时。在某个约需处理 <code>1T</code> 数据的排序任务中，不启用这个机制的情况下整体耗时会增加44%。</p>
<h2 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h2><p>大多数情况下用户仅需编写 <code>map</code> 和 <code>reduce</code> 函数就能满足需求，本节主要描述一些 <code>MapReduce</code> 的扩展，可能在某些场合下会比较有用。</p>
<h3 id="分片函数"><a href="#分片函数" class="headerlink" title="分片函数"></a>分片函数</h3><p>用户可指定 <code>MapReduce</code> 任务最终输出文件的数量 <code>R</code>，也即 <code>reduce</code> 任务的数量。那么由 <code>map</code> 任务产生的中间结果数据应该发给哪个 <code>reduce</code> 节点执行呢？这个就交由分片函数决定，默认的分片函数是哈希函数（例如 <code>hash(key) mod R</code>），这种分片结果一般比较均匀。不过，有时候自定义分片函数会更有用，例如，当最终结果文件的键是 <code>URL</code> 时，我们希望同属于一个 <code>host</code> 下的 <code>URL</code> 对应的数据最终都在同一个文件里，用户可自定义分片函数来实现，例如 <code>hash(Hostname(urlkey)) mod R</code>，即先通过 <code>urlkey</code> 提取 <code>host</code>，然后对 <code>host</code> 计算哈希最后取模 <code>R</code>。</p>
<h3 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a>顺序保证</h3><p><code>MapReduce</code> 框架保证在同一个中间结果分区内，即同一个 <code>reduce</code> 任务内，中间结果数据是按照键的升序处理的，因为 <code>reduce</code> 任务处理前会先将中间结果数据按照键进行排序。这样在 <code>reduce</code> 任务处理完成后，最终结果文件内的数据也是按照键的顺序排序的，这就有利于对最终结果文件按键进行高效的随机查找，或方便其他需要排好序的数据的场景。</p>
<h3 id="合并函数"><a href="#合并函数" class="headerlink" title="合并函数"></a>合并函数</h3><p>在某些场景下，<code>map</code> 任务产生的中间结果数据的键存在大量的重复，同时用户编写的 <code>reduce</code> 函数又符合交换律和结合律（即 <code>a + b = b + a</code>，<code>(a + b) + c = a + (b + c)</code>）。一个典型案例就是前文描述的单词计数程序，每个 <code>map</code> 任务都会产生成百上千的形如 <code>&lt;the, 1&gt;</code> 的中间结果数据，其中 <code>the</code> 指某个单词，1表示该单词出现的次数。这些同键的中间结果数据接着会经过网络传输发送给 <code>reduce</code> 任务，然后由 <code>reduce</code> 函数合并相加。为了减少这种雷同数据的网络传输，用户可编写自定义的合并函数，<code>map</code> 任务在生成中间结果数据前先进行同键的合并，从而将原来成百上千的同键网络传输降低为1次。</p>
<p>一般来说，合并函数和 <code>reduce</code> 函数的用户代码实现是相同的。不同在于 <code>MapReduce</code> 框架如何处理这两个函数产出的结果，<code>reduce</code> 函数的产出结果会写到最终的结果文件里，而合并函数的产出结果会写到中间结果文件里，然后发送给 <code>reduce</code> 任务。</p>
<p>在特定情况下，由于省去了大量的网络 <code>IO</code>，合并函数能显著的降低一次 <code>MapReduce</code> 任务执行的耗时。</p>
<h3 id="输入和输出类型"><a href="#输入和输出类型" class="headerlink" title="输入和输出类型"></a>输入和输出类型</h3><p><code>MapReduce</code> 框架支持从多个数据格式读取输入数据。例如，<code>text</code> 模式下将输入数据的每一行作为键值对，其中键通过在文本中的偏移量来确定，而值就是当前行的内容。另一种通用支持的格式是本身保存了已排好序的键值对。不管是哪种输入格式，<code>MapReduce</code> 都能从原始输入中准确切分出键值对供 <code>map</code> 任务使用（例如 <code>text</code> 模式保证以每一行的结束进行切分）。用户也可实现自定义的 <code>reader</code> 接口来支持读取新的输入格式，不过大部分情况下内置的输入格式已经能满足需求。</p>
<p>虽然前文描述过 <code>MapReduce</code> 的原始输入数据来源于文本文件，不过用户自定义的 <code>reader</code> 接口并不一定要从文本文件读取，例如还可以从数据库或内存中读取。</p>
<p>类似的，<code>MapReduce</code> 框架也支持不同的最终输出数据的格式，用户也同样可实现支持自定义的输出格式。</p>
<h3 id="副作用"><a href="#副作用" class="headerlink" title="副作用"></a>副作用</h3><p>在某些情况下，用户可能希望在 <code>map</code> 或 <code>reduce</code> 阶段生成额外的辅助文件，这就要求开发人员自己保证输出文件的原子性和幂等性，特别是用户程序先将数据写入到临时文件内，最后在所有数据写入完成后能原子性的将临时文件重命名。</p>
<p>不过，<code>MapReduce</code> 框架本身并不支持两阶段协议来保证 <code>map</code> 或 <code>reduce</code> 任务输出多个文件时的一致性，同样的，这也需要开发人员自己来保证。因此多文件一致性对应的任务应当是确定性的，否则如何确定产出的文件是符合一致性的？而在实践中要求任务是确定性的并不是个问题。</p>
<h3 id="忽略异常数据"><a href="#忽略异常数据" class="headerlink" title="忽略异常数据"></a>忽略异常数据</h3><p>有时候由于用户编写的 <code>map</code> 或 <code>reduce</code> 函数存在 <code>bug</code>，导致处理某些数据时 <code>map</code> 或 <code>reduce</code> 函数必然发生异常，这就造成 <code>MapReduce</code> 任务无法正常完成。正常来说应当修复 <code>bug</code>，但有时候不可行，例如造成 <code>bug</code> 的代码可能是第三方库引入的。另一方面，有时候忽略这些造成异常的数据也是可以接受的，例如在对一个数据量非常庞大的数据集做统计分析时。因此，<code>MapReduce</code> 框架提供了一种可选的执行模式，当其检测到某些输入数据必然造成异常时，则会跳过这些数据从而使得执行流程能继续走下去。</p>
<p>为了实现这个功能，首先每个工作节点上都安装了一个 <code>signal handler</code> 程序用于捕获段异常和总线异常。在执行 <code>map</code> 或 <code>reduce</code> 任务之前，<code>MapReduce</code> 框架首先将当前任务需要的输入数据所对应的序号保存在工作节点内的一个全局变量中，在执行 <code>map</code> 或 <code>reduce</code> 任务时，如果用户代码发生异常，此时 <code>signal handler</code> 能捕获到相应的异常信号，然后 <code>signal handler</code> 会发送一个 <code>UDP</code> 数据包给主节点，该数据包中包含了执行当次任务的输入数据序号。如果主节点发现某个数据对应的任务执行失败了多次，则会忽略该数据而不是重新执行 <code>map</code> 或 <code>reduce</code> 任务。按照这样的描述，被忽略的数据是数据片维度，而不是键值对维度，因为每片的数据块大小相比于总数据量的大小来说微乎其微，所以整体影响不大。</p>
<h3 id="本地执行"><a href="#本地执行" class="headerlink" title="本地执行"></a>本地执行</h3><p>调试分布式程序并不是件简单的事，对于 <code>MapReduce</code> 任务来说，一次任务会被分发到几千台机器上执行，每台机器实际执行的任务也无法预测。为了方便调试、性能分析和小规模测试，<code>Google</code> 实现的 <code>MapReduce</code> 框架也提供了一个串行执行的版本，能在单台机器上串行执行所有任务。同时，用户也可通过参数控制一次 <code>MapReduce</code> 任务只执行些特定的 <code>map</code> 任务。通过在启动程序时指定调试参数，用户就可轻松的使用调试或测试工具（如 <code>gdb</code>）对编写的程序进行调试和测试。</p>
<h3 id="状态信息"><a href="#状态信息" class="headerlink" title="状态信息"></a>状态信息</h3><p>主节点内部同时运行了一个 <code>HTTP</code> 服务，用于提供给用户查看一系列状态信息。状态信息页面展示了当前任务的进度，例如有多少个任务已经完成，有多少个任务正在进行中，输入数据的大小，中间结果数据的大小，最终结果数据的大小，任务处理百分比等。同时，状态页面也提供了每个任务执行产生的标准错误输出和标准输出文件。用户可根据这些信息来预测任务需要多久才能完成，以及是否需要添加更多的计算资源。状态页面也可用于判断当前任务执行耗时是否比预期的长。</p>
<p>此外，状态页面也显示了失败的工作节点，以及这些失败的工作节点对应的 <code>map</code> 或 <code>reduce</code> 任务。这有助于用户排查编写的代码中是否有 <code>bug</code>。</p>
<h3 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h3><p><code>MapReduce</code> 框架内部提供了一个计数器用于统计各个事件发生的次数。例如，用户可能希望统计一次任务中一共处理了多少个单词，或者有多少个德语文档建立了索引。</p>
<p>如果要开启这个功能，用户需要编写一个命名计数器，然后在 <code>map</code> 或 <code>reduce</code> 函数中在需要的时候对计数器自增，例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Counter* uppercase;</span><br><span class="line">uppercase &#x3D; GetCounter(&quot;uppercase);</span><br><span class="line"></span><br><span class="line">map(String name, String contents):</span><br><span class="line">    for each word w in contents:</span><br><span class="line">        if (IsCapitalized(w)):</span><br><span class="line">            uppsercase-&gt;Increment();</span><br><span class="line">        EmitIntermediate(w, &quot;1&quot;);</span><br></pre></td></tr></table></figure>

<p>每个工作节点上的计数器的值会周期性的发送给主节点（如前文所述，主节点会周期性的对工作节点进行心跳探测，工作节点会在响应结果中带上计数器的值）。主节点会对执行成功的 <code>map</code> 和 <code>reduce</code> 任务返回的计数器聚合，当整个 <code>MapReduce</code> 任务完成将控制权交还给用户代码时，用户代码可获取到创建的计数器的值。当前的计数器的值也同样会展示在状态页面，用户也可根据此信息来观测整个任务的进展。在对计数器聚合时，和主节点会忽略已完成的某个任务的重复通知一样，主节点同样会忽略某个来自已完成任务的计数器更新，从而避免重复计数（任务的重复执行主要有两种情况，一种是由于网络不连通，导致主节点重新分配某个 <code>map</code> 或 <code>reduce</code> 任务到新的工作节点上；另一种是触发了后备任务，主节点主动分发同一个 <code>map</code> 或 <code>reduce</code> 任务给多个工作节点执行）。</p>
<p><code>MapRecue</code> 框架本身也维护了一些计数器，例如已处理的输入数据键值对的数量，以及已生成的最终数据键值对的数量。</p>
<p>用户能很方便的通过计数器来检查 <code>MapReduce</code> 任务的行为。例如，在任务执行时用户可通过计数器来确保输出的键值对数量是否等于输入的键值对数量，或者已处理的德语文档的数量在全部已处理的文档数量中的占比是否符合预期。</p>
<h2 id="性能"><a href="#性能" class="headerlink" title="性能"></a>性能</h2><p>这一节主要描述 <code>MapReduce</code> 在 <code>Google</code> 内部环境下运行的性能情况，这里不再赘述。简单举例来说，在1800台机器上执行一个 <code>10T</code> 数据量的分布式 <code>grep</code> 搜索耗时约150秒。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>最后，来自 <code>Google</code> 的总结：</p>
<ol>
<li>限制性的编程模型使得计算并行化变得容易，以及有着较好的容错性，这也体现了计算机领域的一个重要思想：抽象</li>
<li>对于大型系统来说，网络 <code>IO</code> 容易成为瓶颈</li>
<li>冗余执行可以作为有效降低成为性能短板的机器带来的影响的手段，另外冗余也是应对机器异常、数据丢失的方式</li>
</ol>
<p>参考：</p>
<ul>
<li><a href="https://research.google/pubs/pub62/">MapReduce: Simplified Data Processing on Large Clusters</a></li>
<li><a href="https://en.wikipedia.org/wiki/Bisection_bandwidth">Bisection bandwidth</a></li>
<li><a href="https://networkengineering.stackexchange.com/questions/28894/understanding-bisection-bandwidth">Understanding bisection bandwidth</a></li>
</ul>
]]></content>
      <tags>
        <tag>MIT 6.824</tag>
        <tag>MapReduce</tag>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 - The Design of a Practical System for Fault-Tolerant Virtual Machines</title>
    <url>/2022/04/24/mit-6.824-vm-ft/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>和一般描述的应用级别的主从备份不同，本文描述的是虚拟机的主从备份。主从备份作为一种常见的容错实现手段，当主节点异常时，从节点能取代主节点从而保证系统依然可用。作为从节点，它的状态必须尽可能的与主节点随时保持一致，这样当主节点异常时从节点能马上取代主节点，而客户端也不会感知到异常，同时也没有数据丢失。其中一种同步主从节点状态的方式是持续将主节点的所有修改发送给从节点，这里的修改包括 <code>CPU</code>、内存以及 <code>IO</code> 设备。然而，采用这种同步方式需要大量的网络带宽，尤其是发送内存的修改。</p>
<p>另一种只需要耗费少量带宽的方式是状态机（<code>state machine</code>）同步。该方法将主从同步抽象为确定性状态机（<code>deterministic state machine</code>）同步问题，在确定性状态机模型下，对于两个初始状态一样的状态机来说，按照相同的顺序执行相同的一系列输入指令后，最后的状态也一定是相同的。然而，对于大部分的服务来说，存在某些非确定性的操作，例如生成一个随机数，这时候就需要额外的协调使得主从间依然是同步的，即从节点也要生成一模一样的随机数。不过，处理这种情况所需要维护的额外信息相比于主节点状态的修改（主要是内存的修改）来说不值一提。</p>
<p>对于物理机来说，随着主频的增加，同步主从间的确定性操作也愈发困难。然而对于运行在 <code>hypervisor</code> 上的虚拟机来说却非常适合实现状态机同步。一个虚拟机本身就可以看做一个明确的状态机，它的所有操作就是被虚拟化的机器的操作（包括所有的设备）。和物理机一样，虚拟机也存在一些非确定性的操作（例如读取当前时间或者发送一个中断），所以也需要发送额外的信息给从节点来保证主从同步。因为 <code>hypervisor</code> 掌管着虚拟机的执行，包括发送所有的输入给被虚拟化的机器，所以它能捕获到执行非确定性操作的所有需要的信息，从而能正确的在从节点上执行重放操作。</p>
<p>因此，基于状态机同步的主从同步方式可以在不需要修改硬件的情况下在廉价的硬件上实现，使得容错技术适用于最新的微处理器。另外，对带宽较低的要求使得长距离的虚拟机主从同步成为了可能。例如，可以在跨校园间不同的物理机上做主从同步，相比于同大厦内的主从同步更为可靠。</p>
<p>目前在 <code>VMware vSphere 4.0</code> 平台上已经实现了这种容错技术，该平台能高效完整的虚拟化 <code>x86</code> 架构的机器。因为 <code>VMware vSphere</code> 实现了一个完全的 <code>x86</code> 虚拟机，所以可以自动的对任何 <code>x86</code> 的操作系统和应用提供容错支持。通过确定性重放（<code>deterministic replay</code>），系统可以记录下主节点的执行并且确保能在从节点执行相同的操作。<code>VMware vSphere Fault Tolerance (FT)</code> 在此基础之上增加了额外的功能和协议来支持构建一个可完全容错的系统。除了对硬件的容错外，当主节点异常时，系统能自动的在本地集群中启动一台可用的从节点来接管主节点。在该篇论文发表的时候，确定性重放技术和 <code>VMware FT</code> 仅支持单核的虚拟机。受限于严重的性能问题，多核虚拟机的重放支持仍在进行中，因为在多核场景下，几乎每一个对共享内存的访问都是一个非确定性的操作。</p>
<p><code>Bressoud</code> 和 <code>Schneider</code> 针对惠普的 <code>PA-RISC</code> 平台的虚拟机容错做了个原型实现。<code>VMware</code> 的实现与其类似，不过出于性能的考虑做了些根本的修改以及调研了一些其他实现方案。另外，为了能构建一个高效、可用的容错系统来支持用户的企业级应用，<code>VMware</code> 还设计和实现了许多其他组件以及解决一些实际的问题。和大多数实际的系统要解决的问题一样，这里的容错针对的是 <code>fail-stop</code> 的异常，即在造成外部可见的不正确的行为前可被监测到的异常，例如磁盘空间不足、网络无法连通等等，而诸如应用程序的 <code>bug</code> 或者人为失误等则不属于 <code>fail-stop</code> 异常，系统也无法进行容错。</p>
<h2 id="基础设计"><a href="#基础设计" class="headerlink" title="基础设计"></a>基础设计</h2><p><img src="/images/vm-ft-1.png" alt="alt"></p>
<p>上图展示了支持容错的虚拟机的基本配置。对于每一台需要支持容错的虚拟机（<code>primary VM</code>），系统会在其他物理机上同时运行一台备份虚拟机（<code>backup VM</code>），备份虚拟机和主虚拟机会保持同步，并执行和主虚拟机相同的指令，不过会存在一定的延迟。这两台虚拟机被称为处于 <code>virtual lockstep</code> 状态。同时，虚拟机连接着相同的共享存储，输入和输出都可以被主从虚拟机访问。不过，只有主虚拟机才会暴露在网络中，所以所有的网络输入都会只发送给主虚拟机。同样的，其他所有的输入（例如键盘和鼠标输入）也都只会发送给主虚拟机。</p>
<p>主虚拟机收到的所有输入都会通过 <code>logging channel</code> 发送给从虚拟机。对系统来说，主要的输入负载就是网络和磁盘。为了保证从虚拟机能和主虚拟机执行相同的非确定性操作，还需要发送一些额外的信息给从虚拟机。从结果上来说，从虚拟机会始终执行和主虚拟机相同的操作。不过，所有从虚拟机的输出都会被 <code>hypervisor</code> 丢弃，只有主虚拟机的输出才会返回给客户端。后面会提到，主从虚拟机间的通信会遵循一个特定的协议，包括从虚拟机对消息的确认，来保证当主虚拟机异常时不会发生数据丢失。</p>
<p>为了监测主虚拟机或者从虚拟机是否发生异常，系统会通过和主从虚拟机间的心跳以及 <code>logging channel</code> 的流量来判断。另外，系统必须保证在任一时间只有一台主虚拟机或者从虚拟机作为对外执行的入口，即使主虚拟机和从虚拟机间失联发生脑裂的场景。</p>
<h3 id="确定性重放的实现"><a href="#确定性重放的实现" class="headerlink" title="确定性重放的实现"></a>确定性重放的实现</h3><p>在前面提到过，主从虚拟机的同步可以抽象为确定性状态机同步问题。如果两个确定性状态机以相同的初始状态启动，并且按照相同的顺序执行相同的输入，那么这两个状态机会经历相同的状态流转并输出相同的结果。一台虚拟机会有一系列的输入，包括网络包，磁盘读取，以及键盘和鼠标输入。而非确定性的事件（例如虚拟中断（<code>virtual interrupts</code>））和非确定性的操作（例如读取当前处理器的时钟周期数）也会影响虚拟机的内部状态。这就给重放执行一台运行着任意操作系统和任意服务的虚拟机带来了3个挑战：</p>
<ol>
<li>需要正确的捕捉到主虚拟机的所有输入和非确定性的操作</li>
<li>需要正确的将输入和非确定性操作在从虚拟机上重放</li>
<li>不能影响系统性能</li>
</ol>
<p>另外，<code>x86</code> 处理器中很多复杂的操作往往伴有副作用，因此也是非确定性的操作，如何捕捉到这些非确定性的操作并正确的在从虚拟机上重放也是一个挑战。</p>
<p><code>VMware vSphere</code> 平台为 <code>x86</code> 虚拟机提供了上述的重放功能。确定性重放技术会将主虚拟机的所有输入和所有可能的非确定性操作写入到日志文件中。从虚拟机就可以读取日志文件并执行和主虚拟机一样的操作。对于非确定性的操作来说，系统会写入一些额外的信息来保证重放时生成相同的虚拟机状态和输出。对于非确定性的事件例如计时器或者 <code>IO</code> 完成中断，在事件发生时所执行的指令也会记录在日志中。在重放时，事件会和指令一同出现在指令流中。借助联合 <code>AMD</code> 和 <code>Intel</code> 开发的 <code>hardware performance counter</code>（一组特殊寄存器用来记录硬件相关事件发生的次数）和其他技术，<code>VMware</code> 确定性重放技术能高效的记录和重放非确定性的事件。</p>
<p><code>Bressound</code> 和 <code>Schneider</code> 在其实现中提到将虚拟机的执行以 <code>epoch</code> 为单位进行切分，其中所有的非确定性操作例如中断都放在 <code>epoch</code> 的最后。这个想法是出于批量处理的考虑，因为单独将每一个中断和中断发生时对应的指令重放执行代价较大。不过 <code>VMware</code> 的实现足够高效使得不需要借助 <code>epoch</code> 来实现确定性重放，每一个中断都能被准确的记录并伴随着发生中断时的指令一起执行。</p>
<h3 id="FT-协议"><a href="#FT-协议" class="headerlink" title="FT 协议"></a><code>FT</code> 协议</h3><p><code>VMware FT</code> 使用确定性重放技术将主虚拟机的执行流记录到日志中，不过主虚拟机并不是将日志写入到磁盘上，而是通过 <code>logging channel</code> 将日志发送给从虚拟机。从虚拟机能实时的读取日志并将其重放，从而执行和主虚拟机一样的操作。然而，双方在 <code>logging channel</code> 的通信必须遵循 <code>FT</code> 协议来保证容错。其中一条基本的要求是：</p>
<blockquote>
<p><code>Output Requirement</code>：当主虚拟机异常，从虚拟机接管执行时，从虚拟机的输出必须和先前主虚拟机已经发送给客户端的输出一致。</p>
</blockquote>
<p>当异常发生时（主虚拟机异常，从虚拟机接管执行），从虚拟机的执行可能会和在没有异常发生时主虚拟机的执行不同，因为在执行时会有很多非确定性的操作。然而，只要从虚拟机的输出满足 <code>Output Requirement</code>，则在主从切换时就不会有外部可见的状态或者数据丢失，而客户端也不会感知到中断或者服务的不一致。</p>
<p>通过主虚拟机的延迟输出，保证从虚拟机确认收到了所有日志后，主虚拟机才将输出返回给客户端来实现 <code>Output Requirement</code>。一个先决的条件是主虚拟机在执行输出操作前，从虚拟机必须已经收到所有的日志。这些日志能保证从虚拟机执行到主虚拟机最新的执行点。然而，假设当主虚拟机刚开始执行输出操作时发生了异常，此时发生了主从切换，从虚拟机必须先将未处理完的日志进行重放，然后才能 <code>go live</code>（不再执行重放，接管成为主虚拟机）。如果在这之前从虚拟机 <code>go live</code>，可能会有一些非确定性的事件（例如计时器中断）在从虚拟机执行输出操作前改变了执行的路径。</p>
<p>针对上述的要求，最简单的实现 <code>Output Requirement</code> 的方式是为每一条输出操作创建一条特殊的日志，从而可以通过以下规则来保证 <code>Output Requirement</code>：</p>
<blockquote>
<p><code>Output Rule</code>：在从虚拟机确认收到输出操作对应的日志前，主虚拟机不能执行输出操作。</p>
</blockquote>
<p>如果从虚拟机收到了所有的日志，包括输出操作对应的日志，那么从虚拟机就能重放出和主虚拟机在执行输出操作时一模一样的状态，当主虚拟机异常时，从虚拟机就能恢复到主虚拟机执行输出操作前一致的状态。相反的，如果从虚拟机在没有收到日志前就接管了主虚拟机的操作，那么它的状态就和主虚拟机是不一致的，从而导致最终的输出也不一致。</p>
<p>注意 <code>Output Rule</code> 并没有要求在从虚拟机确认收到输出日志前停止主虚拟机的执行。这里只是延迟了主虚拟机的输出，它依然可以执行其他指令。因为操作系统以异步中断的方式来通知非阻塞网络和磁盘输出的完成，主虚拟机可以在这期间轻易的执行其他指令，而不用阻塞等待。相反的，在其他的一些实现中，在从虚拟机确认收到输出日志前，主虚拟机必须完全停止等待。</p>
<p><img src="/images/vm-ft-2.png" alt="alt"></p>
<p>上图展示了 <code>FT</code> 协议的要求。主虚拟机到从虚拟机的箭头表示日志的发送，从虚拟机到主虚拟机的箭头表示日志的确认。所有异步事件，输入和输出的操作都必须发送给从虚拟机并得到确认。只有当从虚拟机确认了某条输出操作的日志后，主虚拟机才能执行输出操作。所以只要遵循了 <code>Output Rule</code>，从虚拟机在接管执行时就能保持和主虚拟机一致的状态。</p>
<p>不过在异常发生时，<code>VMware FT</code> 并不能保证所有的输出只发送一次。在缺少两阶段提交的帮助下，从虚拟机不能知晓主虚拟机在发送某条输出之前还是之后发生了异常。不过，网络协议（包括常见的 <code>TCP</code> 协议）在设计时就已经考虑了包的丢失和重复包的情况，所以这里无需特殊处理。另外，在主虚拟机异常时发送给主虚拟机的输入也有可能丢失，因此从虚拟机也会丢失这部分的输入。不过，即使在主虚拟机没有异常的情况下，网络包本身就有可能丢失，所以这里同样也不需要特殊处理，不管是网络协议、操作系统还是应用程序，在设计和编写时本身已经考虑到了包丢失的情况。</p>
<h3 id="监测和响应异常"><a href="#监测和响应异常" class="headerlink" title="监测和响应异常"></a>监测和响应异常</h3><p>之前提到过，当主虚拟机或者从虚拟机发生异常时，双方都必须能快速响应。当从虚拟机异常时，主虚拟机会进入 <code>go live</code> 模式，即不再记录执行日志，以常规的方式执行。当主虚拟机异常时，从虚拟机也会进入 <code>go live</code> 模式，不过相比于主虚拟机略微复杂些。因为从虚拟机在执行上本身就落后于主虚拟机，在主虚拟机异常时，从虚拟机已经收到和确认了一部分执行日志，但是还没有执行重放，此时从虚拟机的状态和主虚拟机还是不一致的。所以，从虚拟机必须先将暂存的日志进行重放，当所有重放都执行完成后，从虚拟机就会进行 <code>go live</code> 模式，正式接管主虚拟机（此时缺少一个从虚拟机）。因为此时这台从虚拟机不再是从虚拟机，被虚拟化的操作系统所执行的输出操作都会发送给客户端。在这个转换期间，可能也需要某些设备执行一些特定的操作来保证后续输出的正确性。特别是对于网络输出来说，<code>VMware FT</code> 会自动的将新的主虚拟机的 <code>MAC</code> 地址在网络中广播，使得物理交换机知道最新的主虚拟机的地址。另外，后文会提到新的主虚拟机可能会重新发起一些磁盘 <code>IO</code> 操作。</p>
<p>有很多种方式来监测主虚拟机和从虚拟机的异常。<code>VMware FT</code> 通过 <code>UDP</code> 心跳来监测启用了容错的虚拟机是否发生了异常。另外，<code>VMware FT</code> 还会监控 <code>logging channel</code> 中的流量，包括主虚拟机发送给从虚拟机的日志，以及从虚拟机的确认回执。因为操作系统本身存在时钟中断，所以理论上来说 <code>logging channel</code> 中的流量应该是连续不断的。因此，如果监测到 <code>logging channel</code> 中没有流量了，那么就可以推断出某台虚拟机发生了异常。如果没有心跳或者 <code>logging channel</code> 中没有流量超过一段指定的时间（近似几秒钟），那么系统就会声明这台虚拟机发生了异常。</p>
<p>然而，这种异常监测机制可能会引发脑裂问题。如果从虚拟机不再接收到来自主虚拟机的心跳，那么有可能说明主虚拟机发生了异常，但也有可能只是双方间的网络断开。如果此时从虚拟机进入 <code>go live</code> 模式，由于此时主虚拟机依然存活，就有可能给客户端造成数据损坏或其他问题。因此，当监测到异常时必须保证只有一台主虚拟机或者从虚拟机进入 <code>go live</code> 模式。为了解决脑裂问题，<code>VMware FT</code> 借助了虚拟机所连接的共享存储。当主虚拟机或者从虚拟机希望进入 <code>go live</code> 模式时，它会向共享存储发起一个原子性的 <code>test-and-test</code> 操作。如果操作成功，那么当前虚拟机可以进入 <code>go live</code> 模式，如果操作失败，说明已经有其他虚拟机先进入了 <code>go live</code> 模式，所以当前虚拟机就将自己挂起。如果虚拟机访问共享存储失败，那么它会一直等待直到访问成功。如果共享存储由于网络问题造成无法访问，那么虚拟机本身也做不了什么因为它的虚拟磁盘就挂载在共享存储上。所以使用共享存储来解决脑裂问题不会带来其他可用性问题。</p>
<p>最后一个设计的点是如果虚拟机发生了异常，使得某台虚拟机进入了 <code>go live</code> 模式，那么 <code>VMware FT</code> 会自动在其他物理机上启动一台新的备份虚拟机。</p>
<h2 id="FT-的实际实现"><a href="#FT-的实际实现" class="headerlink" title="FT 的实际实现"></a><code>FT</code> 的实际实现</h2><p>上节主要描述了 <code>FT</code> 的基础设计和协议。然而，为了构建一个可用，健壮和自动化的系统，还需要设计和实现很多其他的组件。</p>
<h3 id="启动和重启-FT-虚拟机"><a href="#启动和重启-FT-虚拟机" class="headerlink" title="启动和重启 FT 虚拟机"></a>启动和重启 <code>FT</code> 虚拟机</h3><p>其中一个至关重要的组件是如何启动一台有着和主虚拟机一模一样状态的备份虚拟机。这个同时也会在当某台虚拟机异常需要重新启动一台备份虚拟机时用到。因此，这个组件必须能够在主虚拟机处于任意状态的时候复制一台一模一样的备份虚拟机（而不仅仅是初始状态）。另外，这个启动操作还不能影响到主虚拟机的执行，因为这有可能影响到当前所有连接着的客户端。</p>
<p>对于 <code>VMware FT</code> 来说，它借用了 <code>VMware vSphere</code> 平台已有的 <code>VMotion</code> 的功能。<code>VMware VMotion</code> 能以极小的代价将一台运行中的虚拟机迁移到另一台机器上——虚拟机的暂停时间一般在一秒内。<code>VMware FT</code> 对 <code>VMotion</code> 做了些改动使得在不销毁当前虚拟机的情况下，在远程服务器上复制一台和当前虚拟机一模一样的虚拟机。即修改版的 <code>FT VMotion</code> 做的是虚拟机的复制而不是迁移。<code>FT VMotion</code> 也会同时建立一条 <code>logging channel</code>，源虚拟机作为主虚拟机就会将执行日志写入到 <code>logging channel</code>，而复制后的虚拟机作为从虚拟机开始重放执行。和常规的 <code>VMotion</code> 一样，<code>FT VMotion</code> 也能将对主虚拟机的暂停控制在一秒以内。因此，对某台运行中的虚拟机开启 <code>FT</code> 功能非常简单，且没有破坏性。</p>
<p>另一个启动一台备份虚拟机要考虑的点是选择在哪台物理机上启动。支持容错的虚拟机运行在某个可访问共享存储的集群中，所以本质上虚拟机可以运行在任意一台机器上。这个灵活性使得 <code>VMware vSphere</code> 可以轻易的为一台或多台异常的虚拟机启动新的备份虚拟机。<code>VMware vSphere</code> 实现了一套集群服务来管理集群中的资源。当虚拟机发生异常主虚拟机需要一台新的虚拟机来维持容错时，主虚拟机会通知集群服务需要一台新的备份虚拟机。此时集群服务会根据资源利用率和其他条件来决定在哪台机器上重启新的备份虚拟机，然后会由 <code>FT VMotion</code> 创建一台新的备份虚拟机。一般来说，<code>VMware FT</code> 可以在发生异常时几分钟内恢复某台虚拟机的冗余功能，而不会造成任何中断。</p>
<h3 id="管理-Logging-Channel"><a href="#管理-Logging-Channel" class="headerlink" title="管理 Logging Channel"></a>管理 <code>Logging Channel</code></h3><p>在管理 <code>logging channel</code> 的流量上有很多有趣的实现细节。在 <code>VMware</code> 的实现里，<code>hypervisor</code> 为主虚拟机和从虚拟机维护了一大块日志缓冲区。在主虚拟机执行时，它将执行日志发送到日志缓冲区中，类似的，从虚拟机从日志缓冲区中消费日志。每当主虚拟机的日志缓冲区中有数据，系统就会将其发送到 <code>logging channel</code> 中，相应的在另一边则会将其放入到从虚拟机的日志缓冲区中。当从虚拟机从 <code>logging channel</code> 中读取到日志并将其放入日志缓冲区后，它就会向主虚拟机发送一个已读消息的回执。<code>VMare FT</code> 就可以根据这个已读回执决定哪些输出操作可以执行了。下图展示了这个过程：</p>
<p><img src="/images/vm-ft-3.png" alt="alt"></p>
<p>当从虚拟机从日志缓冲区读取不到任何日志时（日志缓冲区为空），它就会暂停执行直到下一条日志到达。因为从虚拟机不和外界交互，这个暂停对客户端没有任何影响。类似的，如果主虚拟机往日志缓冲区中写日志发现日志缓冲区满时，它必须停止执行直到日志缓冲区被消费。这个暂停保证了主虚拟机以一个可控的速度生产执行日志。不过，这个暂停会影响客户端的响应，直到主虚拟机可以继续写日志并恢复执行。所以，在实现时必须考虑如何尽量避免主虚拟机的日志缓冲区写满。</p>
<p>其中一个原因造成主虚拟机的日志缓冲区写满是因为从虚拟机执行的太慢从而造成消费日志太慢。一般来说，从虚拟机必须以和主虚拟机记录执行日志一样的速度来执行重放。幸运的是，在 <code>VMware FT</code> 的实现下，记录执行日志和重放所需要的时间基本是相同的。不过，如果从虚拟机所在的机器存在和其他虚拟机资源竞争（资源超卖），不管 <code>hypervisor</code> 的虚拟机调度多么高效，从虚拟机都有可能得不到足够的 <code>CPU</code> 和内存资源来保证和主虚拟机一样的速度执行重放。</p>
<p>除了主虚拟机日志缓冲区满造成的不可控暂停外，还有一个原因也要求主从虚拟机间的状态不能差太远。当主虚拟机异常时，从虚拟机必须尽快的将所有的执行日志进行重放，达到和主虚拟机一样的状态，然后接管主虚拟机向客户端提供服务。结束重放的时间基本上等于异常发生时从虚拟机落后主虚拟机的时间，所以从虚拟机进入 <code>go live</code> 模式需要的时间就基本上等于检测出异常的时间加上当前从虚拟机落后的时间。因此，从虚拟机不能落后主虚拟机太多（大于一秒），否则这会大大增加故障切换的时间。</p>
<p>因此，<code>VMware FT</code> 有另一套机制来保证从虚拟机不会落后主虚拟机太多。在主从虚拟机间的通信协议里，还会发送额外的信息来计算两者间的执行时间差。一般来说这个时间差在100毫秒以内。如果从虚拟机开始明显落后主虚拟机（例如大于1秒），那么 <code>VMware FT</code> 会通知调度器降低主虚拟机的 <code>CPU</code> 资源配额（初始减少几个百分点）来延缓主虚拟机的执行。<code>VMware FT</code> 会根据从虚拟机返回的落后时间来不断调整主虚拟机的 <code>CPU</code> 资源配额，如果从虚拟机一直落后，那么 <code>VMware FT</code> 会逐渐减少主虚拟机的 <code>CPU</code> 资源配额。相反的，如果从虚拟机开始赶上了主虚拟机的执行速度，那么 <code>VMware FT</code> 会逐渐增加主虚拟机的 <code>CPU</code> 资源配额，直到两者的执行时间差到达一个合理的值。</p>
<p>不过在实际场景中减慢主虚拟机执行的速度非常少见，一般只会发生在系统承受极大负载的情况下。</p>
<h3 id="FT-虚拟机上的操作"><a href="#FT-虚拟机上的操作" class="headerlink" title="FT 虚拟机上的操作"></a><code>FT</code> 虚拟机上的操作</h3><p>另一个实际中要考虑的问题是处理针对主虚拟机的一系列控制操作。例如，如果主虚拟机主动关机了，从虚拟机也需要同步关机，而不是进入 <code>go live</code> 模式。另外，所有对主虚拟机的资源修改（例如增加 <code>CPU</code> 资源配额）都必须应用到从虚拟机上。针对这些操作，系统会将其转化为特殊的执行日志发送到 <code>logging channel</code>，从虚拟机收到后也会将其正确的重放。</p>
<p>一般来说，大部分对虚拟机的操作都只应该在主虚拟机上发起。然后 <code>VMware FT</code> 会将其转化为日志发送给从虚拟机来进行重放。唯一可以独立的在主虚拟机和从虚拟机上执行的操作是 <code>VMotion</code>。即主虚拟机和从虚拟机都可以独立的被复制到其他机器上。<code>VMware FT</code> 保证了在复制虚拟机时不会将其复制到一台已经运行了其他虚拟机的机器上，因为这无法提供有效的容错保证。</p>
<p>复制一台主虚拟机要比复制一台普通的虚拟机复杂些，因为从虚拟机需要先和主虚拟机断开连接，然后之后在合适的时间和新的主虚拟机建立连接。从虚拟机的复制有同样的问题，不过也略微复杂些。对于普通的虚拟机迁移来说，系统会要求当前所有进行中的磁盘 <code>IO</code> 在切换前执行完成。对于主虚拟机来说，它可以等待所有进行中的磁盘 <code>IO</code> 的完成通知。而对于从虚拟机来说，它不能简单的在某个时间让所有的磁盘 <code>IO</code> 都结束，因为从虚拟机还在执行重放，也需要等待重放涉及的磁盘 <code>IO</code> 完成。而另一方面，主虚拟机在执行时有可能一直伴有磁盘 <code>IO</code>。<code>VMware FT</code> 有一个特有的方法来解决这个问题，当从虚拟机在执行切换前，会通过 <code>logging channel</code> 向主虚拟机发送请求要求暂时结束所有的磁盘 <code>IO</code>，主虚拟机收到请求后会天然的将其转化为执行日志发送到 <code>logging channel</code>，从虚拟机的磁盘也因此会伴随着重放而终止。</p>
<h3 id="磁盘-IO-的实现问题"><a href="#磁盘-IO-的实现问题" class="headerlink" title="磁盘 IO 的实现问题"></a>磁盘 <code>IO</code> 的实现问题</h3><p><code>VMware</code> 在实现时遇到了一些和磁盘 <code>IO</code> 相关的问题。首先，因为磁盘操作是非阻塞的所以可以并行执行，同一时间访问同一块磁盘区域就会导致非确定性结果。另外，磁盘 <code>IO</code> 会通过 <code>DMA</code>（<code>Direct memory access</code>） 来直接访问虚拟机的内存，因此同一时间的磁盘操作如果访问到了同一块内存页也会导致非确定性结果。<code>VMware</code> 通过监测这样的 <code>IO</code> 竞争（实际场景中极少）并强制让其在主虚拟机和从虚拟机中串行执行来解决这个问题。</p>
<p>第二，磁盘操作访问内存可能和应用程序访问内存产生竞争，因为磁盘操作可以通过 <code>DMA</code> 直接访问内存。例如，如果应用程序正在访问某个内存块，而此时磁盘也在写入这个内存块，则会发生非确定性的结果。虽然这种情况同样很少，但也仍然需要能够监测并解决。其中一种解决方案是当磁盘正在访问某个内存页时暂时对该页设置页保护。当应用程序尝试访问页保护的内存页时，会触发一个陷阱（<code>trap</code>）使得操作系统能够暂停执行直到磁盘操作完成。不过，修改 <code>MMU</code>（<code>Memory management unit</code>）的页保护机制代价较大，<code>VMware</code> 借助 <code>bounce buffer</code> 来解决这个问题。<code>bounce buffer</code> 是一块和磁盘操作正在访问的内存一样大小的临时缓冲区。磁盘的读操作被修改为磁盘先将数据复制到 <code>bounce buffer</code> 中，然后虚拟机读取 <code>bounce buffer</code> 中的数据，而且只有在磁盘 <code>IO</code> 完成后才会将 <code>bounce buffer</code> 中的数据复制到虚拟机内存中。类似的，对于磁盘写操作，数据会先写到 <code>bounce buffer</code> 中，磁盘写操作再将数据从 <code>bounce buffer</code> 复制到磁盘上。使用 <code>bounce buffer</code> 的情况下会降低磁盘的吞吐，不过实际中还没有发现造成可见的性能损耗。</p>
<p>第三，还有些问题发生于主虚拟机正在执行某些磁盘 <code>IO</code>（未完成），然后主虚拟机异常，从虚拟机接管执行。对于从虚拟机来说，它并不知道这些磁盘 <code>IO</code> 是否已发送给磁盘或者已成功执行。另外，由于这些磁盘 <code>IO</code> 还没有在从虚拟机上发起过，所以也不会相应的 <code>IO</code> 完成的通知，但是在操作系统的角度指令已经发出了，所以从虚拟机上的操作系统也收不到 <code>IO</code> 完成的通知，最终会终止或者重置这个过程。在这种情况下，系统会为每一个 <code>IO</code> 操作发送一个失败的通知，即使某个 <code>IO</code> 操作实际成功了而返回失败也是可以接受的。然而，由于从虚拟机上的操作系统可能不能很好的响应 <code>IO</code> 失败的通知，所以在从虚拟机 <code>go live</code> 阶段会重新发起这些 <code>IO</code> 请求。因为系统已经消除了并发 <code>IO</code> 间的竞争，所以这些 <code>IO</code> 操作可以重新发起即使它们之前已经成功执行了（操作是幂等的）。</p>
<h3 id="网络-IO-的实现问题"><a href="#网络-IO-的实现问题" class="headerlink" title="网络 IO 的实现问题"></a>网络 <code>IO</code> 的实现问题</h3><p><code>VMware vSphere</code> 为虚拟机的网络提供了很多的性能优化。部分优化基于 <code>hypervisor</code> 能异步更新虚拟机的网络设备的状态。例如，在虚拟机还在执行时 <code>hypervisor</code> 就可以直接更新接收缓冲区。不过，这种异步更新同样也带来了非确定性。除非能保证在异步更新的时间点在主虚拟机上执行的指令能严格一致的在从虚拟机上重放，否则从虚拟机的状态就会和主虚拟机不一致。</p>
<p><code>FT</code> 中对网络代码改动最大的一块就是禁止了异步网络更新优化。从原先的异步更新缓冲区修改为强制陷入到陷阱（<code>trap</code>）中，<code>hypervisor</code> 响应后将更新记录到日志中，然后再将其应用到虚拟机上。类似的，异步从缓冲区中拉取数据包也同样被禁止了，同样由 <code>hypervisor</code> 托管执行。</p>
<p>消除了异步的网络设备状态更新以及前面所提到的 <code>Output Rule</code> 带来的延迟输出，为网络性能优化又提出了挑战。<code>VMware</code> 通过两个方面来优化网络性能。第一，实现了集群优化来减少虚拟机的陷阱和中断。当虚拟机在接收网络包时，<code>hypervisor</code> 可以在一个陷阱、中断内处理多组数据包来减少陷阱和中断的次数。</p>
<p>第二个网络优化是降低数据包延迟发送的时间。前面提到，只有当从虚拟机确认收到所有输出操作的日志后，主虚拟机才能执行输出操作。所以减少数据包延迟发送的时间等价于减少日志发送和确认的时间。这里主要的优化点是发送和接受消息回执的过程中确保不会触发线程切换。另外，当主虚拟机将某个数据包加入发送队列时，系统会强制刷新主虚拟机的日志缓冲区到 <code>logging channel</code> 中。</p>
<h2 id="其他设计方案"><a href="#其他设计方案" class="headerlink" title="其他设计方案"></a>其他设计方案</h2><p>本节主要描述了 <code>VMware</code> 在实现 <code>VMware FT</code> 时调研和考虑的其他一些方案。</p>
<h3 id="共享磁盘和非共享磁盘"><a href="#共享磁盘和非共享磁盘" class="headerlink" title="共享磁盘和非共享磁盘"></a>共享磁盘和非共享磁盘</h3><p>在当前的实现中，主虚拟机和从虚拟机共享一个存储。因此当发生主从切换时，从虚拟机上的数据天然是和主虚拟机上的数据一致的。共享存储相对于主从虚拟机来说是一个外部系统，所以任何对共享存储的写入都被视为和外部的通信。因此，只有主虚拟机被允许写入到共享存储，而且写入必须遵循 <code>Output Rule</code> 规则。</p>
<p>另一种设计是主虚拟机和从虚拟机各自有一套独立的存储。在这个设计中，从虚拟机会将所有的输出写入到自己的存储中，所以从虚拟机的数据也能和主虚拟机保持同步。下图展示了这种设计下的配置：</p>
<p><img src="/images/vm-ft-4.png" alt="alt"></p>
<p>在非共享磁盘的场景下，每天虚拟机的存储被视为该虚拟机内部状态的一部分。因此，虚拟机的输出没有必要遵循 <code>Output Rule</code> 规则。非共享磁盘的设计在主从虚拟机无法访问共享存储时很有用。这可能时因为共享存储不可用或者过于昂贵，或者主从虚拟机间的物理距离太长。一个主要的缺点是主从虚拟机开启容错时必须将双方的磁盘进行初始化同步。另外，双方的磁盘也有可能在异常发生后造成不同步，所以当备份虚拟机重启后，双方磁盘需要再次同步。所以，<code>FT VMotion</code> 不只要同步主从虚拟机的状态，还要同步磁盘的状态。</p>
<p>在非共享磁盘的场景下，系统就不能借助共享存储来解决脑裂问题。在这种场景下，系统可借助其他的外部组件，例如某个主从虚拟机都可以连接的第三方服务器。如果主从服务器属于某个多于两个节点的集群，那么就可以使用某个选主算法来选择谁能进入 <code>go live</code> 模式。在这种场景下，如果某台虚拟机获得了大多数节点的投票，那么它就可以进入 <code>go live</code> 模式。</p>
<h3 id="在从虚拟机上执行磁盘读操作"><a href="#在从虚拟机上执行磁盘读操作" class="headerlink" title="在从虚拟机上执行磁盘读操作"></a>在从虚拟机上执行磁盘读操作</h3><p>在当前的实现中，从虚拟机从来不会从虚拟磁盘中读取数据（不论是共享存储还是非共享存储）。因为磁盘读也是一种输入，所以会自然的将磁盘读取后的结果以日志的形式通过 <code>logging channel</code> 发送给从虚拟机。</p>
<p>另一种设计是涉及到磁盘读操作的执行由从虚拟机自行从磁盘中读取，主虚拟机不再向 <code>logging channel</code> 中发送磁盘读取数据。对于磁盘密集型的系统来说，这种设计可以大幅降低 <code>logging channel</code> 的负载。不过，这种设计也存在一些问题。这可能会降低从虚拟机的执行速度，因为从虚拟机在重放时必须先等待所有依赖的 <code>IO</code> 操作完成。</p>
<p>另外，当磁盘读失败时还需要额外的处理。如果主虚拟机读取磁盘成功了，而从虚拟机读取磁盘失败了，那么从虚拟机就需要进行重试直到成功，因为从虚拟机必须拿到和主虚拟机内存中一样的数据。相反的，如果主虚拟机读取磁盘失败了，则相应主虚拟机中目标内存中的数据就必须通过 <code>logging channel</code> 发送给从虚拟机，因为此时主虚拟机中内存中的数据是不确定的。</p>
<p>最后，在共享存储的模式下如果运行从虚拟机执行磁盘读也有个问题。如果主虚拟机在某个磁盘区域执行了读操作，然后马上又对相同的区域执行了写操作，那么这个写操作就必须等到从虚拟机读取完成后再执行。这个依赖也能够被监测和正确处理，不过也给系统实现增加了额外的复杂度。</p>
<p>在实际性能测试中，从虚拟机执行磁盘读操作的情况下应用程序的吞吐会降低 <code>1-4%</code>，但是也能有效降低 <code>logging channel</code> 的负载。因此，在 <code>logging channel</code> 的带宽有限的情况下，可以考虑使用从虚拟机磁盘读操作。</p>
<p>参考：</p>
<ul>
<li><a href="https://pdos.csail.mit.edu/6.824/papers/vm-ft.pdf">The Design of a Practical System for Fault-Tolerant Virtual Machines</a></li>
<li><a href="https://pdos.csail.mit.edu/6.824/notes/l-vm-ft.txt">6.824 2022 Lecture 4: Primary/Backup Replication</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hardware_performance_counter">Hardware performance counter</a></li>
<li><a href="https://en.wikipedia.org/wiki/Direct_memory_access">Direct memory access</a></li>
<li><a href="https://en.wikipedia.org/wiki/Memory_management_unit">Memory management unit</a></li>
</ul>
]]></content>
      <tags>
        <tag>MIT 6.824</tag>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title>MIT 6.824 - GFS</title>
    <url>/2022/04/19/mit-6.824-gfs/</url>
    <content><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>在 <a href="https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf">MapReduce: Simplified Data Processing on Large Clusters</a> 中提到，<code>MapReduce</code> 任务的输入输出构建在 <code>GFS</code> 之上，<code>GFS</code> 是 <code>Google</code> 内部开发的一个分布式文件系统，用于应对大型的数据密集型应用。在 <code>GFS</code> 之前，业界已经存在了一些分布式文件系统的实现，为什么 <code>Google</code> 还要再实现一套？因为基于 <code>Google</code> 内部应用的特点，有别于传统的分布式文件系统，除了考虑性能、可扩展性、可靠性和可用性之外，<code>GFS</code> 在设计时还考虑了以下三个方面：</p>
<ol>
<li>组件异常经常出现而不是偶尔出现。<code>GFS</code> 构建在成百上千台廉价的机器上，并同时被同等数量的客户端访问。在这个量级规模下，在任何时候某个组件都有可能发生异常以及发生异常后无法自动恢复。这里的异常不只包括硬件的异常，还包括软件的异常以及人为的错误。因此，对于异常的监控和检测，容错，以及异常的自动恢复是系统不可或缺的一个部分。</li>
<li>以传统的分布式文件系统的视角来看，<code>Google</code> 要处理的都是大文件，几个G的文件随处可见。</li>
<li>对于 <code>Google</code> 的数据应用来说，大部分对文件的写操作是追加操作而不是覆盖操作。对文件的随机写几乎可以说是不存在。文件一旦写入完成后，基本上就不会被再次修改，剩下的都是读操作，且大部分场景下是顺序读。<code>MapReduce</code> 系统就是这个应用场景的典型例子，<code>map</code> 任务持续顺序追加生成中间结果文件，<code>reduce</code> 任务不断的从中间结果文件中顺序读取。根据这个特点，追加写就成为了系统性能优化以及写操作原子性保证的主要设计方向。</li>
<li>将应用程序和文件系统的 <code>API</code> 协同设计有利于增加系统的灵活性。例如，<code>GFS</code> 提供了原子性的追加写操作，多个客户端可以并发追加写，而无需在应用程序层面进行加锁。</li>
</ol>
<h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><h3 id="假设"><a href="#假设" class="headerlink" title="假设"></a>假设</h3><p>本节主要描述了 <code>GFS</code> 设计的几个出发点：</p>
<ul>
<li>整个系统构建在一批廉价且经常出现异常的硬件上，所以设计上必须考虑对异常的监测和容错，以及异常发生后能够恢复到一个合适的程度。</li>
<li>需要能够高效管理几个G的大文件，系统也支持存储小文件，不过不会对其作特殊的优化。</li>
<li>系统需要支持两种文件读取方式：大量的流式读和少量的随机读。在大量的流式读场景下，每次读取大小一般在几百KB，或者1MB或更多。来自同一个客户端的连续读取一般是读取文件的某一段连续内容。而少量的随机读一般是在文件的任意位置读取几KB。对于性能敏感的应用程序来说，一般会将多个随机读根据读取的位置排序后批量读取，避免磁盘来回的随机寻址。</li>
<li>系统需要支持大量连续的文件追加写操作。对文件追加写的单次大小一般和流式读的单次大小差不多。文件一旦写入完成后就几乎不会再被修改。系统同样需要支持少量的随机写，不过和少量的随机读类似，随机写也不强调性能。</li>
<li>当有多个客户端对同一个文件进行追加写的时候，系统必须能高效的实现清晰明确的执行语义，例如是保证每个客户端至少成功追加写一次，还是至多一次或者其他。<code>GFS</code> 中的文件经常会充当某个生产者消费者场景下的缓冲队列，一边会有多个客户端不断往文件中追加写，一边也会有一个客户端同时进行流式读取（或在写入完成后读取），所以系统必须保证追加写操作的原子性。</li>
<li>整个系统的吞吐的重要性大于延迟，大部分 <code>Google</code> 的应用程序主要是大批量的文件处理，只有少量的程序会对单次的读或写有性能要求，所以系统的吞吐是第一位。</li>
</ul>
<h3 id="接口"><a href="#接口" class="headerlink" title="接口"></a>接口</h3><p>虽然 <code>GFS</code> 并未完全实现标准的文件系统 <code>API</code>，如 <code>POSIX</code>，但仍提供了常见的文件系统接口，如创建（<code>create</code>）、删除（<code>delete</code>）、打开（<code>open</code>）、关闭（<code>close</code>）、读取（<code>read</code>）和写入（<code>write</code>）文件。类似于本地文件系统，文件在 <code>GFS</code> 内通过树状目录的形式组织，每个文件通过文件路径来唯一确定，不过这里的目录是逻辑上的概念，并不会映射到某个物理文件系统目录上。</p>
<p>除此之外，<code>GFS</code> 还支持快照（<code>snapshot</code>）和追加写（<code>record append</code>）的操作。快照能够低成本的复制一个文件或一个目录。追加写允许多个客户端并发的对同一个文件追加写入，并保证每个客户端写入的原子性。</p>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p>一个 <code>GFS</code> 集群由一个主节点（<code>master</code>）和多个 <code>chunkserver</code> 组成，并被多个客户端（<code>client</code>）访问。不管是主节点还是 <code>chunkserver</code> 或客户端，都运行在廉价的 <code>Linux</code> 机器上。可以简单的将 <code>chunkserver</code> 和客户端运行在同一台机器上，如果系统资源允许或者能够容忍客户端代码潜在的不可靠性的话。</p>
<p>每个文件在存入 <code>GFS</code> 时会被切分为固定大小的块（<code>chunk</code>），每个 <code>chunk</code> 在创建时会被主节点分配一个全局不可变的64位 <code>chunk handle</code>。<code>chunkserver</code> 将 <code>chunk</code> 保存在本地文件系统中，每个 <code>chunk</code> 对应着本地的一个 <code>Linux</code> 文件，客户端通过指定 <code>chunk handle</code> 和文件偏移范围来读取或者写入 <code>chunk</code>。为了保证可靠性，每个 <code>chunk</code> 会复制到多台 <code>chunkserver</code> 上。<code>GFS</code> 默认为每个 <code>chunk</code> 生成3份副本，不过用户也可以为某些命名空间下的文件指定不同的副本数量。</p>
<p>主节点保存了全部的系统元数据，包括文件命名空间、访问控制信息、每个文件和对应 <code>chunk</code> 的映射、每个 <code>chunk</code> 所在的位置等。同时主节点还负责 <code>chunk</code> 的租约管理、不再使用的 <code>chunk</code> 的垃圾回收、<code>chunkserver</code> 间的 <code>chunk</code> 迁移等。主节点也会定期的向 <code>chunkserver</code> 发送心跳用于向 <code>chunkserver</code> 发送指令和收集 <code>chunkserver</code> 当前的状态。</p>
<p><code>GFS</code> 的客户端代码会集成到用户应用程序中，它负责实现文件系统 <code>API</code> 以及和主节点、 <code>chunkserver</code> 通信来读取或写入文件。<code>GFS</code> 客户端通过主节点获取文件的元数据信息，然而文件的读取和写入都只和 <code>chunkserver</code> 通信，从而减少了主节点的负担。</p>
<p>不管是 <code>GFS</code> 客户端还是 <code>chunkserver</code> 都不会缓存文件数据。客户端缓存收益不大是因为 <code>Google</code> 大部分的应用程序是对大文件的流式读取或者文件内容过大无法被缓存。不考虑缓存简化了客户端和整个系统的实现，因为引入缓存就要考虑缓存一致性问题。不过客户端会缓存文件的元数据信息，例如某个 <code>chunk</code> 的位置信息。<code>chunkserver</code> 不缓存是因为 <code>chunk</code> 是作为 <code>Linux</code> 文件保存在本地文件系统中，操作系统本身已经提供了一层文件访问缓存，没有必要再加一层。</p>
<h3 id="单主节点"><a href="#单主节点" class="headerlink" title="单主节点"></a>单主节点</h3><p>单主节点同样简化了整个系统的设计，方便主节点高效管理 <code>chunk</code>，因为所有需要的信息都保存在主节点内存中。为了避免对文件的读写使得主节点成为瓶颈，客户端读写文件时直接和 <code>chunkserver</code> 通信而不会经过主节点中转，不过在开始读写前，客户端会先和主节点通信获取需要的 <code>chunk</code> 对应的 <code>chunkserver</code> 列表，并将这个数据缓存一段时间来减少后续和主节点的通信。</p>
<p>结合下面的流程图我们来看一下一次读操作是如何执行的：</p>
<p><img src="/images/gfs-1.png" alt="alt"></p>
<ol>
<li>客户端根据固定的每个 <code>chunk</code> 的大小和想要读取的文件偏移位置，计算出 <code>chunk</code> 的索引。</li>
<li>客户端将文件名和 <code>chunk</code> 的索引发给主节点，主节点收到请求后返回对应的 <code>chunk handle</code> 和保存了该份 <code>chunk</code> 的 <code>chunkserver</code> 列表。</li>
<li>客户端收到主节点返回结果后，以文件名和 <code>chunk</code> 的索引组合作为键，将返回结果缓存。</li>
<li>客户端将 <code>chunk handle</code> 和想要读取的文件内容偏移范围发给其中一台 <code>chunkserver</code>，一般来说，客户端会选择距离最近的 <code>chunkserver</code>，由于缓存了 <code>chunkserver</code> 列表信息，后续对同一个 <code>chunk</code> 的读请求就不需要再次和主节点通信，直到缓存过期或者文件被再次打开。</li>
<li>一般来说，客户端和主节点通信时会在一次请求中要求多个 <code>chunk</code> 的信息，主节点同样也可在一次响应中返回多个 <code>chunk</code> 的信息，这也有利于减少客户端和主节点的通信次数。</li>
</ol>
<h3 id="chunk-大小"><a href="#chunk-大小" class="headerlink" title="chunk 大小"></a><code>chunk</code> 大小</h3><p>每个 <code>chunk</code> 的大小是一个关键的设计选择。<code>GFS</code> 的 <code>chunk</code> 大小为 <code>64 MB</code>，远大于一般文件系统的数据块的大小。每个 <code>chunk</code> 以 <code>Linux</code> 文件的形式保存在 <code>chunkserver</code> 上，但其实际占用的大小是动态增长的，从而避免了大量的文件碎片（例如实际只需要十几K的文件却固定分配了 <code>64 MB</code> 的大小）。</p>
<p>那么，<code>GFS</code> 为什么要选择 <code>64 MB</code> 这样较大的数呢？主要是因为：</p>
<ol>
<li><code>chunk</code> 的大小越大，每个文件拆分成的 <code>chunk</code> 的数量就越少，客户端需要读取或写入的 <code>chunk</code> 数量也就越少，和主节点通信的次数也就越少。对于 <code>Google</code> 的数据应用来说，大部分都是顺序读写，客户端和主节点交互的次数是线性的时间复杂度，减少 <code>chunk</code> 的总个数有助于降低整个的时间复杂度。即使是对于少数的随机写，由于 <code>chunk</code> 大小足够大，客户端也能够将TB级别的数据对应的所有 <code>chunk</code> 的信息缓存起来。</li>
<li>一个 <code>chunk</code> 的大小越大，那么客户端对其可操作次数就越多，客户端就可以和某个 <code>chunkserver</code> 维持一段较长时间的 <code>TCP</code> 连接，减少和不同的 <code>chunkserver</code> 建立连接的次数。</li>
<li>主节点需要维护每个 <code>chunk</code> 对应的 <code>chunkserver</code> 列表，这个也是个线性的空间复杂度，较大的 <code>chunk</code> 大小能减少 <code>chunk</code> 的总个数，从而减少元数据的大小，主节点就可以将所有的元数据放在内存中。</li>
</ol>
<p>另一方面，即使将 <code>chunk</code> 的大小设置的较大，以及采用了懒分配的策略，也依然存在缺点。对于一个小文件来说，它可能只有几个甚至是一个 <code>chunk</code>，如果这个文件被访问的频率较大，它就有可能成为热点数据，保存了对应的 <code>chunk</code> 的 <code>chunkserver</code> 就要承受更大的流量。不过在 <code>Google</code> 的实际应用场景中，热点数据并没有成为一个大问题，因为大部分的系统面向的是大文件的流式读取，流量能较平均的分发到各个 <code>chunkserver</code>。</p>
<p>不过，<code>Google</code> 确实有遇到过一个热点数据问题，有个批处理系统会先将一个可执行文件写入到 <code>GFS</code> 中，这个可执行文件的大小只有一个 <code>chunk</code>，然后所有客户端会同时读取这个可执行文件并执行，这就造成了几台 <code>chunkserver</code> 同时承接了大量的请求。<code>Google</code> 通过两个方面来解决这个问题，第一针对这个文件设置一个较大的副本数量，让更多的 <code>chunkserver</code> 来分散流量，即水平扩展；第二交替启动批处理系统的客户端，避免同一时间的大量请求。另一种长期的解决方案是在这种场景下允许客户端从其他已读取完毕的客户端那读取文件。</p>
<h3 id="元数据"><a href="#元数据" class="headerlink" title="元数据"></a>元数据</h3><p>主节点主要保存了三类元数据：每个文件和 <code>chunk</code> 所属的命名空间、每个文件到对应所有 <code>chunk</code> 的映射、每个 <code>chunk</code> 对应的 <code>chunkserver</code> 列表。所有的元数据都保存在主节点的内存中，前两种元数据被修改时还会以日志的形式保存在本地日志文件中，并备份到其他服务器上。通过日志文件的方式使得主节点能够轻松的修改元数据，并且在主节点崩溃重启后能恢复数据，当然极端情况下主节点有可能没有保存最新的元数据到日志文件中就崩溃了，这里后文会有说明主节点会在持久化完成后才返回结果给客户端，所以客户端不会看到未持久化的元数据。主节点并不会对 <code>chunkserver</code> 列表进行持久化，而是在启动时主动拉取所有 <code>chunkserver</code> 的信息，以及每当一个新的 <code>chunkserver</code> 加入到集群中时，更新元数据，因为 <code>chunkserver</code> 是个动态更新的数据，即使持久化了也需要和当前实时的数据作比对。</p>
<h4 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h4><p>由于元数据保存在主节点内存中，所以涉及主节点的操作都是非常快的。另一方面，主节点也能够轻易的每隔一段时间遍历所有的元数据，这个主要有三个目的，第一是扫描不再需要的 <code>chunk</code> 进行垃圾回收；第二如果某个 <code>chunkserver</code> 失联了，能将其保存的 <code>chunk</code> 备份到其他 <code>chunkserver</code> 上；第三将某些流量失衡或者本地磁盘空间不够的 <code>chunkserver</code> 下的 <code>chunk</code> 转移到其他 <code>chunkserver</code> 下。</p>
<p>将元数据保存在内存中的一个缺陷是受限于主节点的内存容量，能够保存的 <code>chunk</code> 的元数据的个数是有限的，从而整个 <code>GFS</code> 的容量大小是有限的。不过在实践中，这个问题还没有成为瓶颈，每个 <code>chunk</code> 对应的元数据大小约小于64字节，由于 <code>GFS</code> 面向的主要是大文件，所以基本上每个文件也就最后一个 <code>chunk</code> 没有塞满，所以空间浪费较少。类似的，由于使用了前缀压缩，每个文件的命名空间元数据的大小也小于64字节。对于一个 <code>128 GB</code> 内存的主节点来说，假设全部用来保存 <code>chunk</code> 的元数据，则理论上保存的所有 <code>chunk</code> 的大小为 <code>128 GB / 64 B * 64 MB = 128 PB</code>，虽然实际上元数据不只 <code>chunk</code> 一种，但整体上来说也能够维护 <code>PB</code> 级别的数据。</p>
<p>如果需要 <code>GFS</code> 支撑更大的容量，相比于将元数据全部保存在内存中所带来的的简洁、可靠、性能和灵活上的收益，扩展主节点的内存所需要的成本不值一提。</p>
<h4 id="chunk-的保存位置"><a href="#chunk-的保存位置" class="headerlink" title="chunk 的保存位置"></a><code>chunk</code> 的保存位置</h4><p>主节点不会持久化每个 <code>chunk</code> 对应的 <code>chunkserver</code> 列表，它会在启动时主动拉取所有的 <code>chunkserver</code> 信息。在主节点运行后，它可以通过和 <code>chunkserver</code> 的心跳来实时更新 <code>chunkserver</code> 的状态信息。</p>
<p>在最初的设计中，<code>Google</code> 的工程师试过将 <code>chunk</code> 和 <code>chunkserver</code> 的映射关系进行持久化，但是最终还是采用了更简洁的设计，即在主节点启动时主动拉取所有的 <code>chunkserver</code> 信息并在之后定期更新内存中的数据。这就消除了频繁的数据同步，毕竟在集群环境下，<code>chunkserver</code> 加入或者离开集群，修改主机名，发生异常或重启等操作会经常发生。</p>
<p>另一方面，只有 <code>chunkserver</code> 才真正知道自己是否拥有某个 <code>chunk</code>，所以在主节点上持久化一份 <code>chunk</code> 和 <code>chunkserver</code> 的映射关系意义不大，因为这份数据很大概率是不一致的，毕竟 <code>chunkserver</code> 会发生异常然后失联或者运维重命名了一台 <code>chunkserver</code>。</p>
<h4 id="操作日志"><a href="#操作日志" class="headerlink" title="操作日志"></a>操作日志</h4><p>操作日志记录了元数据的重要历史更新，它是 <code>GFS</code> 的关键。不仅因为它是元数据的唯一持久化备份，同时它也提供了系统在并发操作下各操作的执行顺序。各个版本的文件和其对应的 <code>chunk</code> 的操作记录都被唯一的标识在日志文件中。</p>
<p>所以操作日志必须保证可靠性存储，以及在元数据持久化完成之前不能将最新的元数据更新暴露给客户端。否则就有可能丢失最新的客户端操作，即使 <code>chunkserver</code> 还存活着。因此，<code>GFS</code> 会将操作日志备份在多台机器上，并且只有在所有的副本机器都持久化完成后才会返回结果给客户端。同时主节点会对操作日志进行批量持久化以降低频繁持久化对系统整体吞吐的影响。</p>
<p>当主节点崩溃重启后会通过重放操作日志来恢复崩溃前的状态，然而如果每次都从第一条日志开始重放，主节点崩溃重启到可用需要的时间会越来越久，因此当操作日志的大小增长到一定程度的时候，主节点会为当前的元数据创建一个检查点，当主节点崩溃恢复后，可以先加载最新的检查点数据，然后再重放在这个检查点之后生成的操作日志。检查点是一个类似于 <code>B</code> 树的数据结构，可以轻易的映射到内存数据结构中，并且方便根据文件的命名空间检索。这就加快了主节点崩溃恢复的速度和提高了系统的可用性。</p>
<p>因为构建检查点需要时间，所以在创建检查点时需要确保不影响正在进行的文件修改。主节点会先创建一个新的操作日志文件，然后由一个新的线程去创建检查点，这个线程会依据新的操作日志文件创建前的日志生成检查点。对于一个百万级别数量文件的系统来说，大概需要1分钟的时间创建检查点，检查点创建完成后同样会持久化到本地磁盘和副本机器上。</p>
<p>主节点崩溃恢复只需要最新完整的检查点文件以及后续的操作日志文件，在这之前的检查点文件和操作日志文件都可以删除，不过为了提高容错性还是会保留一部分文件。如果生成检查点的时候发生异常并不会影响崩溃恢复的正确性，因为恢复的代码会校验检查点文件的完整性并跳过损坏的检查点文件。</p>
<h3 id="一致性模型"><a href="#一致性模型" class="headerlink" title="一致性模型"></a>一致性模型</h3><p><code>GFS</code> 提供了弱一致性模型，在能较好的支撑 <code>Google</code> 内部各分布式应用的同时也兼顾了简洁和高效的实现。</p>
<h4 id="GFS-的保证"><a href="#GFS-的保证" class="headerlink" title="GFS 的保证"></a><code>GFS</code> 的保证</h4><p>文件命名空间的修改是原子的（例如创建一个文件）。对命名空间的修改会由主节点加锁执行，这就保证了修改的原子性和正确性，同时主节点的操作日志记录了这些修改的全局顺序。</p>
<p>而某块文件区域修改后的状态则取决于修改的类型，是否成功或失败，以及是否存在并发的修改。某块文件区域是一致的（<code>consistent</code>）表示不管客户端从哪个 <code>chunkserver</code> 读取这块的数据，每个客户端看到的内容始终是相同的。某块文件区域是已定义的（<code>defined</code>）表示经过一次修改后，首先这块文件区域是一致的，并且客户端读到的数据就是自己修改的。如果对某块文件区域的修改不受其他并发请求的客户端的影响，那么这块文件区域在修改成功后是已定义的（也是一致的），所有的客户端都能看到对应的修改。而如果有多个客户端并发的对同一块文件区域修改，那么最终的结果是未定义的，但是是一致的，所有的客户端读到的数据都是相同的，但是并不知道读到的数据是哪个客户端修改的，一般来说，最后这块文件区域的内容很可能是多个客户端并发修改后混合的结果。一次失败的修改会使得这块文件区域不一致（因此也是未定义的），不同的客户端在不同时间读取到的数据是不同的，因为多个 <code>chunkserver</code> 上保存的数据不一致。</p>
<p>对文件的修改包括在随机位置的写和在文件末尾的追加写两种，随机写指的是数据会写入到应用程序指定的某个文件偏移的位置，追加写指的是在并发的情况下能保证数据会原子性的至少一次追加写入到文件末尾，不过最后数据写入的实际偏移位置是由 <code>GFS</code> 来决定（相反的，一次常规的追加写指的是在客户端以为是文件末尾的地方写入数据。）。追加写完成后，系统会返回相应的偏移量给客户端，这个偏移量表示了某块已定义的文件区域的开始，对于当前客户端来说，这块区域的数据就是自己写入的，对于其他客户端来说，它们读到的数据也始终是相同的。不过，<code>GFS</code> 有可能在修改 <code>chunk</code> 时插入对齐数据或者重复的数据，例如现在有个追加写操作，<code>chunkserver1</code> 需要写入的偏移量位置是100，并且写入完成了，<code>chunkserver2</code> 需要写入的偏移量位置也是100，但是 <code>chunkserver2</code> 写入失败了，客户端会进行重试，那么 <code>chunkserver1</code> 会在偏移量101的地方再次写入相同的数据，但是由于之前 <code>chunkserver2</code> 没有写入成功，它的偏移量位置还是100，那么为了保证所有客户端根据偏移量读取到的数据是相同的，就需要先补齐 <code>chunkserver2</code> 偏移量位置100的数据，然后在偏移量位置101写入新的数据，如果这次所有 <code>chunkserver</code> 都写入成功了，那么就会把偏移量101返回给客户端，而不是100。所以我们看到，客户端想要保存的原始文件，和最终从 <code>GFS</code> 取回的文件数据并不是每个比特都一致的，存在某些文件区域数据不一致的情况。</p>
<p>当一系列文件修改执行完成后，被修改的文件区域保证了是已定义的，并且包含了最后一次修改的内容。<code>GFS</code> 通过两个方面来保证这一点：第一，对 <code>chunk</code> 的所有修改在所有 <code>chunkserver</code> 上的执行顺序是一样的；第二，通过 <code>chunk</code> 的版本号来识别所有版本落后的 <code>chunkserver</code>，这些 <code>chunkserver</code> 有可能是因为在失联期间 <code>chunk</code> 内容发生了修改。对于版本号落后的 <code>chunkserver</code> 则不会参与 <code>chunk</code> 的修改并且主节点也不会将其作为有效的 <code>chunkserver</code> 返回给客户端，这些 <code>chunkserver</code> 所持有的 <code>chunk</code> 会尽早的被垃圾回收。</p>
<p>然而在前面提到，客户端从主节点获取某个 <code>chunk</code> 的 <code>chunkserver</code> 列表后，会在一段时间内将其缓存，如果这段时间内某个 <code>chunkserver</code> 包含的 <code>chunk</code> 的版本号落后了，那么客户端读到的数据会存在短暂的不一致，这个时间段就取决于客户端缓存的过期时间，以及客户端下次打开文件的时间，因为重新打开文件时客户端会从主节点重新拉取 <code>chunkserver</code> 的信息从而刷新了缓存。然而，鉴于大部分文件的修改是追加写，这里我理解可能在流式读的场景下，读完 <code>chunk</code> 的某段内容后会返回新的偏移量，而对于版本号落后的 <code>chunkserver</code> 来说，它返回的偏移量可能已经读过了，所以此时客户端知道这个 <code>chunkserver</code> 可能过期了，所以会尝试再次和主节点通信，从而获取新的 <code>chunkserver</code> 列表。</p>
<p>然而即使对文件的修改执行成功了，系统其他组件如硬件的异常也有可能导致文件损坏或摧毁。<code>GFS</code> 通过主节点和 <code>chunkserver</code> 的心跳来监测异常的机器，并通过校验和来验证 <code>chunk</code> 的数据是否损坏。如果出现了数据损坏或者某台 <code>chunkserver</code> 失联了，那么 <code>GFS</code> 会从其他有效的 <code>chunkserver</code> 那重新复制数据，来保证副本数量维持在指定的阈值上。所以，只有当某个 <code>chunk</code> 对应的 <code>chunkserver</code> 全都异常了，同时 <code>GFS</code> 还没来得及反应过来（一般来说是几分钟内）复制数据，<code>chunk</code> 才会发生永久丢失。即使在这种情况下，对于应用程序来说它看到的是不可用的状态，而不是数据损坏：应用程序收到的是明确的错误信息而不是损坏的数据。</p>
<p>最后，来看一下每种操作下的一致性保证：</p>
<ul>
<li>随机写<ul>
<li>串行执行成功：已定义（<code>defined</code>），在串行执行场景下，某个时间只会有一个客户端执行写入，客户端在执行成功后读取到的就是自己刚刚写入的，所以是已定义的。</li>
<li>并行执行成功：一致但是未定义（<code>consistent but undefined</code>），某个时间在并发场景下多个客户端写入的偏移范围可能重合，最后文件区域的数据可能是多个客户端写入混合后的产物，每个客户端写入后读取到的不一定是自己写入的，所以是未定义的，但由于写入成功，所以是一致的。</li>
<li>异常：不一致（<code>inconsistent</code>），写入失败时，有的 <code>chunkserver</code> 可能写入成功，有的未成功，不同客户端读取同一个偏移量的数据就会不一致。</li>
</ul>
</li>
<li>追加写<ul>
<li>串行执行成功：已定义但是穿插着不一致（<code>defined, interspersed with inconsistent</code>），由于追加写至少写入一次的保证，一次追加写的成功背后可能包含着重试，所以在某些偏移量下各个 <code>chunkserver</code> 上的 <code>chunk</code> 的数据会不一致，但是追加写返回的是一个写入成功的偏移量，不会把不一致的偏移量返回，这个新的偏移量下的数据就是客户端自己写入的，且每个客户端读取这个偏移量的内容都是相同的，所以是已定义的。</li>
<li>并行执行成功：同上，追加写返回的偏移量是由 <code>GFS</code> 决定的，所以多个并发客户端追加写入不会相互覆盖。</li>
<li>异常：不一致（<code>inconsistent</code>），同随机写。</li>
</ul>
</li>
</ul>
<h4 id="对应用程序的影响"><a href="#对应用程序的影响" class="headerlink" title="对应用程序的影响"></a>对应用程序的影响</h4><p>借助追加写、检查点、可自我校验和识别的数据写入，<code>GFS</code> 的应用可以较好的适应 <code>GFS</code> 的弱一致性模型。</p>
<p>在实际应用场景中，<code>GFS</code> 的应用基本是通过追加写而不是覆盖写来修改文件。在某个典型应用中，某个文件的内容完全由某个生产者写入，在写入完成后能原子性的将其重命名，或者周期性的为至今写入成功的数据建立检查点。检查点同时也可包含应用程序级别的校验和（不同于 <code>GFS</code> 的校验和，应用程序保存的数据对于 <code>GFS</code> 来说是一致的，但对于应用来说可能是不完整的）。对于读文件的消费者来说，它们只需要读取到最新的检查点即可，因为到最新的检查点的数据可以认为是已定义的（<code>defined</code>），并可以通过校验和来验证文件数据的完整性。如上节所属，虽然追加写在失败时也会存在不一致的情况，但结合检查点的方式已经能较好的满足实际的业务场景。另外，追加写也远比随机写高效和健壮。借助检查点生产者可以在崩溃恢复后从检查点开始继续写入，消费者只根据检查点来读取数据，而不会越过检查点读到以应用的视角来说不完整的数据。</p>
<p>在另一个例子中，多个生产者并发的向某个文件进行追加写，追加写至少写入成功一次的保证使得每个生产者的写入都得以保留。不过，消费者在读取文件时就需要额外处理对齐数据和重复数据，每一条追加写可以看做一条记录，生产者在写入时可以附加一个校验和用于消费者校验数据的完整性，对于对齐数据或不完整的数据来说，它们必然没有校验和，因此消费者就可以跳过这些异常记录。另外，每一条记录都有一个唯一的标识符，重复的记录有着相同的标识符，如果消费者不能容忍重复的数据（例如消费者的代码没有做到幂等），则可以通过这个标识符来对数据去重。除了去重以外，上述的功能都已包含在客户端库中，无需应用端自行实现，从而使得在应用层面每一个消费者都能读到同一份数据（当然，可能会有一点重复数据）。</p>
<h2 id="系统交互"><a href="#系统交互" class="headerlink" title="系统交互"></a>系统交互</h2><p>在单主节点的设计下，<code>GFS</code> 尽可能的让主节点少参与到数据交互中，本节主要描述了客户端、主节点和 <code>chunkserver</code> 在数据修改、原子性的追加写和快照中的实现。</p>
<h3 id="租约和修改的执行顺序"><a href="#租约和修改的执行顺序" class="headerlink" title="租约和修改的执行顺序"></a>租约和修改的执行顺序</h3><p>一次修改（<code>mutation</code>）指的是修改了某个 <code>chunk</code> 的元数据或者内容。每个修改都会应用到该 <code>chunk</code> 的所有 <code>chunkserver</code> 上。在修改前，主节点会挑选某个 <code>chunkserver</code> 作为 <code>primary</code>，为其分配一个租约（<code>lease</code>）。对某个 <code>chunk</code> 的修改可能同时会有多个，所以 <code>primary</code> 会对所有的修改安排一个执行顺序，所有其他的 <code>chunkserver</code> 都会按照这个执行顺序应用修改。因此，从全局来看，对同一个 <code>chunk</code> 的修改的顺序首先取决于主节点分配租约的顺序，在某个租约有效期内的执行顺序，则取决于 <code>primary</code> 安排的执行顺序。</p>
<p>租约的设计是为了减少主节点协调的负担。一个租约初始设置了60秒的过期时间，不过如果在过期前该 <code>chunk</code> 还未完成修改，<code>primary</code> 可向主节点申请租约续期。这个申请可以附带在 <code>chunkserver</code> 和主节点的心跳监测中，而无需额外通信。不过有时候主节点可能会在租约有效期内回收租约（例如，某个文件正在重命名时主节点需要暂停所有的修改）。即使主节点和当前的 <code>primary</code> 失联了，主节点依然可以在该租约过期后安全的重新分配一个租约给新的 <code>primary</code>。</p>
<p>同时，租约也避免了脑裂的问题，如果没有租约的时间限制，主节点先指定了一个 <code>primary</code>，然而由于网络原因主节点认为这个 <code>primary</code> 失联了，就会重新分配一个 <code>primary</code>，此时就有两个 <code>chunkserver</code> 认为自己是 <code>primary</code>。而在租约过期前，主节点不会分配新的 <code>primary</code> 就保证了同一时间只有一个 <code>primary</code>。</p>
<p>下图描述了一次随机写的执行流程：</p>
<p><img src="/images/gfs-2.png" alt="alt"></p>
<ol>
<li>客户端询问主节点当前持有租约的 <code>primary</code> 和其他的 <code>chunkserver</code> 的地址，如果当前没有一台 <code>chunkserver</code> 持有租约，则主节点会挑选一个 <code>primary</code> 并分配租约。</li>
<li>主节点返回当前的 <code>primary</code> 和其他的 <code>chunkserver</code>（<code>secondary</code>） 的地址。客户端收到响应后将其缓存供后续修改时使用，只有当 <code>primary</code> 无响应或者 <code>primary</code> 回复不再持有租约时，客户端才会再次询问主节点 <code>primary</code> 的信息。</li>
<li>客户端将需要写入的数据发送给所有的 <code>chunkserver</code>，这一步没有执行顺序的要求。每个 <code>chunkserver</code> 收到数据后会将其暂存在一个 <code>LRU</code> 缓存中直到该数据被取出或过期。从控制流角度来说，是由 <code>primary</code> 向 <code>secondary</code> 发送指令，而发送待写入的数据不关心谁是 <code>primary</code>，下文会说到这里 <code>GFS</code> 将数据流和控制流进行解耦，基于网络的拓扑结构来实现数据的最优传输。</li>
<li>当所有 <code>chunkserver</code> 都收到了客户端的数据后，客户端会向 <code>primary</code> 发送一个写入请求，这个请求中标记了之前发送的那份数据。<code>primary</code> 将该时段收到的所有修改请求设置一个串行的执行顺序，并对每一个修改分配一个执行编号，然后将修改写入到本地的 <code>chunk</code> 中。</li>
<li><code>primary</code> 将写请求分发给其他所有的 <code>secondary</code>，<code>secondary</code> 收到请求后根据执行编号同样将修改按照和 <code>primary</code> 一样的执行顺序写入到自己的 <code>chunk</code> 中。</li>
<li>每个 <code>secondary</code> 写入完成后会回复 <code>primary</code> 告知写入完成。</li>
<li>当 <code>primary</code> 收到所有 <code>secondary</code> 的回复后，再回复给客户端告知写入成功。如果途中任何一个 <code>chunkserver</code> 出现异常都会通知客户端，当发生异常时，可能 <code>primary</code> 已经写入成功了，但是某个 <code>secondary</code> 只写入成功一部分（如果是 <code>primary</code> 写入异常，就不会分发写请求给其他所有的 <code>secondary</code>）。因此此次客户端请求就认为写入失败，多个 <code>chunkserver</code> 间出现了数据不一致，此时客户端会进行重试，它会尝试重新执行第3步到第7步，如果尝试几次后依然失败，则会重新从第1步开始执行。</li>
</ol>
<p>如果客户端一次随机写的数据量较大或者当前 <code>chunk</code> 的剩余空间无法容纳全部的数据则需要跨 <code>chunk</code> 写入，<code>GFS</code> 的客户端库会将一次写请求拆分为多个写请求处理。每个单独的写请求都遵循上述的流程执行，不过由于存在并发客户端写的问题，最终写入的数据有可能多个客户端间相互覆盖，不过由于每个 <code>secondary</code> 都按照相同的执行顺序写入成功，最终各个 <code>chunkserver</code> 上的数据都是相同的，这个也就是之前描述的一致但是未定义状态（<code>consistent but undefined</code>）。</p>
<h3 id="数据流"><a href="#数据流" class="headerlink" title="数据流"></a>数据流</h3><p>在前面提到，在第3步发送数据时，<code>GFS</code> 解耦了控制流和数据流以更有效率的利用网络。在控制流下，请求从客户端发送到 <code>primary</code>，再由 <code>primary</code> 分发给其他所有的 <code>secondary</code>，在数据流下，<code>GFS</code> 会选择最优的路径以接力的方式在各个 <code>chunkserver</code> 间传递数据。目的是为了充分的利用每台机器的网络带宽，同时避免网络瓶颈和高延迟的链路，从而降低推送全部数据的整体延迟。</p>
<p>为了尽可能的充分利用每台机器的网络带宽，<code>GFS</code> 选择了线性接力的方式在各个 <code>chunkserver</code> 间传递数据，而不是其他的分发方式（如树状分发，例如以一台机器发送给3台机器为例，发送的机器的出口带宽就被3台机器共享）。</p>
<p>为了尽可能的避免网络瓶颈和高延迟的链路，每个机器会选择在网络结构下距离最近且还未收到数据的机器传递数据。假设现在客户端需要推送数据给 <code>S1</code> 到 <code>S4</code> 四台机器，客户端先将数据发送给距离最近的机器，比如说是 <code>S1</code>，<code>S1</code> 同样将数据转发给距离 <code>S1</code> 最近的机器，比如说是 <code>S2</code>，依此类推，最后数据到达 <code>S4</code>。<code>Google</code> 内部的网络拓扑结构足够简单使得两台机器间的距离能够较准确的根据 <code>IP</code> 地址估算出来。</p>
<p>最后，<code>GFS</code> 在 <code>TCP</code> 连接上构建了一条流式接力传递的数据流来降低数据传递的延迟。每个 <code>chunkserver</code> 一旦收到一定大小的数据后就马上将其转发给距离最近的其他 <code>chunkserver</code>。收到数据就马上转发并不会降低收数据的速率。在没有网络拥堵的情况下，假设 <code>T</code> 是当前网络的吞吐，<code>L</code> 是两台机器间的传输速度，那么要传输 <code>B</code> 字节给 <code>R</code> 个 <code>chunkserver</code> 需要的时间为 <code>B / T + RL</code>，其中 <code>B / T</code> 是完整传输 <code>B</code> 个字节给第一台机器的时间，<code>RL</code> 表示第一台机器发送的第一个字节经过接力到达最后一台机器所需要的时间。在 <code>Google</code> 的网络环境下，<code>T</code> 为 <code>100 Mbps</code>，<code>L</code> 远小于 <code>1 ms</code>，所以 <code>RL</code> 的时间基本可以忽略，因此传输 <code>1 MB</code> 的数据理论上约需要 <code>80 ms</code>（(1 * 1024 * 1024 * 8 / 100 * 1000000) * 1000 ms）。</p>
<h3 id="原子性追加写"><a href="#原子性追加写" class="headerlink" title="原子性追加写"></a>原子性追加写</h3><p><code>GFS</code> 提供了原子性的追加写操作（<code>record append</code>）。在传统的随机写操作下，客户端会指定要写入的文件偏移位置，在多个客户端并发写的情况下，最终该文件区域的内容为多个客户端并发修改后混合的结果。而在追加写场景下，客户端不指定偏移位置，只提供需要写入的数据，<code>GFS</code> 能够原子性的至少一次将其追加到文件中，并指定一个数据写入后的偏移位置，然后将其返回给客户端。这个操作类似于在 <code>Unix</code> 下多个进程以 <code>O_APPEND</code> 的模式并发写入文件而无需担心竞争问题。</p>
<p>追加写在 <code>Google</code> 的分布式应用中使用的非常频繁，多个客户端会并发的对同一个文件追加写入。在传统的随机写操作下，客户端需要额外的同步机制例如实现一个分布式锁来保证写入的线程安全性。在 <code>Google</code> 的应用场景下，文件一般是作为一个多生产者/单消费者的缓冲队列或者包含了多客户端合并后的结果，所以追加写已经能满足需求。</p>
<p>追加写也是一种修改，它的执行流程和随机写基本是相同的，不过对于 <code>primary</code> 来说多了些额外的处理逻辑。首先客户端将需要追加写的数据发送给对应文件的最后一个 <code>chunk</code> 的所有 <code>chunkserver</code>，然后发送写请求给 <code>primary</code>。<code>primary</code> 会检查当次写入是否会造成最后 <code>chunk</code> 的大小超过 <code>64 MB</code>。如果会超过，那么 <code>primary</code> 会先将当前 <code>chunk</code> 使用特殊字符或其他手段填充到 <code>64 MB</code>，同时告知所有其他的 <code>secondary</code> 也进行同样的操作，接着回复客户端要求针对下一个新的 <code>chunk</code> 发送同样的追加写请求（追加写要求追加写入的偏移位置不超过 <code>chunk</code> 最大大小的四分之一处，从而使得由于数据填充带来的 <code>chunk</code> 碎片在一个可接受的水平。）。如果追加写入不会造成超过 <code>chunk</code> 的最大大小，那么 <code>primary</code> 会先将数据追加到自己的 <code>chunk</code> 中，产生一个新的偏移量，然后再通知其他所有的 <code>secondary</code>，将数据追加到相同的偏移量上，最后全部 <code>chunkserver</code> 执行成功后再将新的偏移量返回给客户端。</p>
<p>如果任何一个 <code>chunkserver</code> 追加写失败了，客户端会发起重试。因此，多个 <code>chunkserver</code> 下同一个 <code>chunk</code> 的数据可能会有数据不一致的情况，某条记录有可能全部或者部分重复。<code>GFS</code> 并不保证每个 <code>chunkserver</code> 上的 <code>chunk</code> 的每个字节都一样。它只保证了每个追加写能原子性的至少写入一次，因为一次追加写执行成功依赖于所有的 <code>chunkserver</code> 成功写入到指定的偏移位置上。此外，在一次追加写执行成功后，后续的追加写必然是写在一个更高的文件偏移位置或者新的 <code>chunk</code> 上，即使主节点挑选了一个新的 <code>primary</code>。在 <code>GFS</code> 的一致性模型下，成功执行了追加写所在的偏移区域的数据是已定义的（也是一致的），而剩下存在写失败的偏移区域的数据是不一致的，前文有提到过这些不一致的区域可以通过校验和来剔除。</p>
<h3 id="快照"><a href="#快照" class="headerlink" title="快照"></a>快照</h3><p>快照能够几乎瞬时的复制一个文件或者文件夹，而尽可能的降低对进行中的修改的影响。在实际应用中，一般使用快照对某个巨大的数据集快速创建一个分支（以及分支的分支），或者为当前的文件状态创建一个检查点，方便对当前的文件进行验证修改，在修改完成后提交或回滚。</p>
<p>类似于 <code>AFS</code>，<code>GFS</code> 也采用了写时复制（<code>copy-on-write</code>）的技术来实现快照。当主节点收到某个文件的快照请求时，会首先回收所有该文件的 <code>chunk</code> 所关联的租约，这就保证了后续所有对这些 <code>chunk</code> 的修改都需要先申请租约。这就给了主节点有复制一份 <code>chunk</code> 的机会。</p>
<p>当所有涉及的租约被回收或者过期后，主节点首先将快照操作写入操作日志，然后修改内存元数据，复制一份新的目标文件或文件夹的元数据，这个新复制的元数据和源文件的元数据都指向相同的 <code>chunk</code>。</p>
<p>在快照生成后，假设此时有一个客户端希望写入 <code>chunk C</code>，它会先询问主节点返回当前持有租约的 <code>primary</code>，主节点发现要修改的 <code>chunk C</code> 有多于1个的元数据引用，说明这个 <code>chunk</code> 发生了快照。主节点首先会为这个文件创建一个新的 <code>chunk C&#39;</code>，然后要求所有当前持有 <code>chunk C</code> 的 <code>chunkserver</code> 在本地创建一个文件作为 <code>chunk C&#39;</code>。因为创建 <code>chunk C&#39;</code> 的机器和持有 <code>chunk C</code> 的机器是同一台机器，所以创建 <code>chunk C&#39;</code> 只是单纯的复制 <code>chunk C</code>，不涉及任何网络 <code>IO</code>（<code>Google</code> 使用的磁盘 <code>IO</code> 速度大概是3倍于 <code>100 MB</code> 的网络 <code>IO</code> 速度）。接下来的操作就和前面描述的客户端申请写入某个 <code>chunk</code> 一样了，主节点返回 <code>chunk C&#39;</code> 的 <code>chunk handle</code> 和对应持有租约的 <code>primary</code> 给客户端，客户端并不会感知这个返回的 <code>chunk</code> 是从某个已有的 <code>chunk</code> 复制而来的。</p>
<h2 id="主节点操作"><a href="#主节点操作" class="headerlink" title="主节点操作"></a>主节点操作</h2><p>所有涉及命名空间的操作都由主节点执行。另外，主节点还负责 <code>chunk</code> 的管理：每个 <code>chunk</code> 应该放在哪台服务器上、创建新的 <code>chunk</code> 及其副本、协调各 <code>chunkserver</code> 保证每个 <code>chunk</code> 的副本数量满足阈值、保证 <code>chunkserver</code> 访问的负载均衡、回收不再使用的 <code>chunk</code> 等等。</p>
<h3 id="命名空间管理和锁"><a href="#命名空间管理和锁" class="headerlink" title="命名空间管理和锁"></a>命名空间管理和锁</h3><p>很多主节点的操作需要较长的时间完成，例如，一次快照操作就需要先回收所有 <code>chunk</code> 涉及的租约。同时，又需要降低不同的主节点操作间的影响。因此，<code>GFS</code> 允许不同的主节点操作并发执行，并通过命名空间加锁来保证线程安全。</p>
<p>和传统的文件系统不同，<code>GFS</code> 的文件夹不支持列出该文件夹内的所有文件，以及不支持文件或文件夹的别名（例如 <code>Unix</code> 的硬链接和软链接）。<code>GFS</code> 通过命名空间作为文件到元数据的映射索引，借助前缀压缩使得整个命名空间映射可以高效的保存在内存中。命名空间下的每个节点（代表一个文件名或者文件夹名）都持有一把读写锁。</p>
<p>主节点每次执行操作前都会先获取一批锁，例如如果当前操作涉及命名空间 <code>/d1/d2/.../dn/leaf</code>，主节点会先获取文件夹 <code>/d1</code>，<code>/d1/d2</code>，…，<code>/d1/d2/.../dn</code> 的读锁，以及 <code>/d1/d2/.../dn/leaf</code> 的读锁或写锁。这里的 <code>leaf</code> 对应的是某个文件或文件夹。</p>
<p>下面来举例说明 <code>GFS</code> 的锁机制如何保证当创建 <code>/home/user</code> 的快照到 <code>/save/user</code> 时避免同时创建文件 /<code>home/user/foo</code>。首先快照操作会获取 <code>/home</code> 和 <code>/save</code> 的读锁，以及 <code>home/user</code> 和 <code>/save/user</code> 的写锁。而文件创建的操作会获取 <code>/home</code> 和 <code>/home/user</code> 的读锁，以及 <code>/home/user/foo</code> 的写锁。可以看到，一个获取 <code>home/user</code> 的写锁，另一个获取 <code>home/user</code> 的读锁，所以这两个操作是互斥的，不会同时发生。写文件并不需要获取文件的父目录的写锁，因为文件夹对于 <code>GFS</code> 来说是个逻辑上的概念，背后没有类似 <code>inode</code> 的数据结构需要共享保护。获取文件夹的读锁已经足够保证不会有另一个客户端能够获取文件夹的写锁从而删除了这个文件夹。</p>
<p>这种锁机制的一个优点是允许对同一个文件夹下的不同文件进行并发修改。例如，可以在同一个文件夹下并发创建不同的文件，每一个创建操作都会获取该文件夹的读锁以及所要创建的文件的写锁。文件夹的读锁能有效避免这个文件夹被删除、重命名或者创建快照。文件的写锁则避免了同一个文件被创建两次。</p>
<p>因为整个命名空间会包含很多的节点，所以每个节点的读写锁采用了懒汉初始化的方式，并且当不需要的时候能及时删除。另外，锁的获取会按照命名空间的层级顺序以及同一层级下节点名称的字母顺序来获取，从而避免死锁。</p>
<h3 id="副本的放置"><a href="#副本的放置" class="headerlink" title="副本的放置"></a>副本的放置</h3><p>一个 <code>GFS</code> 集群一般由多个机柜上的几百台机器组成，这些 <code>chunkserver</code> 又会被几百台在同一个或不同机柜上的客户端访问，如果是两台不同机柜上的机器间的通信可能会经过1个或多个网络交换机。另外不同机柜间的入口和出口带宽一般会小于同机柜内的机器间的带宽。这种多级的分布式对分发数据的扩展性，可靠性和可用性提出了挑战。</p>
<p>所以副本的放置选择策略主要出于两个目的：最大化数据的可靠性和可用性，最大化利用网络带宽。为了实现这两点，仅仅将所有的副本分发到不同的机器上还不够，因为这只对磁盘或者机器异常进行了容错，以及最大化利用了每台机器的带宽，但是还缺少可用性的考虑。因此，需要将副本分发到不同机柜的不同机器上，这样如果当某台机柜上的机器都因故下线了（例如一些共享资源如网络交换机或者供电设备发生异常），系统仍然是可用的。所以在跨机柜的访问下，某个 <code>chunk</code> 的读操作会充分利用不同机柜间的带宽，另一方面 <code>chunk</code> 的写操作就需要跨机柜访问，这也是跨机柜存储的权衡利弊的一个体现。</p>
<h3 id="副本的创建、重复制和负载均衡"><a href="#副本的创建、重复制和负载均衡" class="headerlink" title="副本的创建、重复制和负载均衡"></a>副本的创建、重复制和负载均衡</h3><p><code>chunk</code> 的副本的创建出于三个目的：创建一个新的 <code>chunk</code> 时需要保证存储的可靠性，保证每个 <code>chunk</code> 的副本数量满足阈值，保证 <code>chunkserver</code> 访问的负载是均衡的。</p>
<p>当主节点创建一个 <code>chunk</code> 时，它会决定在哪个 <code>chunkserver</code> 上创建空的 <code>chunk</code>，它主要基于以下几点考虑：</p>
<ol>
<li>选择磁盘空间利用率低于平均值的 <code>chunkserver</code>，这保证了长期来看每台 <code>chunkserver</code> 的磁盘空间利用率维持在一个相近的水平。</li>
<li>避免每台 <code>chunkserver</code> 存在过多最近创建的 <code>chunk</code>。虽然创建一个 <code>chunk</code> 比较简单，但是可以预见的是随之而来这个 <code>chunk</code> 会面临大量的写入。</li>
<li>如前面所述，每个 <code>chunk</code> 的副本需要跨机柜存储。</li>
</ol>
<p>当某个 <code>chunk</code> 的副本数量低于用户指定的阈值时，主节点会复制一个 <code>chunk</code> 到某台 <code>chunkserver</code> 上。这种情况一般有以下几种原因：</p>
<ol>
<li>某台 <code>chunkserver</code> 异常失联了。</li>
<li><code>chunkserver</code> 反馈其保存的 <code>chunk</code> 数据已损坏。</li>
<li><code>chunkserver</code> 的某个磁盘由于异常被禁用了。</li>
<li>用户要求增加副本的数量。</li>
</ol>
<p>主节点在复制一个 <code>chunk</code> 时会按照优先级处理。其中一个是距离满足指定的副本数量阈值还差多少。例如如果某个 <code>chunk</code> 还差两个副本就比只差一个副本的 <code>chunk</code> 有着更高的复制优先级。另外，复制还在使用的 <code>chunk</code> 的优先级高于复制最近被删除的 <code>chunk</code>。最后，为了避免缺少副本带给应用的影响，主节点会优先处理那些阻塞了客户端执行的 <code>chunk</code>。</p>
<p>主节点根据优先级决定复制哪个 <code>chunk</code> 之后，会选择几台 <code>chunkserver</code> 让其直接从拥有完整副本的 <code>chunkserver</code> 上复制数据。这种情况下新的 <code>chunk</code> 副本的存放位置的选择和前文所述类似：尽量保证每台 <code>chunkserver</code> 的磁盘空间利用率维持在一个相近的水平，避免副本的复制集中在一台 <code>chunkserver</code> 上，尽量保证副本跨机柜存储。为了避免副本复制的流量压垮客户端的流量，主节点会限制整个集群以及每台 <code>chunkserver</code> 同一时间执行的副本复制操作的数量。另外，每台 <code>chunkserver</code> 也会限制花在副本复制上的带宽。</p>
<p>最后，主节点会定期检查各 <code>chunkserver</code> 的流量或者磁盘空间利用率是否均衡：如果发现了不均衡则会在各 <code>chunkserver</code> 间移动某些 <code>chunk</code> 以达到磁盘空间利用率或流量的均衡。根据上述的策略，对于一台新加入集群的 <code>chunkserver</code> 来说，主节点会逐渐的将其填满 <code>chunk</code> 而不是马上让其承接大量新的 <code>chunk</code> 然后伴随着大量的写流量。另外，主节点也需要决定从哪台 <code>chunkserver</code> 上移除 <code>chunk</code>，一般的，主节点会优先选择磁盘可用空间率低于平均水平的 <code>chunkserver</code>，从而使得每台 <code>chunkserver</code> 的磁盘空间利用率维持在一个相近的水平。</p>
<h3 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h3><p>当某个文件被删除后，<code>GFS</code> 不会马上释放它所占用的空间，而是在常规的垃圾回收期间在文件和 <code>chunk</code> 层面延迟删除，这种策略使得系统更加简洁和可靠。</p>
<h4 id="机制"><a href="#机制" class="headerlink" title="机制"></a>机制</h4><p>当某个文件被应用删除后，和其他修改一样主节点首先会将该操作记录到操作日志中。不过，<code>GFS</code> 并不会马上删除该文件，而是将该文件重命名为一个隐藏的名字，同时这个隐藏的名字包含了文件删除时的时间戳。在主节点常规扫描系统的命名空间的期间，它会删除命名空间中已经存在了3天（时间间隔可配置）的隐藏文件。在这之前，这个文件依然是可以通过重命名后的名字读取的，或者将其重命名回原来的名字来撤销删除。一旦主节点将其从命名空间中删除，其对应的元数据也会一并删除，从而切断了这个文件和任何 <code>chunk</code> 的关联。</p>
<p>类似的，主节点也会定期扫描所有 <code>chunk</code> 的命名空间，一旦发现没有任何关联的 <code>chunk</code>（即没有被任何文件引用的 <code>chunk</code>），主节点就会删除这些 <code>chunk</code> 的元数据。之后，在主节点和 <code>chunkserver</code> 的心跳监测中，<code>chunkserver</code> 会向主节点反馈其所拥有的 <code>chunk</code>，主节点会返回所有已经不在元数据中的 <code>chunk</code> 标识，<code>chunkserver</code> 收到回复后就可以删除掉这些不需要的 <code>chunk</code>。</p>
<h4 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h4><p>虽然分布式的垃圾回收是个困难的问题，往往需要一套特定编程语言下的复杂解决方案，在 <code>GFS</code> 的实现中却很简单。主节点可以轻易的标识出所有 <code>chunk</code> 的引用，它们全都保存在文件到 <code>chunk</code> 的映射中。同时主节点也可轻易的标识出所有的 <code>chunk</code> 副本，它们都是 <code>chunkserver</code> 上某个指定文件夹下的 <code>Linux</code> 文件。任何一个不在主节点中记录的副本都可以被回收。</p>
<p><code>GFS</code> 采用的延迟垃圾回收的方式相比于立即删除的方式存在以下几个优点：</p>
<ol>
<li>对于组件异常经常发生的大型分布式系统来说，延迟删除更为简洁和可靠。创建 <code>chunk</code> 时有可能在部分 <code>chunkserver</code> 上成功在部分 <code>chunkserver</code> 上失败，这就导致创建 <code>chunk</code> 的这次操作整体是失败的，从而使得主节点不会记录该 <code>chunk</code>，后续也无法知晓这些部分创建成功的 <code>chunk</code>。如果采用立即删除的方式，需要由主节点向 <code>chunkserver</code> 发送删除 <code>chunk</code> 的消息并需要对发送失败的消息进行重发。而延迟垃圾回收的方式提供了一个统一、可靠的方式来删除无用的 <code>chunk</code>。</li>
<li>主节点将 <code>chunk</code> 的删除合并到了主节点的日常维护中进行，例如对命名空间的定期扫描以及主节点和 <code>chunkserver</code> 的心跳监测。这就可以将 <code>chunk</code> 的删除进行批量处理从而摊薄了运行的成本。另外，垃圾回收只会在主节点较为空闲的时候进行，主节点会更优先的响应客户端的请求。</li>
<li>延迟删除给不可逆转的误删除提供了缓冲。</li>
</ol>
<p>在实际应用中，延迟删除的主要缺点是不利于磁盘剩余空间紧张的 <code>chunkserver</code> 释放磁盘空间。尤其是对不停的创建然后删除临时文件的应用来说，不能够马上利用那些不需要的临时文件的空间。<code>GFS</code> 通过加快回收某个重复删除的文件来缓解这个问题。同时，<code>GFS</code> 也允许用户针对不同的命名空间设置不同的副本数量阈值和垃圾回收策略。例如，用户可指定某个目录下的所有文件的 <code>chunk</code> 都不需要额外的副本，以及当文件删除时系统会立即直接删除。</p>
<h3 id="过期的副本检测"><a href="#过期的副本检测" class="headerlink" title="过期的副本检测"></a>过期的副本检测</h3><p>在某个 <code>chunk</code> 所属的 <code>chunkserver</code> 异常下线期间，其他 <code>chunkserver</code> 上的 <code>chunk</code> 发生了修改，则该 <code>chunkserver</code> 再次上线后该 <code>chunk</code> 的数据版本已落后。主节点会记录每一个 <code>chunk</code> 最新的版本号，从而能识别过期的副本。</p>
<p>每当主节点为某一个 <code>chunk</code> 分配一个租约时，它会先更新 <code>chunk</code> 的版本号，并通知所有当前持有最新版本 <code>chunk</code> 的 <code>chunkserver</code> 也更新版本号。主节点和 <code>chunkserver</code> 都会将这个版本号持久化，这里的持久化顺序应该是 <code>chunkserver</code> 先，主节点后，否则主节点先持久化版本号然后此时下线了，再次上线后造成没有任何一个 <code>chunkserver</code> 持有最新的版本号。只有当持久化完成之后，主节点才会将 <code>primary</code> 发送给客户端，之后才能开始写入。如果此时某个 <code>chunkserver</code> 下线了，那么它所持有的 <code>chunk</code> 的版本号就无法更新，当这个 <code>chunkserver</code> 再次上线时，它会向主节点报告所持有的 <code>chunk</code> 以及对应的版本号，主节点就能知道这个 <code>chunkserver</code> 持有了过期的副本。如果主节点发现某个 <code>chunk</code> 的副本的版本号大于自己内存中的版本号，那么主节点就知道自己在更新版本号期间下线了，直接使用 <code>chunkserver</code> 的版本号作为最新的版本号。</p>
<p>主节点会在垃圾回收期间删除过期的副本。在这之前，如果有客户端请求该 <code>chunk</code> 的信息，主节点会忽视持有过期副本的 <code>chunkserver</code>，不会将其返回给客户端。其次，主节点在返回给客户端的 <code>chunk</code> 信息中也包含了版本号，在要求某台 <code>chunkserver</code> 去复制另一台 <code>chunkserver</code> 上的 <code>chunk</code> 数据时也同样附带了版本号，这样客户端或者 <code>chunkserver</code> 在读取 <code>chunk</code> 数据时就能比较读到的数据是否是最近的版本。</p>
<h2 id="容错和诊断"><a href="#容错和诊断" class="headerlink" title="容错和诊断"></a>容错和诊断</h2><p><code>Google</code> 在设计 <code>GFS</code> 遇到的最大问题之一是如何应对频繁的组件异常。各组件的质量和数量决定了异常是经常出现而不是偶尔出现：既不能完全信任机器，也不能完全信任磁盘。组件异常可能造成系统不可用，或者更糟的是数据损坏。本节主要描述 <code>GFS</code> 如何面对这些挑战以及开发了哪些工具来定位问题。</p>
<h3 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h3><p>一个 <code>GFS</code> 集群由数百台机器组成，某些机器必然会在任意时间发生异常。<code>GFS</code> 通过快速恢复和副本这两个手段实现了系统的高可用。</p>
<h4 id="快速恢复"><a href="#快速恢复" class="headerlink" title="快速恢复"></a>快速恢复</h4><p>主节点和 <code>chunkserver</code> 都是设计成不管以什么样的方式终止，都能在数秒内恢复终止前的状态。实际上，<code>GFS</code> 并不会刻意区分正常的终止还是异常的终止，各服务器本身日常就会通过杀死进程来终止。客户端或其他服务器会因此经历一段短暂的中断，因为进行中的请求会因为服务器的终止而超时，继而客户端会对重启后的服务器进行重连，然后重试。</p>
<h4 id="chunk-副本"><a href="#chunk-副本" class="headerlink" title="chunk 副本"></a><code>chunk</code> 副本</h4><p>如之前描述，每个 <code>chunk</code> 会备份到不同机柜上的不同机器。用户可指定不同命名空间配置不同的备份策略。默认每个 <code>chunk</code> 有3个副本。主节点通过 <code>chunkserver</code> 间复制 <code>chunk</code> 来保证每个 <code>chunk</code> 有足够的副本数量，避免 <code>chunkserver</code> 由于下线或者数据损坏造成 <code>chunk</code> 副本数量不足。虽然依靠副本已经能较好的支撑需求，<code>Google</code> 的工程师也在考虑跨服务器的冗余手段如奇偶校验或者 <code>erasure code</code> 来应对日渐增长的只读存储需求。在当前这个松耦合的系统中实现更复杂的冗余策略会更有挑战性，不过也是可控的，因为大部分的文件操作都是追加写和读而不是随机写。</p>
<h4 id="主节点副本"><a href="#主节点副本" class="headerlink" title="主节点副本"></a>主节点副本</h4><p><code>GFS</code> 通过备份主节点的状态来实现可靠性。主节点的操作日志和检查点都会备份到多台机器上。一次文件的修改只有当主节点和所有备份服务器都写入到本地日志之后才认为是已提交的。从实现的简单性考虑，只会有一个主节点机器负责所有的元数据修改以及在后台运行的一些日常维护活动来修改主节点的内部状态，例如垃圾回收。当这个主节点发生异常时，它几乎能马上重启。如果整个机器或者磁盘发生异常，<code>GFS</code> 之外的监控设施能在其他机器上借助操作日志副本重新启动一个新的主节点进程。对于客户端来说不需要有任何改动，因为客户端和主节点的通信是通过主机名进行的（例如 <code>gfs-test</code>），其对应的是一个 <code>DNS</code> 别名，当主节点更换机器时，同步修改别名映射即可。</p>
<p>另外，即使主节点异常了，还有影子主节点也提供对本地文件系统的只读访问功能。因为这个影子主节点不是严格的镜像节点，所以它们的文件系统上的数据可能会略落后于主节点，一般来说是几秒。影子主节点依然能够提供当前未在修改的文件查询功能，或者应用程序不介意查询到一部分过期的数据，例如 <code>chunkserver</code> 列表小于实际运行的数量。因为文件的内容是通过 <code>chunkserver</code> 读取，和主节点无关，所以客户端不会读取到过期的数据。可能过期的数据是元数据，例如文件夹的内容或者权限控制信息。</p>
<p>为了保证自己持续更新，影子主节点会不断从某台操作日志副本机器读取日志，并以和主节点一样的执行顺序将其重放到内存中的数据结构中。和主节点一样，影子主节点在启动时也会拉取 <code>chunkserver</code> 信息来定位 <code>chunk</code> 的副本位置，并定期与其进行心跳监测。它依赖主节点来更新 <code>chunk</code> 副本的位置，如主节点创建和删除副本。</p>
<h3 id="数据完整性"><a href="#数据完整性" class="headerlink" title="数据完整性"></a>数据完整性</h3><p>每台 <code>chunkserver</code> 使用校验和来检测损坏的数据。鉴于一个 <code>GFS</code> 集群有几千个磁盘运行在几百台机器上，磁盘异常经常会导致文件读写时数据损坏或丢失。虽然可以从其他 <code>chunkserver</code> 恢复，但是通过比较多个 <code>chunkserver</code> 上的副本来检测数据损坏显然是不实际的。另外，在一致性模型中提到，每个副本的数据不是每个比特都一致的，由于追加写的原子性保证造成异常重试的存在，每个副本的数据很大可能是不同的。所以，每台 <code>chunkserver</code> 必须能够自己独立通过校验和来检测数据是否损坏。</p>
<p>每个 <code>chunk</code> 切分为每块大小为 <code>64 KB</code> 的数据块，每个数据块对应一个32位的校验和。和其他元数据一样，校验和也保存在内存中，并随日志持久化到本地磁盘中，且和用户数据分开存放。</p>
<p>对于读操作，<code>chunkserver</code> 会根据读取的字节范围先根据校验和校验所覆盖的数据块的数据是否完整，然后再返回数据给客户端或其他的 <code>chunkserver</code>。因此，每台 <code>chunkserver</code> 不会把损坏的数据同步到其他 <code>chunkserver</code> 上。如果 <code>chunkserver</code> 发现某个数据块发生了损坏，则会返回一个异常给调用方，并向主节点报告。调用方收到回复后会重新选择一个 <code>chunkserver</code> 进行读操作，而主节点则会安排这个 <code>chunkserver</code> 从其他 <code>chunkserver</code> 那复制 <code>chunk</code>。当新的 <code>chunk</code> 就绪后，主节点会通知这个 <code>chunkserver</code> 删除损坏的 <code>chunk</code>。</p>
<p>校验和对读操作带来的影响较小，主要有几个方面的原因。大部分的一次读操作只涉及了几个数据块，所以需要读取和验证的校验和数量也较少。另外，客户端在读取时，会尽量保证正好在数据块的边界读取，而不是跨数据块。最后，校验和验证不涉及 <code>IO</code>，以及校验和的计算可以和数据读取 <code>IO</code> 同时进行。</p>
<p>针对追加写，校验和计算对此做了大量的优化，因为追加写是主要的写场景。计算校验和时，<code>GFS</code> 会复用当前最后一个数据块的校验和，一个数据块的大小是 <code>64 KB</code>，可能目前只写入了 <code>30 KB</code>，那么本次往剩下的 <code>34 KB</code> 写入时，则无需从头开始计算这个数据块的校验和。对于新填充的数据块依然还是需要完整计算校验和。即使当前这个写入了 <code>30 KB</code> 的数据块损坏了，计算校验和时无法知晓，最终这个数据块的校验和与保存的数据已经不匹配，这个损坏也会在下一次读操作中被调用方感知。</p>
<p>相反的，对于随机写操作，如果当前的随机写覆盖了某个 <code>chunk</code> 已有的数据，则必须先对所覆盖的数据块进行校验和验证，确保当前的数据未损坏，然后再执行写入和计算新的校验和。如果不进校校验就写入，那么有可能在写入之外的地方已经发生了数据损坏。因为一次随机写可能写不满最后一个数据块，假设这个数据块是损坏的，如果写前校验就能发现这个问题。不过这里并没有理解为什么不能将完整性校验推迟到后续的读操作时，可能是因为追加写和流式读是 <code>GFS</code> 应用的主要方式，完整性校验推迟到读操作也能很快发现问题，而随机写是很少量的场景，写时校验能更快的发现问题。</p>
<p>在系统空闲的时候，<code>chunkserver</code> 会扫描和校验所有不活跃的 <code>chunk</code>，从而能够发现那些不经常被访问但是已损坏的 <code>chunk</code>（因为数据完整性检测发生在读写操作时）。一旦发现这样的 <code>chunk</code>，主节点会创建一个新的 <code>chunk</code> 然后指示 <code>chunkserver</code> 复制一份有效的 <code>chunk</code>，最后再删除损坏的 <code>chunk</code>。这就避免因为一些不活跃但已损坏的副本使得主节点认为这些 <code>chunk</code> 依然满足副本数量阈值的要求。</p>
<h3 id="诊断工具"><a href="#诊断工具" class="headerlink" title="诊断工具"></a>诊断工具</h3><p>通过详尽的诊断日志能有效的帮助问题隔离，调试，性能分析，而且带来的成本较小。如果没有日志，则很难理解各机器间无法复现的交互。针对某些重要的事件（如 <code>chunkserver</code> 的下线和上线） <code>GFS</code> 会生成相应的诊断日志，同时还会记录所有的 <code>RPC</code> 请求和响应。诊断日志的删除对系统的正确性没有任何影响。然而在磁盘空间允许的情况下，还是会尽可能保留多的诊断日志。</p>
<p>除了正在读取或写入的文件，诊断日志记录了其他所有 <code>RPC</code> 的请求和响应。通过比对各机器上的 <code>RPC</code> 日志，就能重现当时系统交互的场景，从而进行问题定位。同时这些日志也能辅助压力测试和性能分析。</p>
<p>诊断日志带来的性能影响很小（在其带来的价值面前不值一提），因为采用了异步顺序的方式写入日志。同时，最近某段时间内的事件也会保存在内存中用于线上的持续监控。</p>
<p>参考：</p>
<ul>
<li><a href="https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf">The Google File System</a></li>
<li><a href="https://pdos.csail.mit.edu/6.824/notes/l-gfs.txt">6.824 2022 Lecture 3: GFS</a></li>
<li><a href="https://www.zhihu.com/question/20485173">GFS，一致性模型里，“已定义”和“不一致”具体表示的什么含义？</a></li>
</ul>
]]></content>
      <tags>
        <tag>MIT 6.824</tag>
        <tag>Paper</tag>
        <tag>GFS</tag>
      </tags>
  </entry>
</search>
